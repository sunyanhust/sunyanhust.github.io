<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>文章汇总：融合BN加速推理、BERT推理加速实践、pytorch C++前端推理模型以及ReZero: 使用加权残差连接加速深度模型收敛 | Gridea</title>
<link rel="shortcut icon" href="https://sunyanhust.github.io/favicon.ico?v=1586660820278">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://sunyanhust.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="文章汇总：融合BN加速推理、BERT推理加速实践、pytorch C++前端推理模型以及ReZero: 使用加权残差连接加速深度模型收敛 | Gridea - Atom Feed" href="https://sunyanhust.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="📚融合BN加速推理
批归一化（Batch Normalization）因其可以加速神经网络训练、使网络训练更稳定，而且还有一定的正则化效果，所以得到了非常广泛的应用。但是，在推理阶段，BN层一般是可以完全融合到前面的卷积层的，而且丝毫不影..." />
    <meta name="keywords" content="" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://sunyanhust.github.io">
  <img class="avatar" src="https://sunyanhust.github.io/images/avatar.png?v=1586660820278" alt="">
  </a>
  <h1 class="site-title">
    Gridea
  </h1>
  <p class="site-description">
    温故而知新
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
        <a href="https://github.com/sunyanhust" target="_blank">
          <i class="ri-github-line"></i>
        </a>
      
    
      
    
      
    
      
        <a href="https://www.zhihu.com/people/sun-yan-90-29" target="_blank">
          <i class="ri-zhihu-line"></i>
        </a>
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              文章汇总：融合BN加速推理、BERT推理加速实践、pytorch C++前端推理模型以及ReZero: 使用加权残差连接加速深度模型收敛
            </h2>
            <div class="post-info">
              <span>
                2020-04-04
              </span>
              <span>
                2 min read
              </span>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <h2 id="融合bn加速推理">📚融合BN加速推理</h2>
<p>批归一化（Batch Normalization）因其可以加速神经网络训练、使网络训练更稳定，而且还有一定的正则化效果，所以得到了非常广泛的应用。但是，在推理阶段，BN层一般是可以完全融合到前面的卷积层的，而且丝毫不影响性能。<br>
<strong>参考文章</strong>：<a href="https://zhuanlan.zhihu.com/p/120265831">深度学习推理时融合BN,轻松获得约5%的提速</a><br>
<strong>代码</strong>：keras的暂时没有找到，有空可以写写</p>
<h2 id="bert推理加速实践">📚BERT推理加速实践</h2>
<p>主要基于Faster Transformer，<strong>参考文章</strong>：</p>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/89694963">BERT模型推理加速总结</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/91024786">BERT推理加速实践</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/73715272">NVIDIA BERT推理解决方案Faster Transformer开源啦</a></li>
</ol>
<h2 id="pytorch-c前端推理模型">📚pytorch C++前端推理模型</h2>
<p>使用libtorch C++前端来推理复杂模型，可能会用到。<strong>参考文章</strong>：<a href="https://zhuanlan.zhihu.com/p/69421019">嫌python慢？来这里用pytorch C++前端推理模型</a></p>
<h2 id="rezero-使用加权残差连接加速深度模型收敛">📚ReZero: 使用加权残差连接加速深度模型收敛</h2>
<p><strong>论文标题</strong>：ReZero is All You Need: Fast Convergence at Large Depth</p>
<p><strong>论文作者</strong>：Thomas Bachlechner, Bodhisattwa Prasad Majumder, Huanru Henry Mao, Garrison W. Cottrell, Julian McAuley</p>
<p><strong>论文链接</strong>：https://arxiv.org/abs/2003.04887</p>
<p><strong>代码链接</strong>：https://github.com/majumderb/rezero</p>
<p>简单来说对残差进行了加权并初始化权重为0来加快网络收敛速度。思路比较清晰，可证明也work，具体参考文章<a href="https://zhuanlan.zhihu.com/p/113384612">ReZero: 使用加权残差连接加速深度模型收敛</a></p>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#%E8%9E%8D%E5%90%88bn%E5%8A%A0%E9%80%9F%E6%8E%A8%E7%90%86">📚融合BN加速推理</a></li>
<li><a href="#bert%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F%E5%AE%9E%E8%B7%B5">📚BERT推理加速实践</a></li>
<li><a href="#pytorch-c%E5%89%8D%E7%AB%AF%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B">📚pytorch C++前端推理模型</a></li>
<li><a href="#rezero-%E4%BD%BF%E7%94%A8%E5%8A%A0%E6%9D%83%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5%E5%8A%A0%E9%80%9F%E6%B7%B1%E5%BA%A6%E6%A8%A1%E5%9E%8B%E6%94%B6%E6%95%9B">📚ReZero: 使用加权残差连接加速深度模型收敛</a></li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://sunyanhust.github.io/post/xin-guan-bing-du-quan-qiu-da-liu-xing-wo-men-que-fa-de-zhi-shi-yi-miao/">
              <h3 class="post-title">
                新冠病毒全球大流行：我们缺乏的只是疫苗？
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://sunyanhust.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
