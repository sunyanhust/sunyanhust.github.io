<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://sunyanhust.github.io</id>
    <title>Gridea</title>
    <updated>2020-04-05T15:14:33.544Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://sunyanhust.github.io"/>
    <link rel="self" href="https://sunyanhust.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://sunyanhust.github.io/images/avatar.png</logo>
    <icon>https://sunyanhust.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, Gridea</rights>
    <entry>
        <title type="html"><![CDATA[有趣的网站]]></title>
        <id>https://sunyanhust.github.io/post/you-qu-de-wang-zhan/</id>
        <link href="https://sunyanhust.github.io/post/you-qu-de-wang-zhan/">
        </link>
        <updated>2020-04-05T14:42:54.000Z</updated>
        <content type="html"><![CDATA[<h2 id="音乐">📻音乐</h2>
<ul>
<li><a href="http://music.qkhhyiu.cn/">音乐搜索器</a>: 多站合一音乐搜索解决方案</li>
<li><a href="http://guozhivip.com/yinyue/">果汁音乐</a></li>
</ul>
<h2 id="搜索">🔮搜索</h2>
<ul>
<li><a href="https://scholar.chongbuluo.com/">虫部落</a></li>
<li><a href="http://guozhivip.com/so/">果汁搜索</a></li>
<li><a href="https://jikipedia.com/">小鸡词典</a>：网络流行语</li>
<li><a href="https://zh.wikihow.com/%E9%A6%96%E9%A1%B5">wikihow</a>：生活维基百科</li>
</ul>
<h2 id="排行榜">📜排行榜</h2>
<ul>
<li><a href="http://guozhivip.com/rank/">果汁排行榜</a></li>
<li><a href="https://tophub.today/">今日热榜</a></li>
</ul>
<h2 id="其他">📚 其他</h2>
<ul>
<li>
<p><a href="http://guozhivip.com/eat/">今天吃啥呀</a></p>
</li>
<li>
<p><a href="http://www.underseacat.com/fan">云风扇</a>：心静自然凉</p>
</li>
<li>
<p><a href="https://fonts.safe.360.cn/">360查字体</a> ：你的字体能商用吗</p>
</li>
<li>
<p><a href="https://www.gaoding.com/koutu">搞定抠图</a></p>
</li>
<li>
<p><a href="http://www.nows.fun/">毒鸡汤</a></p>
</li>
<li></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[文章汇总：融合BN加速推理、BERT推理加速实践、pytorch C++前端推理模型以及ReZero: 使用加权残差连接加速深度模型收敛]]></title>
        <id>https://sunyanhust.github.io/post/wen-zhang-hui-zong-rong-he-bn-jia-su-tui-li-bert-tui-li-jia-su-shi-jian-pytorch-cqian-duan-tui-li-mo-xing-yi-ji-rezero-shi-yong-jia-quan-can-chai-lian-jie-jia-su-shen-du-mo-xing-shou-lian/</id>
        <link href="https://sunyanhust.github.io/post/wen-zhang-hui-zong-rong-he-bn-jia-su-tui-li-bert-tui-li-jia-su-shi-jian-pytorch-cqian-duan-tui-li-mo-xing-yi-ji-rezero-shi-yong-jia-quan-can-chai-lian-jie-jia-su-shen-du-mo-xing-shou-lian/">
        </link>
        <updated>2020-04-04T14:48:05.000Z</updated>
        <content type="html"><![CDATA[<h2 id="融合bn加速推理">📚融合BN加速推理</h2>
<p>批归一化（Batch Normalization）因其可以加速神经网络训练、使网络训练更稳定，而且还有一定的正则化效果，所以得到了非常广泛的应用。但是，在推理阶段，BN层一般是可以完全融合到前面的卷积层的，而且丝毫不影响性能。<br>
<strong>参考文章</strong>：<a href="https://zhuanlan.zhihu.com/p/120265831">深度学习推理时融合BN,轻松获得约5%的提速</a><br>
<strong>代码</strong>：keras的暂时没有找到，有空可以写写</p>
<h2 id="bert推理加速实践">📚BERT推理加速实践</h2>
<p>主要基于Faster Transformer，<strong>参考文章</strong>：</p>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/89694963">BERT模型推理加速总结</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/91024786">BERT推理加速实践</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/73715272">NVIDIA BERT推理解决方案Faster Transformer开源啦</a></li>
</ol>
<h2 id="pytorch-c前端推理模型">📚pytorch C++前端推理模型</h2>
<p>使用libtorch C++前端来推理复杂模型，可能会用到。<strong>参考文章</strong>：<a href="https://zhuanlan.zhihu.com/p/69421019">嫌python慢？来这里用pytorch C++前端推理模型</a></p>
<h2 id="rezero-使用加权残差连接加速深度模型收敛">📚ReZero: 使用加权残差连接加速深度模型收敛</h2>
<p><strong>论文标题</strong>：ReZero is All You Need: Fast Convergence at Large Depth</p>
<p><strong>论文作者</strong>：Thomas Bachlechner, Bodhisattwa Prasad Majumder, Huanru Henry Mao, Garrison W. Cottrell, Julian McAuley</p>
<p><strong>论文链接</strong>：https://arxiv.org/abs/2003.04887</p>
<p><strong>代码链接</strong>：https://github.com/majumderb/rezero</p>
<p>简单来说对残差进行了加权并初始化权重为0来加快网络收敛速度。思路比较清晰，可证明也work，具体参考文章<a href="https://zhuanlan.zhihu.com/p/113384612">ReZero: 使用加权残差连接加速深度模型收敛</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[新冠病毒全球大流行：我们缺乏的只是疫苗？]]></title>
        <id>https://sunyanhust.github.io/post/xin-guan-bing-du-quan-qiu-da-liu-xing-wo-men-que-fa-de-zhi-shi-yi-miao/</id>
        <link href="https://sunyanhust.github.io/post/xin-guan-bing-du-quan-qiu-da-liu-xing-wo-men-que-fa-de-zhi-shi-yi-miao/">
        </link>
        <updated>2020-04-04T14:18:07.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>本文转自微信公众号，<a href="https://mp.weixin.qq.com/s?__biz=MjM5MjYxOTQ2NA==&amp;mid=2650202369&amp;idx=1&amp;sn=738db7d0fc8c69f2dbe5b8ad64ae09e5&amp;chksm=bea1cfa689d646b0183608329abdbf11c53f64924ce476a219bc39cbb7373805c3dbaf36c936&amp;mpshare=1&amp;scene=23&amp;srcid=0404YwhJm01ENyZGtvQaeyr6&amp;sharer_sharetime=1586009335106&amp;sharer_shareid=47825813c3bfc95e426cc37b214c1ac0#rd">原文</a>。个人觉得写得非常好，作为此次疫情的反思和总结。</p>
</blockquote>
<p>又一次的开学典礼付诸东流，这一次春天的典礼是因为新冠肺炎，上一次冬天的典礼是因为香港动荡。不少朋友问我怎么没有看到我在新冠肺炎下的演讲、观点和文章？近两个月里，好文何止上百上千？有多少从疫情中央发出的令人潸然泪下的亲身经历？有多少发自内心的自省和思考？有多少对国家未来的焦虑和期许？我们已经好久没有经历过这样的场面，在同一个时刻、为同一个人、为同一件事发出我们谦卑的声音，吹起我们的口哨声？而这都是为了同一个目标，希望类似的悲剧可以再少些；希望我们无需生活在不必要的恐惧之中；希望这个民族无论何时都是被人敬重的。</p>
<p>这当然是一场灾难。庚子鼠年以超出所有人的想象力，开始了这一场天灾，但这也是一场人祸。根据英国南安普敦大学的研究，如果武汉提前三个星期开始狙击这一病毒，仅中国受感染的数目就可以减少95%。当然这只是一项研究，而现实与数字模型之间存在的距离有时可以是如此之大！如果武汉封城之后欧美各国不会如此傲慢，而是积极合作应对，今天的欧洲和美国或许就不会面对这样的人道危机！在全球面临这样的大灾难面前，相反，我们看到的是自私与自大、嘲讽与指责、恐惧与推卸，甚至阴谋论甚嚣尘上，代替了理性的思考和应有的反思。面对这样的世纪疫情大流行的恐惧，我们缺乏的远非控制疫情的疫苗！</p>
<p>我们缺乏常识；我们缺乏见识；我们缺乏透明度；我们缺乏同理心；我们缺乏担当；我们缺乏反思……</p>
<h2 id="我们缺乏常识">我们缺乏常识</h2>
<p>在这场疫情席卷全球时，新冠肺炎也成了阴谋论的温床。短短的一个多月时间里，有武汉病毒研究所病毒外漏的“泄毒之说”，有美国驻武汉领事馆留下八个可疑生化毒物箱的“种毒之说”，有美国参议员柯顿指控毒源来自大陆生化实验室的“放毒之说”，有武汉军运会期间美国兵“播毒之说”，莫衷一是。我从一开始就对阴谋论存疑，我总觉得人性虽恶，但人类的恶行还不至于如此匪夷所思。有些指控，稍微求证，就知道是胡言乱语。美国驻武汉总领事馆位于武汉新世界国贸大楼第47楼，后院在哪里？生化毒物箱又如何埋在地下1.5公尺处？谎言哗众取宠，但信者众！如果病毒来自中国的生物基因作战实验室，对病毒的认识和控制还会那么难吗？这样低水准的阴谋论竟然畅行全球！其实只要有基本常识，反智的阴谋论就不可能大行其道。</p>
<p>我们缺乏常识也因为我们常常以偏盖全，信息不对称。意大利专家雷穆齐（Giuseppe Remuzzi）表示早在去年11月份，意大利北部就有人染上高度疑似新冠肺炎的不明肺炎。中国的一些媒体第一时间就报道了意大利是源头的说法，让不少中国人信以为真。中国的记者还纷纷打电话去采访，他对自己早先的采访被断章取义非常不满，并指出这是教科书式的“宣传手段”。但之后他纠正中国媒体的说法，并没有被广泛报道。他还在另一个场合表示，武汉可能早已出现新冠肺炎感染，期间有大量中国人从武汉来到意大利，令意大利出现了疑似案例，由于一切来自中国的信息都不透明，才令疫情失去控制的黄金时机。其实意大利北部温州的人很多，而一月的时候，除了武汉，温州疫情也很严重。在中国就有专家因看到浙江有人感染之后，强烈建议武汉必须封城。</p>
<p>疫情刚爆发时，有不少人总在那里质问，美国每年季节性流感死了成千上万人，无人恐慌，世界各国没有切断和美国的联系，但美国为何要切掉和中国的联系？这是否过度反应？是否歧视中国？是否违反世界卫生组织的指引？但季节性流感有疫苗，死亡率只有新冠肺炎的十分之一，这样的事实很多人并不了解。如今看到疫情蔓延全球，纽约成为另一个武汉，大家应该可以明白每年在美国发生的季节性流感和新冠肺炎之间的根本不同。</p>
<p>我们缺乏常识是因为我们受制于我们有限的知识和见识，无法认识事物的真相；我们缺乏常识也是因为我们面对恐惧而惊慌失措，无法理性地看待自媒体时代所获得的虚假资讯；我们缺乏常识也是因为我们的立场和偏见挡住了自己的视线，无法走出原有的认知。</p>
<h2 id="我们缺乏见识">我们缺乏见识</h2>
<p>同样在欧美各国，不少人还真的将新冠肺炎和季节性流感等同起来，根本不把新冠病毒当回事，酿成今日欧美各国沦陷的惨痛教训。在发生新冠肺炎这样的全球公共医疗危机时，不要说普通人，即便全球最顶尖的传染病专家对病毒都缺乏足够的认识，束手无策，无法预见其发展方向，至多只能依靠模型做出推算，但最终和现实也可能相距甚远。在疫情初期，不要说西方的专家，即便内地最顶尖的传染病专家都不认为这次疫情比“非典”严重。因香港的特殊地位，香港大学的专家学者敢于发声，袁国勇教授早在1月3日就警告香港政府，这次疫情极为严重，香港特区政府早在1月7日就宣布把“严重新型传染性病原体呼吸系统病”列为须呈报的疾病，卫生部门有权强制隔离怀疑患者。管轶教授是香港大学新发传染性疾病国家重点实验室主任，最早发出疫情将失控的警告。</p>
<p>香港因2003年受“非典”的沉重打击，大家记忆犹新，不少香港人对新冠肺炎都非常恐惧，也出现了抢购潮。但在香港的西方人对此的反应就大为不同，包括香港大学中的白人学者也觉得这是类似流感的病毒，只不过传染率和死亡率高而已。这种判断一度让我觉得香港是否过度恐慌了，特别是香港医务人员以罢工逼迫政府封关的举动过激，违背了医务人员救死扶伤的伦理底线。疫情初期在香港街上也基本看不到有多少西方人戴口罩，所以在西方的华人因为担心感染病毒戴口罩也被视为怪物，不被理解还算次要，还受到白眼和歧视，甚至遭人毒打。因为在西方的文化里，只有得病的人才戴口罩，而你得病了就不该出现在公众的地方。其实西方人这样的行为也是因认知受限，而诉诸暴力的不法之徒更是蔑视人权。</p>
<p>这次疫情在欧美的迅速蔓延终于让西方意识到新冠病毒不只属于亚洲人，他们原先冷眼旁观，以为白种人可以刀枪不入。甚至欧美的不少医学专家初期都低估了这个疫情的风险，从意大利大意失荆州，到英国的“群体免疫”，再到美国的全线沦陷，在一定程度上都和他们对这个病毒的有限认知有关，说难听点就是无知。因此政府不敢与普通民众的认知相左，轻易做出封城的决定。医学界本身也存在完全对立的看法，直到伦敦帝国理工学院流行病专家尼尔·弗格森团队的研究报告做出了令人恐惧的预测之后，英美两国政府才改变被动的应对策略。这份研究报告警告，如果英美两国不积极应对，英国将会有超过50万的人死亡，而美国将有220万人死亡。即便如此，牛津大学的研究团队在此之后还是得出截然不同的结论，认为新冠病毒在英国已经传播了一个多月，大约一半人口已经获得了实质的群体免疫能力。</p>
<p>全球在应对这个新型病毒的侵袭时，因为知识不足，做出了不少错误的判断。在疫情初期，对病毒的严重性难以做出正确的判断，在获得人传人的证据之后才被迫做出武汉封城的决定。但同时也因为认知不足，人的见识有限，影响了我们应对病毒的策略。东亚地区有“非典”的惨重教训就极为重视，西方民众对新冠病毒的认知则不同，完全放任。</p>
<p>我们的见识常常受限于我们的生活经历和环境，但我们不可能亲临其境去认知每一件事物，因此获取全面的信息就变得至关重要。不幸的是我们因防火墙无法获得客观的信息，因处在同温层里拒绝不同的信息，更不要说我们因缺乏透明度难以接收真实的信息。</p>
<h2 id="我们缺乏透明度">我们缺乏透明度</h2>
<p>回首往事，不少人都低估了疫情的危害！但是，在疫情还没有开始蔓延时，如果做到信息公开透明，如果吹哨人不被劝诫、警告、和惩罚，或许新冠肺炎全球大流行的历史会改写。许多在武汉不该发生的事一定不会发生，武汉的牺牲就不会这么大，中国百姓的牺牲也就不会这么大。</p>
<p>从中国最早处理新冠肺炎的不当做法，到世界卫生组织迟迟未对全球发出最高级别的警告，到欧美各国的迟缓应对行动，都和缺乏透明度有关联。这次疫情如此迅猛扩散的第一责任人当然是武汉当局、湖北当局，他们对公众隐瞒信息甚至掩盖真相，引发了民众的不信任，国际社会不少人甚至怀疑中国的死亡率造假。中国最为受伤的就是因封锁和隐瞒信息，导致疫情的控制受到延误，遭到国际社会诟病、排斥和指责。武汉封城之后，中国的经济和民生受到重创的举措和牺牲也因此大打折扣，对中国的负面影响其实刚刚浮现。</p>
<p>美国政客在中国疫情最严重的时刻，颇有隔岸观火的看客心态。特朗普为了选举，为了股市不下跌，不影响经济，就是不愿承认疫情迟早会冲击美国。他本以为关闭了来往中国的航线，切断了来自中国的人流就万事大吉了。他还不让邮轮上受感染的游客在美国下船，就是要制造美国本土病毒感染者很低的假象。但这样的做法和一切以稳定为首要的考虑有何区别呢？在疫情终于席卷美国之后，他也是不断大事化小，尽量降低疫情所带来的冲击和影响，甚至在感染人数还在不断攀升时竟然表示美国的经济活动在复活节就可以恢复正常！所幸美国有独立的媒体，在白宫可以直接和总统公开叫板，不让政府传播的不实消息当道。在白宫记者会上，美国媒体公开质疑特朗普的抗疫政策不当，当场质问总统为何不停地使用“中国病毒”这样的歧视性字眼。</p>
<p>早在1月20日，当我确认这将是一场公共卫生灾难时，我就第一时间在我的朋友圈里转发了管轶教授对疫情的“悲观”看法。但他的科学分析在内地被视为耸人听闻，有人甚至借他的“逃跑说”对他进行人身攻击，但正是这样客观的信息才有助于我们了解事实真相，了解这一公共卫生危机已经去到了多么危险的境地！其实在发生类似新冠肺炎这样的危机时，面对太多的不确定性，要阻止谣言，信息的透明就显得尤为重要。</p>
<p>除了刻意隐瞒信息，还有虚假资讯泛滥。全球数百名科学家2月上旬出席日内瓦“世卫论坛”，讨论新型冠肺炎疫情，学者就感叹他们不得不面对两条战线作战，除了应付病毒大流行，还要应付虚假资讯大泛滥 ，而应对虚假资讯泛滥比抗疫本身还艰难。网上流传最广最快的往往就是耸人听闻的假消息和渲染成见的看法，这些不实的信息，有恶意造谣，有断章取义，导致非理性的反应和恐慌，甚至制造混乱和分化。世卫顾问隆基尼（Ira Longini）和香港大学医学院院长梁卓伟曾提及全球三分之二的人口有可能感染新冠病毒，但网上的信息都忽略了“如果传播未加抑制”的假设，特意将最坏的可能性无限放大，引起不必要的恐慌。</p>
<p>在任何一场公共危机发生的时候，政府是不可能靠屏蔽信息来阻止危机的蔓延。恰恰相反，这只会造成危机的进一步恶化。即便在上个世纪的苏联时代，对切尔诺贝利核泄露的隐瞒最终给人类带来了一场世纪大灾难，更何况我们已经身处社交媒体如此发达的时代！</p>
<p>面对全球疫情大流行，信息披露和信息对称有助于我们了解不同地域，在不同的文化和背景下的不同应对策略和措施。不管是对疫情的判断，还是应对疫情的方法，各国都有不同的理解和做法，相互之间不仅不该嘲笑，反而应该借鉴。我们因条件限制无法获得全面的信息，但至少可以换位思考，从他者的角度看问题，避免幸灾乐祸的看客心理。</p>
<h2 id="我们缺乏同理心">我们缺乏同理心</h2>
<p>疫情爆发之后，各国不仅有不同的认知过程，而且在获得相同的认知之后所采取的应对也并不相同。武汉封城的消息传出之后，西方的反应也是两极，有称这样的举措是流行病专家的天堂，而这只有在威权国家才能实现，民主国家只能羡慕。但也有一些西方国家看到中国面临的困境，在疫情刚刚爆发时，也带有事不关己高高挂起、甚至幸灾乐祸看笑话的心态来看待中国的抗疫，还把病毒与中国的国民性和低劣文化相联系。</p>
<p>各国抗疫的做法离不开其体制、文化、历史等因素。在中国，一声令下，举国体制立马见效，整个国家有如一部机器，全力抗灾，所有其它事情都要靠边站，甚至做出牺牲，包括在“准战争”状态下个体的权利和自由，其它病人可否受到正常的医疗救助，都不是最重要的考虑。事实证明，这样的牺牲确实巨大，但这一抗疫历史上未曾经历过的举措，一座上千万人口的大城市被封城两个月的战略最终是奏效的。</p>
<p>中国的牺牲阻止了疫情蔓延，可歌可泣。即便如此，可圈可点之处也多如牛毛，野蛮作业的现象也并非个别。中国人不喜欢美国指手画脚，那别的国家难道就喜欢中国这么做？一些自媒体对别国状况一知半解，充满无知、偏见和轻蔑，非要说人家不会抄作业。看看东邻日本，和韩国的做法也不同，连大面积的检测也没做，情况也不算太坏！日本的人口密度还超过中国！但日本人平时的生活和卫生习惯，你又了解多少？其实就是华人社会的香港、澳门、台湾、新加坡等地的处理方式都不同，当中新加坡的所谓“佛系”防疫措施相当成功让不少人大跌眼镜。</p>
<p>新加坡从“重灾区”到“模范生”，表面上看去似乎选择了“佛系”的抗疫策略，曾引来不少怀疑、甚至嘲笑。新加坡防疫成功是有原因的，其策略可以概括为：最快反应、最早防范、最有系统、最严惩罚、最少折腾、最缺恐慌。新加坡一度是仅次于中国病例第二高的国家，同时人口稠密，还是国际交通枢纽。但新加坡政府反应迅速且效率高，最早限制来自中国的人流，并实施了对不同人群的休假令和居家隔离令。“非典”之后建立起来的疫情警报系统立即派上用场。新加坡国家传染病中心集先进的检测、治疗与实验研究为一体，马上研发并合作生产了快速病毒检试剂，有健全的检测体系，保证了疑似患者尽快得到治疗，避免了疫情的传播，加强了民众的信心。新加坡缺乏口罩生产能力，不鼓励大家戴口罩，但政府还是快速购买了五百万个口罩派发到每家每户，安抚民众。新加坡有充足的医疗资源，类似于中国的发热门诊就有873个，相当于北京发热门诊的11倍。我很早在朋友圈里就转发相关的信息看好新加坡的做法，甚至比香港还成功，没有发生香港排长队争口罩、抢厕纸的“奇观”。但话说回来，香港的恐慌是基于香港曾在2003年“非典”时曾遭重创的惨痛历史，以及香港和内地每天有大量的人员来往这一事实。</p>
<p>韩国这次的抗疫模式在西方更是受到肯定，法国总统和瑞典首相等多国政要甚至致电韩国讨教。但韩国对疫情的控制到底有何魅力？为何西方愿意到韩国取经和复制韩国模式呢？韩国也曾面对与中国相同的困境，但两国在大范围发生疫情之后，采取了类似的抗疫战略，新增病例曲线迅速被压平。但西方在看韩国的经验时，特别看重韩国没有因疫情出现压制言论和信息受阻的现象，没有因禁令影响民众的行动和自由，国家的经济更没有受到太大的冲击。韩国的经验可以归结为：早干预、早准备、早检测、早跟踪、早隔离、早观察。韩国的企业早就判断病毒迟早会扩散到韩国，第一时间就研发出检测试剂盒，获得政府的紧急审批投放市场，检测过程只需十分钟，几小时内可以出结果，准确率超过98%。韩国单日可检测近两万人，检测率全球之冠，已有120多个国家争相从韩国进口测试盒。韩国政府还迅速修订法律，网站和手机都可以追踪病发者，一旦有新病例，就可以获得信息和警报。</p>
<p>好的经验当然可以抄，可以借鉴，但不必过分地显耀自己的成功，这只会让人反感。己所不欲，勿施于人。现在中国不准外国人入境，这是因为中国不能再冒第二次疫情失控的风险，于情于理都不是自私自利。同样，疫情爆发初期，香港、新加坡、意大利、美国等地对中国人封关、撤侨也是同理，人家也同样不愿意看到疫情蔓延，为何那时就可以攻击别人是恶意制造恐慌，是对中国背后插上一刀呢？美国在欧洲疫情严重之后也禁止欧洲人前往美国，最后连英国这个小兄弟也进了入境限制名单。日本现在对包括中国、韩国、美国、欧洲在内的国民入境都采取十四日隔离的政策。疫情初期，中国民众对日本的态度发生了180度的大转弯，曾经被我们骂得一无是处的大和民族似乎对中国很友好、很善良，向中国捐赠各类物资，而对美国政府的表现极为不满。其实抛开美国民间和企业的资助不提，为何一定就要期待和中国正在打贸易战的特朗普政府对你友好呢？而对中国最早锁国的是朝鲜、俄罗斯、越南等国！</p>
<p>在疫情袭击的恐惧中，我们更不可以幸灾乐祸地嘲笑别人的行为，透过渲染别国的疫情失控来展现自己的英明和伟大，而忘记了自己并没有走出险境。美国和意大利的报纸上密密麻麻的讣告，看去令人悲伤和沉重，恰恰彰显了人性的一面。中国不少媒体将意大利和美国医院中的尸体的照片无限渲染，而失去亲人的武汉人前去领取骨灰盒，为了正常的悼念发出的哀思和照片却消失了。我们当中总有人不愿正视自己的创伤，不可忍受将苦难、悲剧和丑恶呈现在他们面前的人，将读者高达五千万的“日记”视为恶毒、无耻，却又如此钟情地展示“纽约医院尸满为患”、“纽约穷人疫情之下被迫乘坐地铁上班”、“英国政府勒令医生封口”这样的文字和照片。广东一个企业老板竟然建议厂家做假测温枪卖给美国，让感染者越来越多，辽宁有餐厅门外贴出横幅祝贺美日疫情扩散，就不单单是没有同理心了，而是无知的反人类言论。</p>
<p>如果我们可以同样毫无顾虑地拷问自己，犹如如此心安理得地对他人提出质疑，我们的心智就一定不会萎缩，我们兴许也就有了希望。如今，我们甚至无法正常地伸出舌头，道出自己的甜酸苦辣，又何必如此居高临下，带着幸灾乐祸的病态，刻意营造似是而非的场景，来彰显那虚幻的优越感？！但我总是固执地坚信，一个人、一个国家、一个民族只要勇于承担起苦难中的责任，最终一定是会得到别人的理解和赞许的。</p>
<h2 id="我们缺乏担当">我们缺乏担当</h2>
<p>在这次疫情中最常听到的一个字就是甩锅，这场“甩锅大战”从武汉封城的那一刻开始就不断上演，从当地的医疗机构，到各级政府官员，到中国疾病控制中心，大家都在问，疫情失控和蔓延的责任在谁？</p>
<p>中国在“非典”之后耗资11亿，搭建了全球最大的传染病疫情和突发公共卫生事件网络直报系统，过去15年间持续监测39种法定传染病。这个全球最快速的疫情上报系统，可以在短短两小时内将疫情上达北京，中国最高的疾病防疫专家在2019年曾经表示中国绝不会重演“非典”悲剧。但话音刚落，这个耗费巨资的系统并没有在这次病毒蔓延中发挥功效。或许我们永远都无法知道真相，但有一点很清楚，专业判断在明哲保身、没有承担的官僚系统中被冷冻了，生命的价值也同样在个人权力的棋盘上被抛之脑后。</p>
<p>这场疫情最大的讽刺是，全球最大的两个经济体在面对这场世界公共卫生大危机时，竟然上演了一出极为相似的闹剧。几乎每天陪同特朗普在白宫见记者的美国传染病首席专家福西不谄媚权贵，不介意道出与他旁边的总统立场不同的看法，其独立的专业精神不受政治的左右，但他的专业判断也同样被美国总统束之高阁。疫情在中国蔓延恶化之时，美国的科学家就发出警告，但美国疾病防疫中心、美国食品和药物管理局、美国卫生和公共服务部似乎都没有看到采取行动的紧迫性，更何况美国总统特朗普本人了。特朗普向来蔑视科学和专业的意见，联邦政府被一群科学怀疑论者把持。而特朗普就喜欢看极右的福克斯电视台，曾与中国同行舌战的女主播Trish Regan就鼓吹疫情是民主党的阴谋，而特朗普本人就是一个阴谋论者。他同样不信任主流媒体，不停地和主流媒体在白宫记者会上唇枪舌剑，甚至当众侮辱记者。特朗普也不重视来自情报机关的报告，警告疫情的严重性被中国低估和隐瞒，以及疫情将会蔓延全球。此外，特朗普对玩政治的兴趣多过抗疫，为了竞选就是不愿承认疫情迟早会冲击美国，他对疫情轻描淡写的原因也是因为民主党主政的纽约州、加州、华盛顿州受到重创，但共和党的红州并未受到太大的影响。纽约时报在3月28日刊登万字文，以“美国错失的一个月”为题，分析了美国因检测技术落后，法规不配套，白宫领导无方，政府官僚作风，导致美国失去了疫情防控的黄金30天。</p>
<p>美国的科技和医疗发达，美国的医疗开支占GDP的比例最高，达到了近18%，但美国至今的表现为何令人大跌眼镜？无法早期进行检测是疫情蔓延的元凶，美国疾病防控中心也不是不作为，但为何会发生这样灾难性的失误呢？这和欧美社会对新冠肺炎的轻视有相当大的关联。中国在修正了前期隐瞒疫情的错误之后，武汉封城的快速行动，为整个国际社会控制疫情争取了难得的宝贵时间。随后东亚各国和地区也纷纷采取行动，大体上都取得一定的成效，制止了新冠病毒的蔓延。遗憾的是，由于对疫情的认知存在极大的偏差，欧美国家都没有及时采取适当的应对措施，欧洲和美国先后演变成疫情的重灾区。此次疫情的另一个中心意大利，也只不过停飞了前往中国的航班。而美国早在1月3日就获得了中国的通报， 但美国和其它欧洲国家一样一直心态超然，觉得自己远隔重洋，“非典”只在东亚流行，便以为此次新冠肺炎也同样会局限在东亚地区。</p>
<p>而疫情在美国开始蔓延后，这场“甩锅”大战竟然也蔓延到国际社会，中美两国爆发了令人捧腹的唇枪舌战。中国外交部的新任发言人在推特上怀疑美军在武汉播毒，特朗普亲自上阵，恶意地称新冠肺炎为“中国病毒”。病毒起源地的争论凸显了各方意图透过“甩锅”来推卸应有的责任，其实起源地何罪之有？而美国国务卿蓬佩奥在特朗普改口之后，还坚持要将武汉病毒写进七大工业国外长的公报里，而被其它国家拒绝。美国自己浪费了一个多月的时间，疫情失控，特朗普却只会将矛头转移，掩盖自己抗疫能力的失误！更为严重的是，“中国病毒”经过他的大嘴巴，在推特里一天又一天地在说，传遍全球，造成了美国等地歧视亚裔人的犯罪上升。美国联邦调查局的一项全新研究，警告全美针对亚裔人的仇恨犯罪案件数目，因新型冠状病毒疫情的扩散而飙升，危及美国的亚裔社群。连新加坡总理李显龙在接受美国有线电视新闻网CNN采访的时候，不仅感慨美国失去了领导世界战疫的能力，而且惊叹这两个世界大国竟然可以如此低水平地进行“口水战”。</p>
<p>从亚洲到欧洲到美洲，昔日繁忙的大都会因这场疫情，生活已经停顿。这场疫情不仅暴露了我们制度的缺陷、系统的脆弱、和人性的罪恶，全球已经跌入新一轮的金融市场大动荡和全球经济大衰退，但不幸的是，我们不仅没有进行反思，却依旧在那里自我陶醉和自我撕裂！</p>
<h2 id="我们缺乏反思">我们缺乏反思</h2>
<p>一场史无前例的病毒大流行正向全球各个角落冲撞，死亡笼罩着这个星球。但面对这场突如其来的天灾，其中多少人祸是可以避免的呢？</p>
<p>封口vs封城：围绕着这场人道危机的争论焦点从一开始就从这里展开。如果没有发生“封口”事件，新冠肺炎的蔓延是否会有另一个结局？我们无法知道答案，但我们知道至少不会如此惨烈。问题在于一个经济如此发达的国度，为何依旧无法实现一个开放社会所需要的基本条件；一个自信的社会为何难以拉响危机来临的警报声。而这并非个别和单一现象，这有如隐藏在我们社会中的毒瘤和顽疾，总是如此粗暴地压制善意的提醒和批评。</p>
<p>在危机抵达临界点之后义无反顾的“封城”行动，尽管惨烈，却也是迫不得已的孤注一掷，但我们并非事事都一定要以牺牲个体的代价来实现宏大的目标，文明是体现在对每一个生命的关怀上的。“封口”可以令一个民族、一个国家在全球失去信用和信任，即便在“封城”的巨大牺牲之后，受感染和死亡的官方的数据还是被质疑。扪心自问，为何中国常常成为这类被怀疑的目标与对象？一个真正开放的社会，和一个透明度高的社会，一定可以勇敢地面对真相并向大众提供真相。所幸，在疫情重击下，中国也出现了难得一见的媒体松绑现象。</p>
<p>另一方面，西方也常常从固有的认知出发，用有色眼镜看待中国的“封城”行动。在这场抗疫中，与东亚各地在武汉“封城”之后迅速进入作战状态完全不同，欧美各国不仅负面看待中国的“封城”行动，而且没有从中国的“封城”行动中嗅出危机的严重程度。</p>
<p>傲慢vs自大：这让我们再次活生生地看到了傲慢与无知，欧美各国普遍将最初在武汉出现的新病毒归结为黄种人的病。日本副首相兼财务大臣麻生太郎2月份曾在G20财长的一次会议上主动表示援助意大利和西班牙，却自讨没趣，欧洲国家非常不屑。意大利副总理后来在G7财政会议上更直截了当地表示，这是黄种人才会得的病，和他们西方人没有关系。无怪乎，意大利一度成为中国之外感染者最多的国家。特朗普的傲慢与自大终于在疫情横扫美国之后，被迫承认美国将面对比第二次世界大战还要惨重的死亡。</p>
<p>然而与西方的傲慢相对应的则是在中国自媒体的世界里无时不在的自大，在那里你只有看到中国成了全球抗疫的英雄和救世主，所有的悲剧都活脱脱地变成了赞歌的素材，而忘记了病毒是从武汉开始向全国和全球蔓延的。这样的自大在中国抗疫初现曙光之后，更是变成了对他国肆无忌惮的嘲笑。而最新的对象就是感染新冠肺炎人数最多的美国，却忘记了美国拥有强大的科技力量和发达的医疗体系，仅ICU（重症监护室）的床位数量就远远超过中国。而“傲慢”与“自大”这对孪生兄弟却拥有一个共同点：偏见。</p>
<p>吃野味vs戴口罩：在有关病毒源头的吃野味文化，以及防止病毒扩散的戴口罩文化的讨论中，我们也看到了类似的偏见。2003年“非典”之后中国人的确没有从中吸取惨痛的教训，及时关闭野味市场，不少人因而将此次病毒的爆发与中国人喜爱吃野味的文化联系在一起。这样的看法有其道理，中国人是时候改变吃野味的生活习俗。有趣的是，中国网民反而找出了纽约上流社会吃野味的视频，一时之间在朋友圈中疯传，证明美国人不过是五十步笑百步。不过这几年比较严重的传染病，包括中东呼吸综合症和甲型H1N1流感病毒并非源自中国。</p>
<p>另一方面，亚洲人戴口罩以防止病毒扩散基本是共识。但西方人，即便是生活在亚洲的西方人也不喜欢戴口罩。在西方，视口罩为病人标志的观念还带来了对亚裔人的歧视。在欧美各国生活的亚裔人处在戴口罩被歧视，不带口罩怕染上病毒的天人交战中。但在这次疫情重击欧美之后，戴口罩抵抗病毒的认知终于慢慢开始在欧美被接受了。</p>
<p>自媒体vs主流媒体（赞美vs批评）：在疫情的报道上，中国的主力军是自媒体，不管是赞歌，还是批评，自媒体带有更多的主观性和情绪性。而在许多其它地方，报道疫情的主力是主流媒体，力求客观。特别是美国媒体，其角色是监督政府，且喜欢监督全世界的政府，多数又是自由主义倾向，所以特朗普也反感美国主流媒体。但只有在美国这个国家，CBS记者胆敢在白宫怒怼总统为何要使用歧视性的“中国病毒”；NBC的记者质问特朗普吹捧效果未经证实的抗疫药物是否给美国人虚假的希望，并指美国数百万人活于恐惧中；纽约时报驻京记者张彦（Ian Johnson ）的“观点”文章，指出中国为美国赢得了时间却被美国白白浪费了；纽约时报的社论公开谴责特朗普政府官员的言词加剧了对亚裔的种族仇恨。</p>
<p>中国自媒体里那个发自纽约的抗疫日记，作者声称其素材全部取自美国媒体的公开报道，而非道听途说，语带双关。的确，当纽约成为美国的武汉时，我每天在美国电视新闻上看到的几乎全是“负面”消息。每一个活生生的人离开人世时的凄惨故事；病人因缺乏医疗设备无法获得及时医治的悲剧；医务人员面对死亡威胁战斗在第一线几乎崩溃的场面；停留在街边装满尸体的冰冻车和医院走廊里运尸袋的场景；质问白宫何时可以确保医疗设备运抵现场的愤怒；受到病毒感染威胁下美国海军官兵的呼吁；失去工作的普通人无法交付房贷的忧虑。在这里你看到的是恐惧，是担忧，是悲伤，在这里你听不到任何赞歌。</p>
<p>威权vs民主：这次全球抗疫的叙事已经成为中国模式和西方模式之争，甚至上升到威权还是民主体制在抗疫中哪个更有成效的争论，但不少人却忘记了无论何种体制都有其成功与失败的经验与教训。在欧洲成为重灾区之后，德国的死亡率却一直很低，这或许与日耳曼民族的自律有关。在亚洲处于恐慌的时候，日本并没有跟随中国封城、没有跟随韩国大面积检测，但也没有像欧美发达国家那样失控，这或许与大和民族的自律和生活习惯有关。如果将抗疫简单地看成是中国体制的胜利，那么韩国、日本、新加坡、香港、台湾等地又是何种体制？无疑，中国自上而下的动员力量，让全球看到了中国体制战胜疫情的超强能力，但自下而上的公民社会的应变和调整能力在纽约成为疫情重灾区之后，同样令人刮目相看。</p>
<p>纽约在中央公园、体育场迅速建起方舟医院，并加快对受感染疑似人员的检测。来自全美的六万多名医务人员主动报名成为自愿者，自发前往纽约支援人手不足的医院，“捷蓝”航空免费载送这些医护人员“上战场”，酒店免费提供住宿，企业慷慨捐赠急需的防护用品和医疗设备，但没有企业对这些行动发稿、做公关、高调宣传。即便美国总统面对新冠肺炎的反应丑态百出，但这个国家所幸不是一个人说的算，受疫情影响最大的纽约州、加州、华盛顿州都不理睬他的狂言妄语。而美国的体制也决定了联邦政府对州一级政府的事务不可干涉，即便特朗普想对纽约和临近的两个州“封城”，但纽约州州长公开反对，使得特朗普不得不放弃这一想法。特朗普随心所欲，疫情还未控制，就要求复活节恢复经济运作，但疾病专家和媒体则公开和他唱对台戏。因此，应对病毒需要在一个自下而上的公民社会里，民众敢于承担公民应有的责任和义务。</p>
<p>在全球面对这场前所未有的大灾难时，我们需要理性地思考人类的失误和失败，而非指责和推卸。这场大灾难离落幕之日还有漫漫长路，但这场天灾与人祸也给人类提供了一次难得的反思机会。在这场疫情结束之后，或许全球终将明白这不是“中国病毒”，是各国必须共同面对的“世界病毒”，病毒恰恰因我们人类的傲慢、自大、和自私而四处肆虐。在这个全球化被污名化的时代，尽管国与国的界线依旧分明，但病毒绝不会只在一国的边境线内停留。我们比以往任何时候都更需要有全球的视野和全球的胸怀，我们必须学会如何合作去共同应对前所未有的挑战。</p>
<p>庚子年常常是灾难之年，但或许也是转折之年。在新冠病毒横扫全球之后，这不应该是我们重拾孤立的时刻，而是通向一个不一样的全球化新时代的新起点。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Centos服务器conda环境配置脚本]]></title>
        <id>https://sunyanhust.github.io/post/centos-fu-wu-qi-conda-huan-jing-pei-zhi-jiao-ben/</id>
        <link href="https://sunyanhust.github.io/post/centos-fu-wu-qi-conda-huan-jing-pei-zhi-jiao-ben/">
        </link>
        <updated>2020-04-04T14:11:21.000Z</updated>
        <content type="html"><![CDATA[<h2 id="说明">📃说明</h2>
<p>本脚本主要包括以下几个功能：</p>
<ol>
<li>从清华源自动下载anaconda并安装</li>
<li>配置pip国内源为阿里源</li>
<li>配置conda源为ustc(这一步有疑问，因为conda源经常会不可用，需要经常性测试)</li>
<li>自动创建tf14环境 安装cudnn和cuda以及pytorch 自动测试GPU环境是否可用</li>
<li>自动创建tf20环境 安装cudnn和cuda以及pytorch 自动测试GPU环境是否可用</li>
</ol>
<h2 id="code">💾Code</h2>
<pre><code class="language-shell">yum install -y bzip2

# download anaconda and install
echo &quot;download anaconda and install&quot;
wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.3.1-Linux-x86_64.sh
sh Anaconda3-5.3.1-Linux-x86_64.sh -u

source ~/.bashrc

# change pip source to aliyun
echo &quot;change pip source to aliyun&quot;

if [ ! -d &quot; ~/.pip/&quot; ];then
mkdir  ~/.pip
else
echo &quot;pip existed&quot;
fi

cat&gt;~/.pip/pip.conf&lt;&lt;EOF
[global]
index-url = http://mirrors.aliyun.com/pypi/simple/
[install]
trusted-host=mirrors.aliyun.com
EOF

# change anaconda source to ustc
echo &quot;change anaconda source to ustc&quot;
cat&gt;~/.condarc&lt;&lt;EOF 
channels:
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
  - https://mirrors.ustc.edu.cn/anaconda/cloud/menpo/
  - https://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/
  - https://mirrors.ustc.edu.cn/anaconda/cloud/msys2/
  - https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/
  - https://mirrors.ustc.edu.cn/anaconda/pkgs/free/
  - https://mirrors.ustc.edu.cn/anaconda/pkgs/main/
  - defaults
show_channel_urls: true
EOF

#gpu test file
cat&gt;gpu_test.py&lt;&lt;EOF
import os
import tensorflow as tf
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
if tf.test.gpu_device_name():
    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))
    print('Your tensorflow-gpu is available')
else:
    print('Your tensorflow-gpu is not available')
    print(&quot;Please install GPU version of TF&quot;)
import torch
if torch.cuda.is_available():
    print('Default GPU Device: {}'.format(torch.cuda.get_device_name()))
    print('Your pytorch-gpu is available')
else:
    print('Your pytorch-gpu is not available')
    print(&quot;Please install GPU version of Pytorch&quot;)
EOF

# creat tf14 env 
echo &quot;creating tf14 env&quot;
conda create -n tf14 python=3.7 -y
conda activate tf14

conda install tensorflow-gpu==1.14.0 -y
pip install torch torchvision -U
pip install numpy==1.15.4

python gpu_test.py

# creat tf20 env
echo &quot;creating tf20 env&quot;
conda create -n tf20 python=3.7 -y
conda activate tf20

conda install tensorflow-gpu==2.0.0 -y
pip install torch torchvision -U
pip install numpy==1.15.4

python gpu_test.py
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Keras指定显卡并限制显存使用（tensorflow后端）]]></title>
        <id>https://sunyanhust.github.io/post/keras-zhi-ding-xian-qia-bing-xian-zhi-xian-cun-shi-yong-tensorflow-hou-duan/</id>
        <link href="https://sunyanhust.github.io/post/keras-zhi-ding-xian-qia-bing-xian-zhi-xian-cun-shi-yong-tensorflow-hou-duan/">
        </link>
        <updated>2020-04-02T04:08:55.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>本文转载自<a href="https://zhuanlan.zhihu.com/p/65218239">知乎</a></p>
</blockquote>
<p>Keras使用显卡时是默认调用所有的GPU，并且占满所有显存的，所以就很有必要搞清楚Keras如何指定GPU和如何限制显存的使用比例了。</p>
<h2 id="指定某块gpu">📒指定某块GPU</h2>
<p>指定GPU很简单，在载入keras和tensorflow之前，设置CUDA计算使用的GPU序号即可。这其实是CUDA本身的参数，对所有深度学习框架都是适用的。需要注意的是最好写在<code>improt keres</code> 和 <code>import tensorflow</code>之前，不然可能出错。</p>
<pre><code class="language-python">import os
os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;1&quot;
</code></pre>
<p>此代码选择的是编号为“1”的显卡。显卡的编号是从“0”开始的，若只有一块显卡则编号为“0”。</p>
<h2 id="指定多块gpu">📒指定多块GPU</h2>
<p>指定多块GPU的方式和前文完全一致，只需要多写几个编号即可：</p>
<pre><code class="language-python">import os
os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] =  &quot;0, 2&quot;
</code></pre>
<p>此时选择的是编号为“0”和编号为“2”的显卡</p>
<h2 id="控制gpu显存使用比例">📒控制GPU显存使用比例</h2>
<p>Keras是默认占满GPU显存的，我们通过重设backend的gpu_memory_fraction来进行调节，0.3表示占用30%的显存：</p>
<pre><code class="language-python">import tensorflow as tf
from keras.backend.tensorflow_backend import set_session
config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.3
set_session(tf.Session(config=config))
</code></pre>
<p>不过虽然配置了GPU显存的占用比例，实际运行中若不够用的话还是获取更多的显存。比方说如果运行了3个设置为30%显存的应用，实际上是可能超过100%造成显存不足的。</p>
<h2 id="指定gpu控制显存使用">📒指定GPU+控制显存使用</h2>
<p>将指定GPU与控制显存使用比例合并操作即可：</p>
<pre><code class="language-python">import os
os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;1&quot;
import tensorflow as tf
from keras.backend.tensorflow_backend import set_session
config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.3
set_session(tf.Session(config=config))
</code></pre>
<p>该代码实现的是指定编号为“1”的GPU，并设置占用显存的比例为30%。</p>
<h2 id="显存的按需分配动态增长">📒显存的按需分配（动态增长）</h2>
<p>如果并不清楚自己的应用分配多少的显存比例合适，可以使用按需分配的方式，也就是动态增长allow_growth：</p>
<pre><code class="language-python">import os
os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;1&quot;
import tensorflow as tf
from keras.backend.tensorflow_backend import set_session
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
set_session(tf.Session(config=config))
</code></pre>
<p>该代码实现的是指定编号为“1”的GPU，并设置占用显存的方式为按需增长。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[服务器使用screen后台运行程序]]></title>
        <id>https://sunyanhust.github.io/post/fu-wu-qi-shi-yong-screen-hou-tai-yun-xing-cheng-xu/</id>
        <link href="https://sunyanhust.github.io/post/fu-wu-qi-shi-yong-screen-hou-tai-yun-xing-cheng-xu/">
        </link>
        <updated>2020-04-01T12:49:31.000Z</updated>
        <content type="html"><![CDATA[<ol>
<li>安装screen：<code>yum install -y screen</code></li>
<li>确认远程服务器是否安装screen：screen -v</li>
<li>启动screen 会话：<code>screen -S train</code>，会话名字为train。这个时候会切换到新的会话终端，在里面运行我们想要的程序。</li>
<li>切换返回： <code>ctrl+a+d</code></li>
<li>查看运行中的screen会话：<code>screen -ls</code></li>
<li>看到对应的id后，重新登录会话,，这里假设id为774：<code>screen -r 774</code>，如果登录不上，使用<code>screen -D -r 774</code> 先踢掉前一用户，再登陆。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[华为面试]]></title>
        <id>https://sunyanhust.github.io/post/hua-wei-mian-shi/</id>
        <link href="https://sunyanhust.github.io/post/hua-wei-mian-shi/">
        </link>
        <updated>2020-03-09T13:28:53.000Z</updated>
        <content type="html"><![CDATA[<pre><code class="language-python">
</code></pre>
<pre><code class="language-python">def eval(input_str):
    op1 = ('+','-')
    op2 = ('*','/')
    
    temp = []
    result = 0
    num = &quot;&quot;
    for s in input_str:
        if s not in op1 and s not in op2:
           num = num + s
        else:
            temp.append(int(num))
            temp.append(s)
            num = &quot;&quot;
    temp.append(int(num))

    print(temp)

    run = False
    temp1 = []
    for i, d in enumerate(temp):
        if run:
            run = False
            continue
        if d not in op2:
           temp1.append(d)
        else:
            if d == '*':
                r = temp1[-1] * temp[i+1]
            else:
                r = int(temp1[-1] / temp[i+1])
            temp1.pop()
            temp1.append(r)
            run = True
    print(temp1)

    run = False
    temp2 = []
    for i, d in enumerate(temp1):
        if run:
            run = False
            continue
        if d not in op1:
           temp2.append(d)
        else:
            if d == '+':
                r = temp2[-1] + temp1[i+1]
            else:
                r = temp2[-1] - temp1[i+1]
            temp2.pop()
            temp2.append(r)
            run = True
    print(temp2)

    result = temp2[0]
    return result

if __name__ == &quot;__main__&quot;:
    str = &quot;10+5*3/2-7*2+1&quot;
    print(eval(str))
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[NLP面试]]></title>
        <id>https://sunyanhust.github.io/post/nlp-mian-shi/</id>
        <link href="https://sunyanhust.github.io/post/nlp-mian-shi/">
        </link>
        <updated>2020-03-07T04:14:52.000Z</updated>
        <content type="html"><![CDATA[<h2 id="深度学习和nlp">深度学习和NLP</h2>
<h3 id="过拟合欠拟合偏差方差正则化-交叉验证">过拟合欠拟合，偏差方差，正则化， 交叉验证</h3>
<figure data-type="image" tabindex="1"><img src="https://s2.ax1x.com/2020/03/07/3jyaLQ.png" alt="3jyaLQ.png" loading="lazy"></figure>
<ol>
<li>
<p><strong>怎么判断过拟合， 过拟合如何处理</strong><br>
定义：过拟合（overfitting）是指在模型训练中由于训练数据包含抽样误差，对抽样误差也进行了很好的拟合。<br>
表现：模型在训练集上效果好，在测试集上效果差（相差20%以上），模型泛化能力弱。<br>
原因：（1）观察值与真实值存在偏差。（2）训练数据不足，数据太少，导致无法描述问题的真实分布。（3）训练模型过度，导致模型非常复杂。<br>
处理方法：（1）数据层面上，增加数据或者数据增广 （2）模型层面，主要是降低模型的复杂度：减少数据特征，L1，L2，Droupout，BN，集成学习，早期停止策略 ，使用简单的模型</p>
</li>
<li>
<p><strong>怎么判断欠拟合， 欠拟合如何处理</strong><br>
定义：欠拟合（underfitting）是指模型无法得到较低的训练误差。<br>
表现：训练的模型在训练集上面的表现很差，在验证集上面的表现也很差。<br>
原因：模型发生欠拟合的最本质原因是训练的模型太简单，最通用的特征模型都没有学习到<br>
处理方法：（1）添加新的特征 （2）减少正则化参数 （3）使用更深或者更宽的模型 （4）使用集成方法</p>
</li>
</ol>
<p><img src="https://s2.ax1x.com/2020/03/07/3jc2VJ.png" alt="3jc2VJ.png" loading="lazy"><br>
3. <strong>偏差和方差的定义，为什么要在两者之间进行权衡</strong><br>
偏差（Bias）表示模型输出与真实值之间的误差，刻画模型的准确度，方差（Variance）表示模型在训练集和验证集之间的误差，刻画模型的稳定性。<br>
在一个实际系统中，Bias与Variance往往是不能兼得的。如果要降低模型的Bias，就一定程度上会提高模型的Variance，反之亦然。造成这种现象的根本原因是，我们总是希望试图用有限训练样本去估计无限的真实数据。当我们更加相信这些数据的真实性，而忽视对模型的先验知识，就会尽量保证模型在训练样本上的准确度，这样可以减少模型的Bias。但是，这样学习到的模型，很可能会失去一定的泛化能力，从而造成过拟合，降低模型在真实数据上的表现，增加模型的不确定性。相反，如果更加相信我们对于模型的先验知识，在学习模型的过程中对模型增加更多的限制，就可以降低模型的variance，提高模型的稳定性，但也会使模型的Bias增大。因此通常需要在两者之间权衡。</p>
<ol start="4">
<li>
<p>L1和L2正则化的区别，为什么L1可以获得稀疏解，L2解接近于0？<br>
L1正则化就是在loss function后边所加正则项为L1范数，加上L1范数容易得到稀疏解（0比较多）。L2正则化就是loss function后边所加正则项为L2范数的平方，加上L2正则相比于L1正则来说，得到的解比较平滑（不是稀疏），但是同样能够保证解中接近于0（但不是等于0，所以相对平滑）的维度比较多，降低模型的复杂度。</p>
</li>
<li>
<p>word2vec如何实现，实现方法有什么区别</p>
</li>
<li>
<p>基于业务的问答系统如何设计</p>
</li>
<li>
<p>如何训练基于知识图谱的问答系统</p>
</li>
<li>
<p>在训练KBQA时会用到例如freebase这样的开源知识图谱，他们过大的体积在训练中要如何进行优化</p>
</li>
<li>
<p>基于匹配的问答系统的关键技术是什么（文本相似度匹配）</p>
</li>
<li>
<p>文本相似度匹配有哪些实现方法（转特征求距离，或者使用自然语言推理的模型）</p>
</li>
<li>
<p>开放式的对话系统如何训练</p>
</li>
<li>
<p>transformer和RNN的区别</p>
</li>
<li>
<p>推荐系统了解吗，有那两部分（召回和排序）</p>
</li>
<li>
<p>怎么抓取热门</p>
</li>
<li>
<p>召回有哪些（微博召回怎么做），排序算法了解吗</p>
</li>
<li>
<p>小样本数据集怎么做</p>
</li>
<li>
<p>样本不均衡怎么搞（重点考核损失函数优化）</p>
</li>
<li>
<p>AUC的具体含义</p>
</li>
<li>
<p>介绍推荐系统的召回和排序系统，召回系统的输出是什么</p>
</li>
<li>
<p>RF和GBDT介绍、RF的属性采样时有放回还是不放回</p>
</li>
<li>
<p>手写LSTM的公式（手画LSTM图）</p>
</li>
<li>
<p>lightgbm对缺失值的处理方法</p>
</li>
<li>
<p>kmeans的K值确定方法</p>
</li>
<li>
<p>FM（factorization machine）模型的公式写一下，模型解决了什么问题</p>
</li>
<li>
<p>DIN（deep interest network）主要使用了什么机制，解释一下，画一下DIN的框图</p>
</li>
<li>
<p>DIN的activation unit的作用</p>
</li>
<li>
<p>一个模型的bais和variance的具体定义是什么，bais和variance哪个比较重要，为什么是trade-off<br>
任何机器学习算法的预测误差可以分解为三部分，即：偏差+方差+不可约的误差（对于给定的模型，我们不能进一步减少的误差）。</p>
</li>
<li>
<p>泛化误差解释（bais^2+variance+noise）</p>
</li>
<li>
<p>dropout的工作机制，dropout在训练过程如何使用</p>
</li>
<li>
<p>聚类算法了解程度、kmeans介绍、K值选择、kmeans++算法)</p>
</li>
<li>
<p>推荐系统还有融合框架，假如通过两种不同的召回和ranking系统得到结果，如何在两种备选结果中最终给用户推荐出最适合的十个广告</p>
</li>
<li>
<p>XGBOOST ，LGB，GBDT 的区别</p>
</li>
<li>
<p>一阶优化器，二阶优化器</p>
</li>
<li>
<p>Attention怎么做，self-attention怎么做</p>
</li>
<li>
<p>Transformer细节，Bert细节（多头和缩放）</p>
</li>
<li>
<p>标签平滑怎么做的</p>
</li>
<li>
<p>交叉熵，相对熵</p>
</li>
<li>
<p>Bagging, boosting , 偏差，方差关系<br>
二者都是集成学习算法，都是将多个弱学习器组合成强学习器的方法。<br>
Bagging：从原始数据集中每一轮有放回地抽取训练集，训练得到k个弱学习器，将这k个弱学习器以投票的方式得到最终的分类结果。<br>
Boosting：每一轮根据上一轮的分类结果动态调整每个样本在分类器中的权重，训练得到k个弱分类器，他们都有各自的权重，通过加权组合的方式得到最终的分类结果。</p>
</li>
<li>
<p>CRF理论与代码实现细节, CRF与HMM关系，区别</p>
</li>
<li>
<p>维特比，beam-search 时间复杂度，区别</p>
</li>
<li>
<p>XGBOOST ，LGB 生长策略，分类策略</p>
</li>
<li>
<p>少样本情况怎么缓解</p>
</li>
<li>
<p>实际场景做softmax很容易出现下溢问题, 怎么解决<br>
可以用每个维度减去一个固定值</p>
</li>
<li>
<p>正则项为什么能减缓过拟合</p>
</li>
<li>
<p>过拟合解决方法，正则项为什么能减缓过拟合, 权重衰减等价于哪个正则项</p>
</li>
<li>
<p>随机森林的随机体现在哪里</p>
</li>
<li>
<p>tm和rnn的区别</p>
</li>
<li>
<p>LR和svm的区别是什么</p>
</li>
<li>
<p>lstm的优点，记忆单元是怎么工作的，他为什么可以克服梯度消失</p>
</li>
<li>
<p>bp的原理</p>
</li>
<li>
<p>bn的原理</p>
</li>
<li>
<p>解释一下AUC的计算方法和它代表的意义。问了一个相关的问题，当时没有答的很好，就是一个数据如果分成两份，分别在两份数据上计算出AUC为AUC_1和AUC_2，问整体数据的AUC是多少？面试的时候一直以为这个是能算出来的，所以一直在推导公式。最后的答案其实是无法得到，因为从局部的有序无法直接退出全局的有序，这个题目其实还是考查对于AUC这个指标的理解深度。</p>
</li>
<li>
<p>word2vec的两种优化方法，说下分层softmax是怎么做的。word2vec的优点和缺点，是如何解决oov的问题的，实际上word2vec如何使用</p>
</li>
<li>
<p>lucene搜索</p>
</li>
<li>
<p>关键字搜索如何实现</p>
</li>
<li>
<p>单元测试。</p>
</li>
<li>
<p>深度优先和广度优先的本质区别。</p>
</li>
<li>
<p>从搜谷歌到返回页面，发生了什么。</p>
</li>
<li>
<p>batchsize大或小有什么问题, LR怎么设置</p>
</li>
</ol>
<h2 id="计算机网络">计算机网络</h2>
<ol>
<li>TCP和UDP的区别<br>
1、TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接<br>
2、TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付<br>
3、TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP是面向报文的UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等<br>
4、每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信<br>
5、TCP首部开销20字节;UDP的首部开销小，只有8个字节<br>
6、TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道</li>
<li>线程和进程的区别，如何实现多线程；</li>
<li>L1范数能否去除冗余特征</li>
<li>没坐标怎么做kmeans</li>
<li>决策树的特征和神经网络特征有什么差异</li>
<li>句子向量有哪些生成方式</li>
<li>词袋模型有哪些不足的地方<br>
稀疏，无序，纬度爆炸, 每个词都是正交的，相当于每个词都没有关系。</li>
<li>albert相对于bert的改进</li>
<li>稀疏词向量 用skip-gram还是cbow训练好</li>
<li>word2vec  两种训练方式哪种更好？对生僻词谁更好？</li>
<li>在工程中什么样的结果会表明是over fitting/under fitting</li>
<li>对于CNN 卷积层、和池化层的物理意义是什么, 对于池化的max方法和mean方法 分别适合针对什么情况下应用？<br>
当feature map中的信息都具有一定贡献的时候使用AvgPooling，比如网络走到比较深的地方，这个时候特征图的H W都比较小，包含的语义信息较多，这个时候再使用MaxPooling就不太合适了.反之为了减少无用信息的影响时用maxpool，比如网络浅层常常见到maxpool，因为开始几层对图像而言包含较多的无关信息。二者的具体使用场景只有在具体任务上观察，实际效果炼丹后才知道。</li>
<li>L2正则化的penalize term和先验有关系嘛？如有是什么样的关系</li>
<li>树模型怎么剪枝？如何处理缺失值？</li>
<li>讲讲Glove的原理，它和Word2vec有什么区别？Fasttext说一下</li>
<li>画一下ELMo的模型图，讲一下ELMo的原理，为什么它能解决词歧义的问题？</li>
<li>画Bert的模型图，讲原理，预训练的过程。Bert输入是由哪些组成的？Bert相比于ELMo有什么优点？它是怎么用作下游任务的？</li>
<li>Attention机制的原理，常用的Attention计算相似度方式有哪些，写一下公式。</li>
<li>有分布式训练神经网络的经验吗？多卡跑模型的命令是什么</li>
<li>简述一种中文分词算法。</li>
<li>讲一下Hessian矩阵？ Hessian矩阵是对称矩阵吗？</li>
<li>SVM的优化函数讲一下？</li>
<li>聚类算法了解吗？DBSCAN讲一下</li>
</ol>
<h2 id="机器学习">机器学习</h2>
<ol>
<li>Xgboost的原理介绍以及如何并行化实现</li>
<li>生成模型和判别模型（SVM、LR属于哪种）</li>
</ol>
<h2 id="python">Python</h2>
<ol>
<li>Python的装饰器, 迭代器和生成器<br>
装饰器的功能：在不修改原函数及其调用方式的情况下对原函数功能进行扩展<br>
装饰器的本质：就是一个闭包函数<br>
迭代器就是用于迭代操作的的对象，遵从迭代协议（内部实现了__iter__()和__next__()方法，可以像列表（可迭代对象，只有__iter__()方法）一样迭代获取其中的值，与列表不同的是，构建迭代器的时候，不像列表一样一次性把数据加到内存，而是以一种延迟计算的方式返回元素，即调用next方法时候返回此值。<br>
生成器本质上也是一个迭代器，自己实现了可迭代协议，与迭代器器不同的是生成器的实现方式不同，可以通过生成器表达式和生成器函数两种方式实现，代码更简洁。生成器和迭代器都是惰性可迭代对象，只能遍历一次，数据取完抛出Stopiteration异常<pre><code class="language-python">#生成器函数（带yield语句）
def gen():
    yield 3
#生成器表达式（类似列表推导式）
gen=(x for x in range(1,5))
</code></pre>
</li>
<li>Python中的Lambda函数</li>
<li>Python回调</li>
<li>python中函数self的区别，读取一个txt文件中2.5是什么数据类型，2.5+2.5等于多少</li>
<li>深拷贝和浅拷贝的区别</li>
<li>线程进程的区别, python内部实现的多线程有什么问题</li>
<li>Python2和Python3 map的差别<br>
Python3 map函数返回一个迭代器, Python2中返回一个列表。</li>
<li>Python可变数据类型和不可变数据类型分别有哪些？<br>
可变数据类型：列表list和字典dict。<br>
不可变数据类型：整型int、浮点型float、字符串型string和元组tuple。</li>
<li>Python是如何进行内存管理的<br>
Python采用的是基于值的内存管理方式，如果为不同变量赋值相同值，则在内存中只有一份该值，多个变量指向同一块内存地址</li>
</ol>
<h2 id="linux基础">Linux基础</h2>
<ol>
<li>AWK</li>
<li>nohup</li>
</ol>
<p>##代码</p>
<ol>
<li>最长回文子串</li>
<li>给你10亿数据，不重复，求前k大。（n为10亿，k为2亿）</li>
<li>给你1000个数组，求最长的等差数列</li>
<li>TopK（快排和小顶堆分别实现，分析时间和空间复杂度）</li>
<li>分析插入和快排的时间和空间复杂度，稳定，不稳定？稳定排序和不稳定排序算法的定义？手写快排</li>
<li>LR的随机梯度实现</li>
<li>数组的最大和，数组的最大乘积</li>
<li>数组排成最大的数字</li>
<li>数据中出现空值处理的方法</li>
<li>给定一个矩阵，在矩阵中选取一行，求取某一行某个数附近的5个数的值，需要用哪种数据结构（KD树）</li>
<li>二叉树的最短路径</li>
<li>给定10G的文件，只有2G的内存，如何将文件放到内存中</li>
<li>编辑距离</li>
<li>完全二叉树的节点个数</li>
<li>二叉树的前序遍历的递归和非递归、时间复杂度</li>
<li>15分钟 写一个k-means，没写完时间不够</li>
<li>打家劫舍II</li>
<li>反转链表</li>
<li>用神经网络搭建一个LR</li>
<li>如果有很大的文件，怎么统计文件里面出现的各个单词的数量</li>
<li>用两个栈实现一个队列</li>
<li>o(n)实现三色排序</li>
<li>有一个城市名称列表，如何判断语句中是否出现了列表中的城市(KMP)</li>
<li>手写tfidf</li>
<li>二叉树层次遍历</li>
<li>大数加法 大数相乘</li>
<li>二叉树之子型遍历，每行打印</li>
<li>数组，可以分别从最左边最右边取个数字，求取得k个数的最大值，O（1）空间呢，k的取值范围的条件</li>
<li>k个的列表反转</li>
<li>对称二叉树</li>
<li>连续数组，给定k，求连续数组最小区间。动态规划要优化时间，贪心法需要证明。</li>
<li>圆上三点组成锐角三角形概率</li>
<li>cnn的卷积计算，参数计算。</li>
<li>倒水问题</li>
<li>最长公共子序列</li>
<li>最大上升子序列</li>
<li>旋转数组找K值</li>
<li>蓄水池抽样算法（Reservoir Sampling）</li>
<li>跳台阶+有一次后退机会</li>
<li>排序二叉树 插入新数字</li>
<li>归并排序中的归并</li>
<li>给定一个int数组，求数组中能组成三角形的个数。</li>
<li>数组中索引K前面是有序的，K之后也是有序的，调整使得整个数组有序，要求空间复杂度O(1)</li>
<li>有1,2,5,10,20,50的纸币，求凑到100元一共有多少种方法</li>
<li>合并两个有序链表，合并K个有序链表</li>
<li>顺时针打印矩阵</li>
</ol>
<h2 id="智力题">智力题</h2>
<ol>
<li>2个蜡烛1个小时，如何记录15分钟</li>
<li>只有01生成器，如何生成 0-3等概率，如何生成 0-k等概率（模拟二进制）</li>
<li>ABCD乘以9等于DCBA，那么ABCD各等于几？</li>
</ol>
<p>反转链表</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[NLP常用模型和数据集高速下载]]></title>
        <id>https://sunyanhust.github.io/post/nlp-chang-yong-mo-xing-he-shu-ju-ji-gao-su-xia-zai/</id>
        <link href="https://sunyanhust.github.io/post/nlp-chang-yong-mo-xing-he-shu-ju-ji-gao-su-xia-zai/">
        </link>
        <updated>2020-03-05T11:23:53.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="楔子">楔子</h2>
<p>由于大部分NLP的模型和数据集都在国外，导致国内下载速度实在感人😭。好在有很多NLP的框架内置了很多数据集，都是国内链接，亲测下载速度很快，本文汇总一下一些我见到的国内链接，文末感谢这些平台提供的存储和下载服务。</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="楔子">楔子</h2>
<p>由于大部分NLP的模型和数据集都在国外，导致国内下载速度实在感人😭。好在有很多NLP的框架内置了很多数据集，都是国内链接，亲测下载速度很快，本文汇总一下一些我见到的国内链接，文末感谢这些平台提供的存储和下载服务。</p>
<!--more-->
<h2 id="正文">正文</h2>
<h3 id="模型">模型</h3>
<table>
<thead>
<tr>
<th style="text-align:center">模型</th>
<th style="text-align:center">文件名称</th>
<th style="text-align:center">下载链接</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>bert-base-cased</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/bert-base-cased.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>bert-base-chinese</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/bert-base-chinese.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>bert-base-uncased</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/bert-base-uncased.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>bert-chinese-wwm-ext</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/bert-chinese-wwm-ext.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center">BERT</td>
<td style="text-align:center"><code>bert-chinese-wwm</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/bert-chinese-wwm.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>bert-large-cased-wwm</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/bert-large-cased-wwm.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>bert-large-cased</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/bert-large-cased.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>bert-large-uncased-wwm</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/bert-large-uncased-wwm.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>bert-large-uncased</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/bert-large-uncased.zip">下载</a></td>
</tr>
</tbody>
</table>
<h3 id="数据集">数据集</h3>
<table>
<thead>
<tr>
<th style="text-align:center">数据集</th>
<th style="text-align:center">文件名称</th>
<th style="text-align:center">下载链接</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">中文情感分析</td>
<td style="text-align:center"><code>ChnSentiCorp</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/chnsenticorp.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">语义相似度</td>
<td style="text-align:center"><code>LCQMC</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/lcqmc.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">问答匹配</td>
<td style="text-align:center"><code>NLPCC_DPQA</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/nlpcc-dbqa.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">中文命名实体识别</td>
<td style="text-align:center"><code>MSRA_NER</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/msra_ner.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">英文多标签分类数据集</td>
<td style="text-align:center"><code>Toxic</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/toxic.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">抽取式英文阅读理解</td>
<td style="text-align:center"><code>SQUAD</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/squad.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">抽取式中文阅读理解</td>
<td style="text-align:center"><code>CMRC2018</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/cmrc2018.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">抽取式繁体阅读理解</td>
<td style="text-align:center"><code>DRCD</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/drcd.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">英文数据集集合</td>
<td style="text-align:center"><code>GLUE</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/glue_data.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">跨语言自然语言推理</td>
<td style="text-align:center"><code>XNLI</code></td>
<td style="text-align:center"><a href="%22https://bj.bcebos.com/paddlehub-dataset/XNLI-lan.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">今日头条中文新闻短文本分类</td>
<td style="text-align:center"><code>TNews</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/tnews.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">互联网情感分析</td>
<td style="text-align:center"><code>INews</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/inews.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">智能客服中文问句匹配</td>
<td style="text-align:center"><code>BQ</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/bq.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">中文长文本分类</td>
<td style="text-align:center"><code>IFLYTEK</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/iflytek.tar.gz">下载</a></td>
</tr>
<tr>
<td style="text-align:center">中文长文本分类</td>
<td style="text-align:center"><code>THUCNEWS</code></td>
<td style="text-align:center"><a href="https://bj.bcebos.com/paddlehub-dataset/thucnews.tar.gz">下载</a></td>
</tr>
</tbody>
</table>
<h3 id="词向量">词向量</h3>
<table>
<thead>
<tr>
<th style="text-align:center">词向量</th>
<th style="text-align:center">文件名称</th>
<th style="text-align:center">下载链接</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>glove.6B.50d</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/glove.6B.50d.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>glove.6B.100d</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/glove.6B.100d.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center">GloVe</td>
<td style="text-align:center"><code>glove.6B.200d</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/glove.6B.200d.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>glove.6B.300d</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/glove.6B.300d.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>glove.42B.300d</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/glove.42B.300d.zip">下载</a></td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"><code>glove.840B.300d</code></td>
<td style="text-align:center"><a href="http://212.129.155.247/embedding/glove.840B.300d.zip">下载</a></td>
</tr>
</tbody>
</table>
<h2 id="感谢">感谢</h2>
<ul>
<li>fastnlp提供的模型和词向量，<a href="https://docs.qq.com/sheet/DVnpkTnF6VW9UeXdh?tab=BB08J2&amp;c=D22A0I0">more</a> 😘</li>
<li>paddlehub提供的数据集, <a href="https://github.com/PaddlePaddle/PaddleHub/wiki/PaddleHub-API:-Dataset">more</a>😘</li>
</ul>
<h2 id="tips">Tips</h2>
<p>如果还有其他的国外文件需要下载，国内下载很慢，可以尝试使用kaggle的notebook先下载到kaggle，然后再下载到本地，亲测有效😄。</p>
]]></content>
    </entry>
</feed>