<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://sunyanhust.github.io</id>
    <title>Gridea</title>
    <updated>2020-04-18T21:05:53.250Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://sunyanhust.github.io"/>
    <link rel="self" href="https://sunyanhust.github.io/atom.xml"/>
    <subtitle>æ¸©æ•…è€ŒçŸ¥æ–°</subtitle>
    <logo>https://sunyanhust.github.io/images/avatar.png</logo>
    <icon>https://sunyanhust.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, Gridea</rights>
    <entry>
        <title type="html"><![CDATA[çŸ¥è¯†ç‚¹å¤‡å¿˜]]></title>
        <id>https://sunyanhust.github.io/post/zhi-shi-dian-bei-wang-he-todo/</id>
        <link href="https://sunyanhust.github.io/post/zhi-shi-dian-bei-wang-he-todo/">
        </link>
        <updated>2020-04-16T03:02:25.000Z</updated>
        <content type="html"><![CDATA[<h2 id="æ¯”è¾ƒçç¢çš„çŸ¥è¯†">æ¯”è¾ƒçç¢çš„çŸ¥è¯†</h2>
<ul>
<li>è”æƒ³å°æ–°æ˜¯å¼€æœºæŒ‰F2è¿›å…¥bios</li>
<li>windowsä¸Šç¼–è¾‘çš„shæ–‡ä»¶åœ¨linuxä¸Šéœ€è¦è½¬æ¢ï¼Œè½¬æ¢è½¯ä»¶ä¸º<code>doc2unix</code>ï¼Œå‘½ä»¤ä¸º<code>doc2unix filename</code></li>
<li>GPUæœºå™¨ä¹‹é—´æ‹·è´æ–‡ä»¶ç›´æ¥scpåŠ ä¸Šæœºå™¨çš„ipåœ°å€å°±å¯ä»¥ï¼Œå› ä¸ºå„ä¸ªæœºå™¨åœ¨åŒä¸€å±€åŸŸç½‘å†…</li>
</ul>
<h2 id="æ–‡æœ¬åˆ†ç±»kaggle-kernel">æ–‡æœ¬åˆ†ç±»kaggle kernel</h2>
<h3 id="åŸºäºlstmçš„å¤šæ ‡ç­¾æ–‡æœ¬åˆ†ç±»">åŸºäºLSTMçš„å¤šæ ‡ç­¾æ–‡æœ¬åˆ†ç±»</h3>
<p>kaggle kernel é“¾æ¥ï¼š https://www.kaggle.com/rftexas/gru-lstm-rnn-101</p>
<p><strong>ä¸»è¦äº®ç‚¹</strong>ï¼š</p>
<ol>
<li>ä½¿ç”¨äº†tf.kerasè¿›è¡Œæ„å»ºï¼Œå¾ˆå¤šä»£ç å¯ä»¥å¤ç”¨ä¸ºbaseline</li>
<li>è¯»å–å’ŒåŠ è½½Gloveè¯å‘é‡</li>
<li>AUCä½œä¸ºè¯„ä»·æ ‡å‡†</li>
<li>æ•°æ®é›†å¤„ç†ä¸ºtf_datasetè¾“å…¥kerasæ¨¡å‹</li>
<li>åœ¨è®­ç»ƒé›†è®­ç»ƒåï¼Œåœ¨éªŒè¯é›†ç»§ç»­è®­ç»ƒä¸¤ä¸ªepochsï¼ˆå°æŠ€å·§ï¼Œå¯èƒ½å¾ˆæœ‰ç”¨ï¼‰</li>
</ol>
<pre><code class="language-python">import gc
import pickle
import re
import string
import warnings

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf
from keras.preprocessing.sequence import pad_sequences
from keras.preprocessing.text import Tokenizer
from tensorflow.keras import backend as K
from tensorflow.keras.losses import binary_crossentropy
from tensorflow.keras import initializers, regularizers, constraints
from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping
from tensorflow.keras.layers import Layer, Dense, Input, Embedding, SpatialDropout1D, Bidirectional, LSTM, \
    GlobalMaxPooling1D, GlobalAveragePooling1D
from tensorflow.keras.layers import concatenate
from tensorflow.keras.models import Model
from tqdm.notebook import tqdm

tqdm.pandas()

warnings.simplefilter('ignore')

# HYPERPARAMETERS
MAX_LEN = 220
MAX_FEATURES = 100000
EMBED_SIZE = 600
BATCH_SIZE = 128
N_EPOCHS = 5
LEARNING_RATE = 8e-4

# We will concatenate Crawl and GloVe embeddings
CRAWL_EMB_PATH = '../input/pickled-glove840b300d-for-10sec-loading/glove.840B.300d.pkl'
GLOVE_EMB_PATH = '../input/pickled-crawl300d2m-for-kernel-competitions/crawl-300d-2M.pkl'


def display_training_curves(training, validation, title, subplot):
    &quot;&quot;&quot;
    Quickly display training curves
    &quot;&quot;&quot;
    if subplot % 10 == 1:
        plt.subplots(figsize=(10, 10), facecolor='#F0F0F0')
        plt.tight_layout()

    ax = plt.subplot(subplot)
    ax.set_facecolor('#F8F8F8')
    ax.plot(training)
    ax.plot(validation)
    ax.set_title('model' + title)
    ax.set_ylabel(title)
    ax.set_xlabel('epoch')
    ax.legend(['train', 'valid'])


def get_coeffs(word, *arr):
    return word, np.asarray(arr, dtype='float32')


def load_embeddings(embed_dir):
    with open(embed_dir, 'rb') as  infile:
        embeddings = pickle.load(infile)
        return embeddings


def build_embedding_matrix(word_index, embeddings_index, max_features, lower=True, verbose=True):
    embedding_matrix = np.zeros((max_features, 300))
    for word, i in tqdm(word_index.items(), len=(word_index.items())):
        if lower:
            word = word.lower()
        if i &gt;= max_features: continue
        try:
            embedding_vector = embeddings_index[word]
        except:
            embedding_vector = embeddings_index[&quot;unknown&quot;]
        if embedding_vector is not None:
            # words not found in embedding index will be all-zeros.
            embedding_matrix[i] = embedding_vector
    return embedding_matrix


def build_matrix(word_index, embeddings_index):
    embedding_matrix = np.zeros((len(word_index) + 1, 300))
    for word, i in word_index.items():
        try:
            embedding_matrix[i] = embeddings_index[word]
        except:
            embedding_matrix[i] = embeddings_index[&quot;unknown&quot;]
    return embedding_matrix


class Attention(Layer):
    &quot;&quot;&quot;
    Custom Keras attention layer
    Reference: https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043
    &quot;&quot;&quot;

    def __init__(self, step_dim, W_regularizer=None, b_regularizer=None,
                 W_constraint=None, b_constraint=None, bias=True, **kwargs):

        self.supports_masking = True

        self.bias = bias
        self.step_dim = step_dim
        self.features_dim = None
        super(Attention, self).__init__(**kwargs)

        self.param_W = {
            'initializer': initializers.get('glorot_uniform'),
            'name': '{}_W'.format(self.name),
            'regularizer': regularizers.get(W_regularizer),
            'constraint': constraints.get(W_constraint)
        }
        self.W = None

        self.param_b = {
            'initializer': 'zero',
            'name': '{}_b'.format(self.name),
            'regularizer': regularizers.get(b_regularizer),
            'constraint': constraints.get(b_constraint)
        }
        self.b = None

    def build(self, input_shape):
        assert len(input_shape) == 3

        self.features_dim = input_shape[-1]
        self.W = self.add_weight(shape=(input_shape[-1],),
                                 **self.param_W)

        if self.bias:
            self.b = self.add_weight(shape=(input_shape[1],),
                                     **self.param_b)

        self.built = True

    def compute_mask(self, input, input_mask=None):
        return None

    def call(self, x, mask=None):
        step_dim = self.step_dim
        features_dim = self.features_dim

        eij = K.reshape(
            K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))),
            (-1, step_dim))

        if self.bias:
            eij += self.b
        eij = K.tanh(eij)
        a = K.exp(eij)

        if mask is not None:
            a *= K.cast(mask, K.floatx())

        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())
        a = K.expand_dims(a)
        weighted_input = x * a
        return K.sum(weighted_input, axis=1)

    def compute_output_shape(self, input_shape):
        return input_shape[0], self.features_dim


# We create a balanced

print('Loading train sets...')
train1 = pd.read_csv(&quot;/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv&quot;)
train2 = pd.read_csv(&quot;/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv&quot;)

train = pd.concat([
    train1[['comment_text', 'toxic']],
    train2[['comment_text', 'toxic']].query('toxic==1'),
    train2[['comment_text', 'toxic']].query('toxic==0').sample(n=100000, random_state=0)
])

del train1, train2

print('Loading validation sets...')
valid = pd.read_csv('/kaggle/input/val-en-df/validation_en.csv')

print('Loading test sets...')
test = pd.read_csv('/kaggle/input/test-en-df/test_en.csv')
sub = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv')

misspell_dict = {&quot;aren't&quot;: &quot;are not&quot;, &quot;can't&quot;: &quot;cannot&quot;, &quot;couldn't&quot;: &quot;could not&quot;,
                 &quot;didn't&quot;: &quot;did not&quot;, &quot;doesn't&quot;: &quot;does not&quot;, &quot;don't&quot;: &quot;do not&quot;,
                 &quot;hadn't&quot;: &quot;had not&quot;, &quot;hasn't&quot;: &quot;has not&quot;, &quot;haven't&quot;: &quot;have not&quot;,
                 &quot;he'd&quot;: &quot;he would&quot;, &quot;he'll&quot;: &quot;he will&quot;, &quot;he's&quot;: &quot;he is&quot;,
                 &quot;i'd&quot;: &quot;I had&quot;, &quot;i'll&quot;: &quot;I will&quot;, &quot;i'm&quot;: &quot;I am&quot;, &quot;isn't&quot;: &quot;is not&quot;,
                 &quot;it's&quot;: &quot;it is&quot;, &quot;it'll&quot;: &quot;it will&quot;, &quot;i've&quot;: &quot;I have&quot;, &quot;let's&quot;: &quot;let us&quot;,
                 &quot;mightn't&quot;: &quot;might not&quot;, &quot;mustn't&quot;: &quot;must not&quot;, &quot;shan't&quot;: &quot;shall not&quot;,
                 &quot;she'd&quot;: &quot;she would&quot;, &quot;she'll&quot;: &quot;she will&quot;, &quot;she's&quot;: &quot;she is&quot;,
                 &quot;shouldn't&quot;: &quot;should not&quot;, &quot;that's&quot;: &quot;that is&quot;, &quot;there's&quot;: &quot;there is&quot;,
                 &quot;they'd&quot;: &quot;they would&quot;, &quot;they'll&quot;: &quot;they will&quot;, &quot;they're&quot;: &quot;they are&quot;,
                 &quot;they've&quot;: &quot;they have&quot;, &quot;we'd&quot;: &quot;we would&quot;, &quot;we're&quot;: &quot;we are&quot;,
                 &quot;weren't&quot;: &quot;were not&quot;, &quot;we've&quot;: &quot;we have&quot;, &quot;what'll&quot;: &quot;what will&quot;,
                 &quot;what're&quot;: &quot;what are&quot;, &quot;what's&quot;: &quot;what is&quot;, &quot;what've&quot;: &quot;what have&quot;,
                 &quot;where's&quot;: &quot;where is&quot;, &quot;who'd&quot;: &quot;who would&quot;, &quot;who'll&quot;: &quot;who will&quot;,
                 &quot;who're&quot;: &quot;who are&quot;, &quot;who's&quot;: &quot;who is&quot;, &quot;who've&quot;: &quot;who have&quot;,
                 &quot;won't&quot;: &quot;will not&quot;, &quot;wouldn't&quot;: &quot;would not&quot;, &quot;you'd&quot;: &quot;you would&quot;,
                 &quot;you'll&quot;: &quot;you will&quot;, &quot;you're&quot;: &quot;you are&quot;, &quot;you've&quot;: &quot;you have&quot;,
                 &quot;'re&quot;: &quot; are&quot;, &quot;wasn't&quot;: &quot;was not&quot;, &quot;we'll&quot;: &quot; will&quot;, &quot;tryin'&quot;: &quot;trying&quot;}


def _get_misspell(misspell_dict):
    misspell_re = re.compile('(%s)' % '|'.join(misspell_dict.keys()))
    return misspell_dict, misspell_re


def replace_typical_misspell(text):
    misspellings, misspellings_re = _get_misspell(misspell_dict)

    def replace(match):
        return misspellings[match.group(0)]

    return misspellings_re.sub(replace, text)


puncts = [',', '.', '&quot;', ':', ')', '(', '-', '!', '?', '|', ';', &quot;'&quot;, '$', '&amp;', '/', '[', ']',
          '&gt;', '%', '=', '#', '*', '+', '\\', 'â€¢', '~', '@', 'Â£', 'Â·', '_', '{', '}', 'Â©', '^',
          'Â®', '`', '&lt;', 'â†’', 'Â°', 'â‚¬', 'â„¢', 'â€º', 'â™¥', 'â†', 'Ã—', 'Â§', 'â€³', 'â€²', 'Ã‚', 'â–ˆ',
          'Â½', 'Ã ', 'â€¦', 'â€œ', 'â˜…', 'â€', 'â€“', 'â—', 'Ã¢', 'â–º', 'âˆ’', 'Â¢', 'Â²', 'Â¬', 'â–‘', 'Â¶',
          'â†‘', 'Â±', 'Â¿', 'â–¾', 'â•', 'Â¦', 'â•‘', 'â€•', 'Â¥', 'â–“', 'â€”', 'â€¹', 'â”€', 'â–’', 'ï¼š', 'Â¼',
          'âŠ•', 'â–¼', 'â–ª', 'â€ ', 'â– ', 'â€™', 'â–€', 'Â¨', 'â–„', 'â™«', 'â˜†', 'Ã©', 'Â¯', 'â™¦', 'Â¤', 'â–²',
          'Ã¨', 'Â¸', 'Â¾', 'Ãƒ', 'â‹…', 'â€˜', 'âˆ', 'âˆ™', 'ï¼‰', 'â†“', 'ã€', 'â”‚', 'ï¼ˆ', 'Â»', 'ï¼Œ', 'â™ª',
          'â•©', 'â•š', 'Â³', 'ãƒ»', 'â•¦', 'â•£', 'â•”', 'â•—', 'â–¬', 'â¤', 'Ã¯', 'Ã˜', 'Â¹', 'â‰¤', 'â€¡', 'âˆš']


def clean_text(x):
    x = str(x)
    for punct in puncts + list(string.punctuation):
        if punct in x:
            x = x.replace(punct, f' {punct} ')
    return x


def clean_numbers(x):
    return re.sub(r'\d+', ' ', x)


def preprocess(train, valid, test, tfms):
    for tfm in tfms:
        print(tfm.__name__)
        train['comment_text'] = train['comment_text'].progress_apply(tfm)
        valid['comment_text_en'] = valid['comment_text_en'].progress_apply(tfm)
        test['content'] = test['content'].progress_apply(tfm)

    return train, valid, test


tfms = [replace_typical_misspell, clean_text, clean_numbers]
train, valid, test = preprocess(train, valid, test, tfms)

tokenizer = Tokenizer(num_words=MAX_FEATURES, filters='', lower=False)

print('Fitting tokenizer...')
tokenizer.fit_on_texts(list(train['comment_text']) + list(valid['comment_text_en']) + list(test['content_en']))
word_index = tokenizer.word_index

print('Building training set...')
X_train = tokenizer.texts_to_sequences(list(train['comment_text']))
y_train = train['toxic'].values

print('Building validation set...')
X_valid = tokenizer.texts_to_sequences(list(valid['comment_text_en']))
y_valid = valid['toxic'].values

print('Building test set ...')
X_test = tokenizer.texts_to_sequences(list(test['content_en']))

print('Padding sequences...')
X_train = pad_sequences(X_train, maxlen=MAX_LEN)
X_valid = pad_sequences(X_valid, maxlen=MAX_LEN)
X_test = pad_sequences(X_test, maxlen=MAX_LEN)

y_train = train.toxic.values
y_valid = valid.toxic.values

del tokenizer

print('Loading Crawl embeddings...')
crawl_embeddings = load_embeddings(CRAWL_EMB_PATH)

print('Loading GloVe embeddings...')
glove_embeddings = load_embeddings(GLOVE_EMB_PATH)

print('Building matrices...')
embedding_matrix_1 = build_matrix(word_index, crawl_embeddings)
embedding_matrix_2 = build_matrix(word_index, glove_embeddings)

print('Concatenating embedding matrices...')
embedding_matrix = np.concatenate([embedding_matrix_1, embedding_matrix_2], axis=1)

del embedding_matrix_1, embedding_matrix_2
del crawl_embeddings, glove_embeddings

gc.collect()

train_dataset = (
    tf.data.Dataset
        .from_tensor_slices((X_train, y_train))
        .repeat()
        .shuffle(2048)
        .batch(BATCH_SIZE)
)

valid_dataset = (
    tf.data.Dataset
        .from_tensor_slices((X_valid, y_valid))
        .batch(BATCH_SIZE)
        .cache()
)

test_dataset = (
    tf.data.Dataset
        .from_tensor_slices(X_test)
        .batch(BATCH_SIZE)
)


def build_model(word_index, embedding_matrix, verbose=True):
    &quot;&quot;&quot;
    credits go to: https://www.kaggle.com/thousandvoices/simple-lstm/
    &quot;&quot;&quot;
    sequence_input = Input(shape=(MAX_LEN,), dtype=tf.int32)

    embedding_layer = Embedding(*embedding_matrix.shape,
                                weights=[embedding_matrix],
                                trainable=False)

    x = embedding_layer(sequence_input)
    x = SpatialDropout1D(0.3)(x)
    x = Bidirectional(LSTM(256, return_sequences=True))(x)
    x = Bidirectional(LSTM(128, return_sequences=True))(x)

    att = Attention(MAX_LEN)(x)
    avg_pool1 = GlobalAveragePooling1D()(x)
    max_pool1 = GlobalMaxPooling1D()(x)
    hidden = concatenate([att, avg_pool1, max_pool1])

    hidden = Dense(512, activation='relu')(hidden)
    hidden = Dense(128, activation='relu')(hidden)
    out = Dense(1, activation='sigmoid')(hidden)
    model = Model(sequence_input, out)

    return model

model = build_model(word_index, embedding_matrix)
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC()])
model.summary()

file_weights = 'best_model.h5'
# cb1 = ModelCheckpoint(file_weights, save_best_only=True)

cb2 = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)
cb3 = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, cooldown=0, min_lr=0.0001)
cb4 = LearningRateScheduler(lambda epoch: LEARNING_RATE * (0.6 ** epoch))

n_steps = X_train.shape[0] // BATCH_SIZE

train_history = model.fit(
    train_dataset,
    steps_per_epoch=n_steps,
    validation_data=valid_dataset,
    callbacks=[cb4],
    epochs=N_EPOCHS
)

display_training_curves(
    train_history.history['loss'],
    train_history.history['val_loss'],
    'loss',
    211)

display_training_curves(
    train_history.history['auc'],
    train_history.history['val_auc'],
    'AUC',
    212)

n_steps = X_valid.shape[0] // BATCH_SIZE

train_history = model.fit(
    valid_dataset.repeat(),
    steps_per_epoch=n_steps,
    callbacks=[cb4],
    epochs=N_EPOCHS
)

preds = model.predict(test_dataset, verbose=1)
sub['toxic'] = preds

</code></pre>
<h3 id="åŸºäºbertçš„å¤šæ ‡ç­¾æ–‡æœ¬åˆ†ç±»ä½¿ç”¨tpu">åŸºäºBERTçš„å¤šæ ‡ç­¾æ–‡æœ¬åˆ†ç±»(ä½¿ç”¨TPU)</h3>
<p>kaggle kernel é“¾æ¥ï¼š https://www.kaggle.com/sunyancn/jigsaw-tpu-bert-with-huggingface-and-keras</p>
<p><strong>ä¸»è¦äº®ç‚¹</strong>ï¼š</p>
<ol>
<li>ä½¿ç”¨äº†transformersçš„åˆ†è¯å™¨è¿›è¡Œå¿«é€Ÿåˆ†è¯</li>
<li>æ–‡æœ¬é•¿åº¦çš„å¯è§†åŒ–</li>
<li>TF Hub BERTæ¨¡å‹çš„åŠ è½½</li>
<li>TPUç­–ç•¥</li>
</ol>
<pre><code class="language-python"># %% [markdown]
# ## About this notebook
# 
# *[Jigsaw Multilingual Toxic Comment Classification](https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification)* is the 3rd annual competition organized by the Jigsaw team. It follows *[Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)*, the original 2018 competition, and *[Jigsaw Unintended Bias in Toxicity Classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification)*, which required the competitors to consider biased ML predictions in their new models. This year, the goal is to use english only training data to run toxicity predictions on many different languages, which can be done using multilingual models, and speed up using TPUs.
# 
# Many awesome notebooks has already been made so far. Many of them used really cool technologies like [Pytorch XLA](https://www.kaggle.com/theoviel/bert-pytorch-huggingface-starter). This notebook instead aims at constructing a **fast, concise, reusable, and beginner-friendly model scaffold**. It will focus on the following points:
# * **Using Tensorflow and Keras**: Tensorflow is a powerful framework, and Keras makes the training process extremely easy to understand. This is especially good for beginners to learn how to use TPUs, and for experts to focus on the modelling aspect.
# * **Using Huggingface's `transformers` library**: [This library](https://huggingface.co/transformers/) is extremely popular, so using this let you easily integrate the end result into your ML pipelines, and can be easily reused for your other projects.
# * **Native TPU usage**: The TPU usage is abstracted using the native `strategy` that was created using Tensorflow's `tf.distribute.experimental.TPUStrategy`. This avoids getting too much into the lower-level aspect of TPU management.
# * **Use a subset of the data**: Instead of using the entire dataset, we will only use the 2018 subset of the data available, which makes this much faster, all while achieving a respectable accuracy.

# %% [code]
import os
import warnings

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ModelCheckpoint
from kaggle_datasets import KaggleDatasets
import transformers
import traitlets
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm.notebook import tqdm
from tokenizers import BertWordPieceTokenizer
from sklearn.metrics import roc_auc_score

warnings.simplefilter(&quot;ignore&quot;)

# %% [markdown]
# ## Helper Functions

# %% [code]
def fast_encode(texts, tokenizer, chunk_size=256, maxlen=512):
    tokenizer.enable_truncation(max_length=maxlen)
    tokenizer.enable_padding(max_length=maxlen)
    all_ids = []
    
    for i in tqdm(range(0, len(texts), chunk_size)):
        text_chunk = texts[i:i+chunk_size].tolist()
        encs = tokenizer.encode_batch(text_chunk)
        all_ids.extend([enc.ids for enc in encs])
    
    return np.array(all_ids)

# %% [code]
def build_model(transformer, loss='binary_crossentropy', max_len=512):
    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=&quot;input_word_ids&quot;)
    sequence_output = transformer(input_word_ids)[0]
    cls_token = sequence_output[:, 0, :]
    x = tf.keras.layers.Dropout(0.35)(cls_token)
    out = Dense(1, activation='sigmoid')(x)
    
    model = Model(inputs=input_word_ids, outputs=out)
    model.compile(Adam(lr=3e-5), loss=loss, metrics=[tf.keras.metrics.AUC()])
    
    return model

# %% [markdown]
# Cosine similarity calculates similarity by measuring the cosine of angle between two vectors. This is calculated as:
# ![](https://miro.medium.com/max/426/1*hub04IikybZIBkSEcEOtGA.png)
# 
# Cosine Similarity calculation for two vectors A and B [source]
# With cosine similarity, we need to convert sentences into vectors. One way to do that is to use bag of words with either TF (term frequency) or TF-IDF (term frequency- inverse document frequency). The choice of TF or TF-IDF depends on application and is immaterial to how cosine similarity is actually performed â€” which just needs vectors. TF is good for text similarity in general, but TF-IDF is good for search query relevance.

# %% [code]
# https://stackoverflow.com/questions/8897593/how-to-compute-the-similarity-between-two-text-documents
import nltk, string
from sklearn.feature_extraction.text import TfidfVectorizer

nltk.download('punkt') # if necessary...


stemmer = nltk.stem.porter.PorterStemmer()
remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)

def stem_tokens(tokens):
    return [stemmer.stem(item) for item in tokens]

'''remove punctuation, lowercase, stem'''
def normalize(text):
    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))

vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words='english')

def cosine_sim(text1, text2):
    tfidf = vectorizer.fit_transform([text1, text2])
    return ((tfidf * tfidf.T).A)[0,1]

# %% [markdown]
# ## TPU Configs

# %% [code]
AUTO = tf.data.experimental.AUTOTUNE

# Create strategy from tpu
tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
tf.config.experimental_connect_to_cluster(tpu)
tf.tpu.experimental.initialize_tpu_system(tpu)
strategy = tf.distribute.experimental.TPUStrategy(tpu)

# Data access
#GCS_DS_PATH = KaggleDatasets().get_gcs_path('kaggle/input/') 

# %% [markdown]
# ## Create fast tokenizer

# %% [code]
# First load the real tokenizer
tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')

# Save the loaded tokenizer locally
save_path = '/kaggle/working/distilbert_base_uncased/'
if not os.path.exists(save_path):
    os.makedirs(save_path)
tokenizer.save_pretrained(save_path)

# Reload it with the huggingface tokenizers library
fast_tokenizer = BertWordPieceTokenizer('distilbert_base_uncased/vocab.txt', lowercase=True)
fast_tokenizer

# %% [markdown]
# ## Load text data into memory

# %% [code]
train1 = pd.read_csv(&quot;/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv&quot;)
train2 = pd.read_csv(&quot;/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv&quot;)

valid = pd.read_csv('/kaggle/input/val-en-df/validation_en.csv')
test1 = pd.read_csv('/kaggle/input/test-en-df/test_en.csv')
test2 = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-test-translated/jigsaw_miltilingual_test_translated.csv')
sub = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv')

# %% [code]
test2.head()

# %% [markdown]
# ## Test dataset comparision

# %% [code]
plt.figure(figsize=(12, 8))

sns.distplot(train1.comment_text.str.len(), label='train')
sns.distplot(test1.content_en.str.len(), label='test1')
sns.distplot(test2.translated.str.len(), label='test2')
plt.legend();

# %% [code]
plt.figure(figsize=(12, 8))

sns.distplot(train1.comment_text.str.len(), label='train')
sns.distplot(test1.content_en.str.len(), label='test1')
sns.distplot(test2.translated.str.len(), label='test2')
plt.xlim([0, 512])
plt.legend();

# %% [markdown]
# Lets calculate cosine similarity two translated test datasets.

# %% [code]
test_set_similarity = [cosine_sim(t1, t2) for t1, t2 in tqdm(zip(test1.content_en, test2.translated))]

plt.figure(figsize=(12, 8))

sns.distplot(test_set_similarity);

# %% [markdown]
# ## Fast encode

# %% [code]
x_train = fast_encode(train1.comment_text.astype(str), fast_tokenizer, maxlen=512)
x_valid = fast_encode(valid.comment_text_en.astype(str), fast_tokenizer, maxlen=512)
x_test1 = fast_encode(test1.content_en.astype(str), fast_tokenizer, maxlen=512)
x_test2 = fast_encode(test2.translated.astype(str), fast_tokenizer, maxlen=512)

y_train = train1.toxic.values
y_valid = valid.toxic.values

# %% [markdown]
# ## Build datasets objects

# %% [code]
train_dataset = (
    tf.data.Dataset
    .from_tensor_slices((x_train, y_train))
    .repeat()
    .shuffle(2048)
    .batch(64)
    .prefetch(AUTO)
)

valid_dataset = (
    tf.data.Dataset
    .from_tensor_slices((x_valid, y_valid))
    .batch(64)
    .cache()
    .prefetch(AUTO)
)

test_dataset = [(
    tf.data.Dataset
    .from_tensor_slices(x_test1)
    .batch(64)
),
    (
    tf.data.Dataset
    .from_tensor_slices(x_test2)
    .batch(64)
)]

# %% [markdown]
# # Focal Loss

# %% [code]
from tensorflow.keras import backend as K

def focal_loss(gamma=2., alpha=.2):
    def focal_loss_fixed(y_true, y_pred):
        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))
        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))
        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))
    return focal_loss_fixed

# %% [markdown]
# ## Load model into the TPU

# %% [code]
%%time
with strategy.scope():
    transformer_layer = transformers.TFBertModel.from_pretrained('bert-base-uncased')
    model = build_model(transformer_layer, loss=focal_loss(gamma=1.5), max_len=512)
model.summary()

# %% [markdown]
# ## RocAuc Callback

# %% [code]
from tensorflow.keras.callbacks import Callback 

class RocAucCallback(Callback):
    def __init__(self, test_data, score_thr):
        self.test_data = test_data
        self.score_thr = score_thr
        self.test_pred = []
        
    def on_epoch_end(self, epoch, logs=None):
        if logs['val_auc'] &gt; self.score_thr:
            print('\nRun TTA...')
            for td in self.test_data:
                self.test_pred.append(self.model.predict(td))

# %% [markdown]
# # LrScheduler

# %% [code]
def build_lrfn(lr_start=0.000001, lr_max=0.000002, 
               lr_min=0.0000001, lr_rampup_epochs=7, 
               lr_sustain_epochs=0, lr_exp_decay=.87):
    lr_max = lr_max * strategy.num_replicas_in_sync

    def lrfn(epoch):
        if epoch &lt; lr_rampup_epochs:
            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start
        elif epoch &lt; lr_rampup_epochs + lr_sustain_epochs:
            lr = lr_max
        else:
            lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min
        return lr
    
    return lrfn

# %% [code]
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 7))

_lrfn = build_lrfn()
plt.plot([i for i in range(35)], [_lrfn(i) for i in range(35)]);

# %% [markdown]
# ## Train Model

# %% [code]
roc_auc = RocAucCallback(test_dataset, 0.9195)
lrfn = build_lrfn()
lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)

train_history = model.fit(
    train_dataset,
    steps_per_epoch=150,
    validation_data=valid_dataset,
    callbacks=[lr_schedule, roc_auc],
    epochs=35
)

# %% [markdown]
# ## Submission

# %% [code]
sub['toxic'] = np.mean(roc_auc.test_pred, axis=0)
sub.to_csv('submission.csv', index=False)

# %% [markdown]
# # Reference
# * [Jigsaw TPU: DistilBERT with Huggingface and Keras](https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras)
# * [inference of bert tpu model ml w/ validation](https://www.kaggle.com/abhishek/inference-of-bert-tpu-model-ml-w-validation)
# * [Overview of Text Similarity Metrics in Python](https://towardsdatascience.com/overview-of-text-similarity-metrics-3397c4601f50)
# * [test-en-df](https://www.kaggle.com/bamps53/test-en-df)
# * [val_en_df](https://www.kaggle.com/bamps53/val-en-df)
# * [Jigsaw multilingual toxic - test translated](https://www.kaggle.com/kashnitsky/jigsaw-multilingual-toxic-test-translated)
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Latexç”»ç¥ç»ç½‘ç»œå›¾]]></title>
        <id>https://sunyanhust.github.io/post/latex-hua-shen-jing-wang-luo-tu/</id>
        <link href="https://sunyanhust.github.io/post/latex-hua-shen-jing-wang-luo-tu/">
        </link>
        <updated>2020-04-12T03:56:10.000Z</updated>
        <content type="html"><![CDATA[<h2 id="bilstm">BiLSTM</h2>
<h3 id="æ•ˆæœå›¾">ğŸ¥™æ•ˆæœå›¾</h3>
<figure data-type="image" tabindex="1"><img src="https://sunyanhust.github.io/post-images/1587243946926.png" alt="" loading="lazy"></figure>
<h3 id="ä»£ç ">ğŸ“œä»£ç </h3>
<pre><code class="language-tex">\documentclass[crop, tikz]{standalone}
\usepackage{tikz}

\usetikzlibrary{positioning}

\begin{document}
\begin{tikzpicture}
	\node[rectangle] (Y0) at (0, 0) {$\dots$};
	\node[rectangle, draw, right=2em of Y0, minimum height=1cm, minimum width=1cm] (RNN) {LSTM$_\rightarrow$};
	\node[rectangle, right=of RNN, draw, minimum height=1cm, minimum width=1cm] (RNN2) {LSTM$_\rightarrow$};
	\node[rectangle, right=of RNN2, draw, minimum height=1cm, minimum width=1cm] (RNN3) {LSTM$_\rightarrow$};
			
	\node[rectangle, right= of RNN3, draw, minimum height=1cm, minimum width=1cm] (RNN4) {LSTM$_\rightarrow$};
	\node[rectangle, right=2em of RNN4] (RNN5) {$\dots$};
			
			
	\node[rectangle, above=of RNN4, draw, minimum height=1cm, minimum width=1cm] (R25) {LSTM$_\leftarrow$};
	\node[rectangle, left=of R25, minimum height=1cm, minimum width=1cm, draw] (R24) {LSTM$_\leftarrow$};
	\node[rectangle, left=of R24, draw, minimum height=1cm, minimum width=1cm] (R23) {LSTM$_\leftarrow$};
	\node[rectangle, left=of R23, draw, minimum height=1cm, minimum width=1cm] (R22) {LSTM$_\leftarrow$};
	\node[rectangle, left=2em of R22] (R21) {$\dots$};
	\node[right=2em of R25] (Y20) {$\dots$};
			
	\node[below=of RNN] (X1) {$\vec{x}_1$};
	\node[below=of RNN2] (X2) {$\vec{x}_2$};
	\node[below=of RNN3] (X3) {$\vec{x}_3$};
	\node[below=of RNN4] (X4) {$\vec{x}_4$};
	\node[above=of R25] (Y5) {$\vec{h}_4$};
	\node[above=of R24] (Y4) {$\vec{h}_3$};
	\node[above=of R23] (Y3) {$\vec{h}_2$};
	\node[above=of R22] (Y2) {$\vec{h}_1$};
			
	\draw[-stealth, thick] (X1) -- (RNN);
	\draw[-stealth, thick] (X2) -- (RNN2);
	\draw[-stealth, thick] (X3) -- (RNN3);
	\draw[-stealth, thick] (X4) -- (RNN4);
	\draw[-stealth, thick, densely dotted] (Y0) -- (RNN);
	\draw[-stealth, thick] (RNN) -- node[above, pos=0.35] {$\vec{h}_2^\rightarrow$} (RNN2);
	\draw[-stealth, thick] (RNN2) -- node[above, pos=0.35] {$\vec{h}_3^\rightarrow$} (RNN3);
	\draw[-stealth, thick] (RNN3) -- node[above, pos=0.35] {$\vec{h}_4^\rightarrow$} (RNN4);
	\draw[-stealth, densely dotted, thick] (RNN4) -- (RNN5);
	\node[below=4em of Y0] (d) {\dots};
	\node[below=4em of RNN5] (d) {\dots};
			
	\path[-stealth, ultra thick, white] (X1) edge[bend left=45] (R22);
	\path[-stealth, thick] (X1) edge[bend left=45] (R22);
	\path[-stealth, ultra thick, white] (X2) edge[bend left=45] (R23);
	\path[-stealth, thick] (X2) edge[bend left=45] (R23);
	\path[-stealth, ultra thick, white] (X3) edge[bend left=45] (R24);
	\path[-stealth, thick] (X3) edge[bend left=45] (R24);
	\path[-stealth, ultra thick, white] (X4) edge[bend left=45] (R25);
	\path[-stealth, thick] (X4) edge[bend left=45] (R25);
	\draw[-stealth, densely dotted, thick] (Y20) -- (R25);
			
	\draw[-stealth, thick] (R22) -- (Y2);
	\draw[-stealth, thick] (R23) -- (Y3);
	\draw[-stealth, thick] (R24) -- (Y4);
	\draw[-stealth, thick] (R25) -- (Y5);
		
	\draw[stealth-, densely dotted, thick] (R21) -- (R22);
	\draw[stealth-, thick] (R22) -- node[above, pos=0.65] {$\vec{h}_3^\leftarrow$} (R23);
	\draw[stealth-, thick] (R23) -- node[above, pos=0.65] {$\vec{h}_4^\leftarrow$} (R24);
	\draw[stealth-, thick] (R24) -- node[above, pos=0.65] {$\vec{h}_5^\leftarrow$} (R25);
	\draw[-stealth, densely dotted, thick] (Y20) -- (R25);	
			
	\path[-stealth, ultra thick, white] (RNN) edge[bend right=45] (Y2);
	\path[-stealth, thick] (RNN) edge[bend right=45] (Y2);
	\path[-stealth, ultra thick, white] (RNN2) edge[bend right=45] (Y3);
	\path[-stealth, thick] (RNN2) edge[bend right=45] (Y3);
	\path[-stealth, ultra thick, white] (RNN3) edge[bend right=45] (Y4);
	\path[-stealth, thick] (RNN3) edge[bend right=45] (Y4);
	\path[-stealth, ultra thick, white] (RNN4) edge[bend right=45] (Y5);
	\path[-stealth, thick] (RNN4) edge[bend right=45] (Y5);
			
\end{tikzpicture}
\end{document}
</code></pre>
<h2 id="lstmå•å…ƒ">LSTMå•å…ƒ</h2>
<h3 id="æ•ˆæœå›¾-2">ğŸ¥™æ•ˆæœå›¾</h3>
<figure data-type="image" tabindex="2"><img src="https://sunyanhust.github.io/post-images/1587241071902.PNG" alt="" loading="lazy"></figure>
<h3 id="ä»£ç -2">ğŸ“œä»£ç </h3>
<pre><code class="language-tex">\documentclass[crop, tikz]{standalone}
\usepackage{tikz}

\usepackage{bm}
\usepackage{relsize}
\usepackage{pgfplots}
 
\usetikzlibrary{arrows,shapes, decorations.pathmorphing,backgrounds,positioning}

\begin{document}
\begin{tikzpicture}

	\node[rectangle, rounded corners=10, minimum width=20em, minimum height=12em, draw, very thick, fill=white] (lstm) at (0, 0) {};
	
	\node[rectangle, draw] at (-2.5, -0.8) (s1){$\sigma$};
	\node[rectangle, draw, right=1em of s1] (s2) {$\sigma$};
	\node[rectangle, draw, right=1em of s2] (t1) {$tanh$};
	\node[rectangle, draw, right=1em of t1] (s3) {$\sigma$};
	\node[circle, draw, above=2em of t1, inner sep=0em] (m1) {$\otimes$};
	\node[circle, draw, above=6em of s1, inner sep=0em] (m2) {$\otimes$};
	\node[circle, draw, right=6.55em of m2, inner sep=0em] (p1) {$\oplus$};
	\node[circle, draw, right=4.5em of m1, inner sep=0em] (m3) {$\otimes$};
	\node[rectangle, draw, above=1em of m3, inner sep=0.2em] (tt) {$tanh$ };
	
	\node[circle, draw, below=1em of s1, inner sep=0em] (conc) {$||$};
	
	\node[below=5em of s1] (xt) {$\vec{x}_t$};
	\node[left=3em of conc] (ht1) {$\vec{h}_{t-1}$};
	\node[left=3em of m2] (ct1) {$c_{t-1}$};
	\node[right=18em of m2] (ct) {$c_t$};
	\node[right=18em of conc] (ht) {$\vec{h}_t$};
	\node[] (yt) at (3, 3) {$\vec{h}_t$};
	
	\draw[-stealth, line width=1mm, white] (xt) -- (conc);
	\draw[-stealth, very thick] (xt) -- (conc);
	\draw[-stealth, line width=1mm, white] (ht1) -- (conc);
	\draw[-stealth, very thick] (ht1) -- (conc);
	
	\draw[-stealth, very thick] (conc) -- (s1);
	\path[-stealth, very thick] (conc) edge[bend right] (s2.south);
	\path[-stealth, very thick] (conc) edge[bend right] (t1.south);
	\path[-stealth, very thick] (conc) edge[bend right] (s3.south);
	\draw[-stealth, very thick] (s1) -- node[left] {$f_t$} (m2);
	\draw[-stealth, very thick] (s2) edge[bend left] node[above] {$i_t$} (m1.west);
	\draw[-stealth, very thick] (t1) -- node[right] {$\tilde{c_t}$} (m1);
	\draw[-stealth, very thick] (m1) -- (p1);
	\draw[-stealth, line width=1mm, white] (ct1) -- (m2);
	\draw[-stealth, very thick] (ct1) -- (m2);
	\draw[-stealth, very thick] (m2) -- (p1);
	\draw[-stealth, very thick] (s3) edge[bend left] node[left] {$o_t$} (m3.west);
	
	\draw[-stealth, line width=1mm, white] (p1) -- (ct);
	\draw[-stealth, very thick] (p1) -- (ct);
	\draw[-stealth, very thick] (tt) -- (m3);
	\draw[-stealth, line width=1mm, white] (m3) edge[bend right] (ht.west);
	\draw[-stealth, very thick] (m3) edge[bend right] (ht.west);
	
	\draw[-stealth ,very thick] (p1) edge[bend right] (tt.west);
	\draw[-stealth, line width=1mm,white] (m3) edge[bend right] (yt.south);
	\draw[-stealth, very thick] (m3) edge[bend right] (yt.south);
			
\end{tikzpicture}
\end{document}
</code></pre>
<h2 id="è‡ªæ³¨æ„åŠ›">è‡ªæ³¨æ„åŠ›</h2>
<h3 id="æ•ˆæœå›¾-3">ğŸ¥™æ•ˆæœå›¾</h3>
<figure data-type="image" tabindex="3"><img src="https://sunyanhust.github.io/post-images/1587241576659.png" alt="" loading="lazy"></figure>
<h3 id="ä»£ç -3">ğŸ“œä»£ç </h3>
<pre><code class="language-tex">\documentclass[crop, tikz]{standalone}
\usepackage{tikz}

\usetikzlibrary{positioning}

\begin{document}
\begin{tikzpicture}

	\node (X1) {$\vec{h}_{1}$};

	\node[rectangle, right= 0.5em of X1] (x_dots_1) {$\dots$};

	\node[right=0.5em of x_dots_1] (Xj) {$\vec{h}_{j}$};

	\node[rectangle, right= 1em of Xj] (x_dots_2) {$\dots$};

	\node[right=1em of x_dots_2] (Xn) {$\vec{h}_{n}$};

	\node[rectangle, draw, ultra thick, above=of X1] (attn1) {\large $a_\phi$};

	\node[rectangle, draw, ultra thick, above=of Xj] (attnj) {\large $a_\phi$};

	\node[rectangle, draw, ultra thick, above=of Xn] (attnn) {\large $a_\phi$};


	\draw[-stealth, thick] (X1) -- (attn1);
	\draw[-stealth, thick] (Xj) -- (attn1);

	\draw[-stealth, thick] (Xj) -- (attnj);
	\draw[-stealth, thick] ([xshift=3em]Xj) -- (attnj);
	
	\draw[-stealth, thick] (Xj) -- (attnn);
	\draw[-stealth, thick] (Xn) -- (attnn);
	
	\node[above= of attn1, opacity=0.2] (alpha1j) {$\alpha_{1,j}$};
	\node[above= of attnj, opacity=1] (alphajj) {$\alpha_{j,j}$};
	\node[above= of attnn, opacity=0.6] (alphanj) {$\alpha_{n,j}$};
	
	\node[circle, draw, above=of alpha1j] (times1) {$\times$};
	\node[circle, draw, above=of alphajj] (timesj) {$\times$};
	\node[circle, draw, above=of alphanj] (timesn) {$\times$};
	
	\node[rectangle, draw, above=of timesj] (sum) {$\Sigma$};

	\node[above=1em of sum] (x_tprim) {$\vec{h}_j'$};

	\draw[-stealth, line width=1.5mm, white] (attn1) -- (alpha1j);
	\draw[-stealth, thick, opacity=0.2] (attn1) -- (alpha1j);
	\draw[-stealth, line width=1.5mm, white] (attnj) -- (alphajj);
	\draw[-stealth, thick, opacity=1] (attnj) -- (alphajj);
	\draw[-stealth, line width=1.5mm, white] (attnn) -- (alphanj);
	\draw[-stealth, thick, opacity=0.6] (attnn) -- (alphanj);
	
	\draw[-stealth, white, line width=1.5mm] (X1) edge[bend right=30] (times1);
	\draw[-stealth, thick] (X1) edge[bend right=30] node[rectangle, draw, fill=white, midway] {$f_\psi$} (times1);
	\draw[-stealth, white, line width=1.5mm] (Xj) edge[bend right=30] (timesj);
	\draw[-stealth, thick] (Xj) edge[bend right=30] node[rectangle, draw, fill=white, midway] {$f_\psi$} (timesj);
	\draw[-stealth, thick] (Xn) edge[bend right=30] node[rectangle, draw, fill=white, midway] {$f_\psi$} (timesn);

	\draw[-, line width=1.5mm, white] (times1) -- (sum);
	\draw[-stealth, thick] (times1) -- (sum);
	\draw[-, line width=1.5mm, white] (timesj) -- (sum);
	\draw[-stealth, thick] (timesj) -- (sum);
	\draw[-stealth, thick] (timesn) -- (sum);
	\draw[-stealth, thick] (times1) -- (sum);
		
	\draw[-stealth, line width=1.5mm, white] (alpha1j) -- (times1);
	\draw[-stealth, thick, opacity=0.2] (alpha1j) -- (times1);
	\draw[-stealth, line width=1.5mm, white] (alphajj) -- (timesj);
	\draw[-stealth, thick, opacity=1] (alphajj) -- (timesj);
	\draw[-stealth, line width=1.5mm, white] (alphanj) -- (timesn);
	\draw[-stealth, thick, opacity=0.6] (alphanj) -- (timesn);

	\draw[-stealth, thick] (sum) -- (x_tprim);

\end{tikzpicture}
\end{document}
</code></pre>
<h2 id="rnn">RNN</h2>
<h3 id="æ•ˆæœå›¾-4">ğŸ¥™æ•ˆæœå›¾</h3>
<figure data-type="image" tabindex="4"><img src="https://sunyanhust.github.io/post-images/1587243725699.png" alt="" loading="lazy"></figure>
<h3 id="ä»£ç -4">ğŸ“œä»£ç </h3>
<pre><code class="language-tex">\documentclass[crop, tikz]{standalone}
\usepackage{tikz}

\usetikzlibrary{positioning}

\begin{document}
\begin{tikzpicture}
	\node[rectangle] (Y0) at (0, 0) {$\dots$};
	\node[rectangle, draw, right=2em of Y0, minimum height=1cm, minimum width=1cm] (RNN) {RNN};
	\node[rectangle, right=of RNN, draw, minimum height=1cm, minimum width=1cm] (RNN2) {RNN};
	\node[rectangle, right=of RNN2, draw, minimum height=1cm, minimum width=1cm] (RNN3) {RNN};
	\node[rectangle, right= of RNN3, draw, minimum height=1cm, minimum width=1cm] (RNN4) {RNN};
	\node[rectangle, right=2em of RNN4] (RNN5) {$\dots$};
			
	\node[below=of RNN] (X1) {$\vec{x}_1$};
	\node[below=of RNN2] (X2) {$\vec{x}_2$};
	\node[below=of RNN3] (X3) {$\vec{x}_3$};
	\node[below=of RNN4] (X4) {$\vec{x}_4$};
	\node[above=of RNN4] (Y5) {$\vec{h}_4$};
	\node[above=of RNN3] (Y4) {$\vec{h}_3$};
	\node[above=of RNN2] (Y3) {$\vec{h}_2$};
	\node[above=of RNN] (Y2) {$\vec{h}_1$};
			
	\draw[-stealth, thick] (X1) -- (RNN);
	\draw[-stealth, thick] (X2) -- (RNN2);
	\draw[-stealth, thick] (X3) -- (RNN3);
	\draw[-stealth, thick] (X4) -- (RNN4);
	
	\draw[-stealth, thick] (RNN) -- (Y2);
	\draw[-stealth, thick] (RNN2) -- (Y3);
	\draw[-stealth, thick] (RNN3) -- (Y4);
	\draw[-stealth, thick] (RNN4) -- (Y5);
	
    \draw[-stealth, densely dotted, thick] (Y0) -- (RNN);
    \draw[-stealth, densely dotted, thick] (RNN) -- (RNN2);
    \draw[-stealth, densely dotted, thick] (RNN2) -- (RNN3);
    \draw[-stealth, densely dotted, thick] (RNN3) -- (RNN4);
    \draw[-stealth, densely dotted, thick] (RNN4) -- (RNN5);
			
\end{tikzpicture}
\end{document}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PaddleHubä½¿ç”¨ç¤ºä¾‹]]></title>
        <id>https://sunyanhust.github.io/post/paddlehub/</id>
        <link href="https://sunyanhust.github.io/post/paddlehub/">
        </link>
        <updated>2020-04-12T03:04:18.000Z</updated>
        <content type="html"><![CDATA[<p>æœ€è¿‘ç”¨äº†ä¸€ä¸‹PaddleHubï¼Œæ„Ÿè§‰è¿˜æŒºå¥½ç”¨çš„ã€‚è¿™é‡Œä¸¤ä¸ªä½¿ç”¨PaddleHubçš„ç¤ºä¾‹ã€‚</p>
<h2 id="åˆ†è¯">åˆ†è¯</h2>
<p>è¿™ä¸ªåˆ†è¯å’Œå®˜ç½‘çš„åˆ†è¯æ•ˆæœä¸€æ ·ï¼Œè§‰å¾—æ¯”jiebaä¹‹ç±»çš„è¦å¥½ã€‚</p>
<pre><code class="language-python"># pip install pyahocorasick
# https://www.paddlepaddle.org.cn/hubdetail?name=lac&amp;en_category=LexicalAnalysis
import paddlehub as hub

temp_user_dict = [
    dict(word='è‡ªç„¶', tag='n', freq='10000')
]


def make_dict(user_dicts):
    with open('user.dict', 'w') as f:
        for user_dict in user_dicts:
            f.write(user_dict['word'] + '\t' +
                    user_dict['tag'] + '\t' +
                    user_dict['freq'] + '\n')


make_dict(temp_user_dict)

lac = hub.Module(name='lac')
lac.set_user_dict(dict_path='user.dict')
results = lac.lexical_analysis(texts=['æˆ‘çˆ±è‡ªç„¶è¯­è¨€å¤„ç†'],
                               use_gpu=False,
                               batch_size=1,
                               return_tag=True)

for result in results:
    print(result[&quot;word&quot;])
    print(result[&quot;tag&quot;])
</code></pre>
<h2 id="é˜…è¯»ç†è§£">é˜…è¯»ç†è§£</h2>
<pre><code class="language-python">import paddlehub as hub

module = hub.Module(name=&quot;roberta_wwm_ext_chinese_L-24_H-1024_A-16&quot;)
inputs, outputs, program = module.context(trainable=True, max_seq_len=384)
dataset = hub.dataset.CMRC2018()

reader = hub.reader.ReadingComprehensionReader(
    dataset=dataset,
    vocab_path=module.get_vocab_path(),
    max_seq_len=384)

strategy = hub.AdamWeightDecayStrategy(
    learning_rate=5e-5,
    weight_decay=0.01,
    warmup_proportion=0.1
)

config = hub.RunConfig(use_cuda=False, num_epoch=2, batch_size=12, strategy=strategy)
seq_output = outputs[&quot;sequence_output&quot;]

# feed_listçš„Tensoré¡ºåºä¸å¯ä»¥è°ƒæ•´
feed_list = [
    inputs[&quot;input_ids&quot;].name,
    inputs[&quot;position_ids&quot;].name,
    inputs[&quot;segment_ids&quot;].name,
    inputs[&quot;input_mask&quot;].name,
]

reading_comprehension_task = hub.ReadingComprehensionTask(
    data_reader=reader,
    feature=seq_output,
    feed_list=feed_list,
    config=config,
    sub_task=&quot;cmrc2018&quot;)

reading_comprehension_task.finetune_and_eval()

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[å¯¹å¾…å©šå§»çš„æ€åº¦]]></title>
        <id>https://sunyanhust.github.io/post/guan-yu-hun-yin/</id>
        <link href="https://sunyanhust.github.io/post/guan-yu-hun-yin/">
        </link>
        <updated>2020-04-06T13:42:02.000Z</updated>
        <content type="html"><![CDATA[<p>ä»Šå¤©æ™šä¸Šï¼Œå¾—çŸ¥æˆ‘æœ€å¥½çš„æœ‹å‹ç¦»å©šäº†ã€‚å­©å­æ‰1å²ï¼ŒåŒæ ·èº«ä¸ºçˆ¶äº²çš„æˆ‘æ„Ÿåˆ°éš¾è¿‡ï¼Œç¦»å©šå¯¹å­©å­æ¥è¯´å½±å“å¤ªå¤§ã€‚</p>
<p>æˆ‘æ²¡èµ„æ ¼è¯´è¿™äº›ã€‚ä¸è¿‡ï¼Œè‡³å°‘æˆ‘çš„å©šå§»ç®—å‡‘åˆï¼Œæˆ‘ä¹Ÿæœ‰æŠŠæ¡å»¶ç»­è¿™ç§å‡‘åˆã€‚æˆ‘å†™è¿™ç¯‡æ–‡ç« ï¼Œå°±æ˜¯å¸Œæœ›æœ‰æ›´å¤šçš„äººèƒ½æŠŠæ¡è‡ªå·±çš„å©šå§»ã€‚å°±ç®—æˆ‘è¯´çš„éƒ½æ˜¯åºŸè¯ï¼Œå¦‚æœèƒ½å¼•èµ·æœ‹å‹ä»¬åœ¨å©šå‰å¯¹å©šå§»å¤šä¸€äº›æ€è€ƒï¼Œå°±è¾¾åˆ°ç›®çš„äº†ã€‚</p>
<p>æ¯ä¸ªäººå¯¹å©šå§»çš„æ€åº¦éƒ½æ˜¯ä¸åŒçš„ï¼Œéšä¾¿æ‰¾ä¸ªäººè¿‡æ—¥å­çš„ï¼Œæ‰¾ä¸ªå¥³äººå¸®è‡ªå·±ç”Ÿå­©çš„ï¼Œæ‰¾ä¸ªè¿‡å¤œä¸æ”¶é’±çš„ï¼Œè¿™äº›æ‰€è°“çš„â€œå©šå§»â€å°±ä¸åœ¨è®¨è®ºèŒƒå›´äº†ï¼Œè¿™é‡Œå’Œå¤§å®¶è®¨è®ºçš„ï¼Œæ˜¯é«˜è´¨é‡çš„å©šå§»ã€‚</p>
<p>æ¯ä¸ªäººçš„ç†è§£éƒ½ä¸ä¸€æ ·ï¼Œåœ¨æˆ‘çœ‹æ¥ï¼Œå©šå§»çš„çŠ¶æ€æœ‰å¾ˆå¤šç§ï¼Œä½†æ˜¯è®©äººèˆ’æœçš„å©šå§»ï¼Œä¸€å®šéƒ½æ˜¯æœ‰çˆ±çš„ã€‚</p>
<p>æœ‰äººè¯´ï¼Œçˆ±æƒ…æ˜¯æœ‰ä¿è´¨æœŸçš„ã€‚æˆ‘è¯´ï¼Œæœ‰ä¿è´¨æœŸçš„ä¸å«çˆ±æƒ…ã€‚é‚£å«æ¿€æƒ…ï¼Œæ¿€æƒ…å¤¹æ‚çš„ä¸œè¥¿å¤ªå¤šï¼Œæ€§æ¬²ï¼Œæ„ŸåŠ¨ï¼Œå†…ç–šï¼Œæ†§æ†¬ï¼Œæœ‰å¤ªå¤šå¤ªå¤šçš„æ‚è´¨ï¼Œè¿™æ ·çš„æƒ…æ„Ÿç¡®å®éš¾ä»¥æŒä¹…ã€‚ä½•å†µï¼Œæ¿€æƒ…å¾€å¾€æ˜¯ç²¾å¿ƒå‘µæŠ¤èµ·æ¥çš„ï¼Œä¸€æ—¦ä¸¢å¤±äº†ç²¾å¿ƒå‘µæŠ¤çš„åŠ¨åŠ›ï¼Œè¤ªè‰²å¤ªå¿«ã€‚</p>
<p>æ³¡å¦çš„æ—¶å€™ï¼Œæ¿€æƒ…æ˜¯æœ€å¥½çš„å·¥å…·ã€‚ç„¶è€Œé¢ä¸´ç»“å©šé€‰æ‹©æ—¶ï¼Œä½œä¸ºç”·äººï¼Œä¸€å®šè¦ç†æ¸…è‡ªå·±çš„å¤´è„‘ï¼Œç¥›é™¤æ¿€æƒ…çš„æˆåˆ†ã€‚è¿™ä¸ªæ€è€ƒçš„è¿‡ç¨‹éå¸¸é‡è¦ï¼Œå©šå§»æ˜¯æ²¡æœ‰å›å¤´è·¯çš„ã€‚åˆ«ä»¥ä¸ºå¤§ä¸äº†è¿˜å¯ä»¥ç¦»å©šã€‚ç¦»å©šä¸æ˜¯è§£è„±ï¼Œæ˜¯åˆä¸€ä¸ªéº»çƒ¦çš„å¼€å§‹ã€‚</p>
<p>å¦‚ä½•ç¡®å®šè‡ªå·±çˆ±ä¸çˆ±ä¸€ä¸ªå¥³äººï¼Œè¿™æ˜¯éå¸¸å…³é”®çš„ä¸€æ­¥ã€‚æˆ‘å¾ˆè‚¯å®šçš„è¯´ï¼Œå¾ˆå°‘ç”·äººæ¸…æ¥šè¿™ä¸ªé—®é¢˜ã€‚ç”·äººçš„ç”Ÿç†å¤©æ€§å†³å®šäº†å¯¹å¥³äººçš„é€‰æ‹©å¾ˆå¤§å› ç´ æ˜¯å¤–è²Œã€‚ä½†æ˜¯å©šå§»æ˜¯åäººç±»å¤©æ€§çš„ã€‚æ‰€ä»¥å½“ç”·äººé€‰æ‹©äº†å©šå§»ï¼Œå°±æ³¨å®šè¦å…‹æœè‡ªå·±çš„ç”Ÿç†å¤©æ€§ã€‚</p>
<p>ç”·äººçš„ç”Ÿç†å¤©æ€§ï¼Œè¯´ç™½å°±æ˜¯å¸Œæœ›ä¿è´¨ä¿é‡çš„é—ä¼ è‡ªå·±çš„åŸºå› ï¼Œæ¯”å¦‚å°½å¯èƒ½çš„å’Œæ›´å¤šå¥³äººä¸ŠåºŠï¼Œå°½å¯èƒ½çš„é€‰æ‹©æ›´æ¼‚äº®ï¼ŒåŸºå› æ›´ä¼˜ç§€çš„å¥³äººä¸ŠåºŠã€‚</p>
<p>è€Œå©šå§»ï¼Œæ°æ°ç›¸åï¼Œç”·äººåªèƒ½é€‰æ‹©ä¸€ä¸ªå¥³äººã€‚è€Œä¸”è¦çŸ¥é“ï¼Œçœ¼å‰è¿™ä¸ªå°†è¦å«ç»™è‡ªå·±çš„ç¾å¥³ï¼Œä¸å‡ å¹´å°±ä¼šç”Ÿå­©å­ï¼Œçœ¼è§’ä¼šæœ‰çš±çº¹ï¼Œä¹³æˆ¿ä¼šä¸‹å‚ï¼Œä¹³å¤´ä¼šå˜çš„å¾ˆé»‘ï¼Œå±è‚¡ä¼šå˜å½¢ï¼Œå°è‚šå­ä¼šå‡ºæ¥ï¼Œè¿˜ä¼šæœ‰éš¾çœ‹çš„æ–‘çº¹ã€‚æ›´å¯æ€•çš„æ˜¯ï¼Œç”·äººçš„ç”Ÿç†å¤©æ€§å†³å®šäº†ç”·äººè€å’ŒåŒä¸€ä¸ªå¥³äººä¸ŠåºŠï¼Œæ˜¯ä¼šè…»çš„ã€‚æ‰€ä»¥ï¼Œæ²¡æœ‰çˆ±çš„å©šå§»æ˜¯å±é™©çš„ã€‚å› ä¸ºæ²¡æœ‰å…‹æœç”Ÿç†æ¬²æœ›çš„ä¿¡å¿µã€‚</p>
<p>â€‹       å…„å¼Ÿä»¬æ°¸è¿œåˆ«åœ¨å©šå‰ä¿¡èª“æ—¦æ—¦çš„è¯´è‡ªå·±ä¸æ˜¯é‚£ç§åŒ…äºŒå¥¶çš„äººã€‚50å¹´ä»£å‡ºèº«é‚£æ‰¹äººï¼Œé“å¾·è§‚å¿µæ¯”æˆ‘ä»¬é‡çš„å¤šï¼Œè€å©†è¿˜éƒ½æ˜¯å…±è¿‡æ‚£éš¾çš„ç³Ÿç³ ï¼Œä¸ä¸€æ ·å¤§é‡çš„å‡ºè½¨ï¼Ÿæ‰€ä»¥ï¼Œåœ¨ä¸€å¤«ä¸€å¦»çš„åˆ¶åº¦ä¸‹ï¼Œä¿éšœå©šå§»çš„æ ¹æœ¬ï¼Œè¿˜æ˜¯å¾—ä¾é çˆ±æƒ…ã€‚å…¶ä»–çº¦æŸåœ¨äººæ€§æœ¬èƒ½çš„æ‹‰æ‰¯ä¸‹éƒ½æ˜¯è„†å¼±çš„ã€‚</p>
<p>æ®æˆ‘è§‚å¯Ÿï¼Œå¾ˆå¤šå¤±è´¥å©šå§»çš„å…ƒå‡¶å°±æ˜¯æ€§ã€‚æ€§å¯¹ç”·äººçš„è¯±æƒ‘æ˜¯è‡´å‘½çš„ï¼Œä¸å°‘ç”·äººå°±æ˜¯å› ä¸ºå’Œå¥³äººä¸Šäº†åºŠå°±é¡ºç†æˆç« çš„ç»“å©šäº†ã€‚æ˜¯å¥½æ˜¯åå…¨çœ‹è¿æ°”ã€‚å‹æ ¹ä¸æ€è€ƒæœ‰æ²¡æœ‰å…±åŒè¯­è¨€ï¼Œé‡åˆ°é—®é¢˜åŒæ–¹çš„æ²Ÿé€šæ–¹å¼å½¼æ­¤èƒ½å¦æ¥å—ï¼Œè¿™äº›å…³é”®çš„é—®é¢˜ä¸å»æƒ³ã€‚å°±å› ä¸ºä¸Šäº†åºŠå°±ç»“å©šã€‚è¿™æ˜¯å¾ˆå¤šæ‚²å‰§çš„æ¥æºã€‚ç”¨äººæ€§æœ¬èƒ½æ¥é€‚åº”åäººæ€§æœ¬èƒ½çš„å©šå§»åˆ¶åº¦ã€‚è¿™æ˜¯éå¸¸æ„šè ¢çš„ã€‚æ›´æ„šè ¢çš„æ˜¯å¾ˆå¤šå¥³äººä»¥æ€§ä¸ºå·¥å…·æ¥å¯¹å¾…å©šå§»ã€‚è¯´åˆ°è¿™é‡Œæ‰å‘ç°ï¼Œå©šå§»çœŸæ˜¯ä¸ªå¤§è¯é¢˜ã€‚æ¯ä¸ªäººå»é¢†ç»“å©šè¯çš„æ—¶å€™ï¼Œéƒ½æ²¡æƒ³è¿‡æœ‰ä¸€å¤©ä¼šå»æ‹¿ç¦»å©šè¯ã€‚å¯æƒœï¼Œç¦»å©šçš„äººè¶Šæ¥è¶Šå¤šã€‚æ®ç»Ÿè®¡80åçš„ç¦»å©šç‡å¿«åˆ°ç™¾åˆ†å››åäº†ã€‚</p>
<p>ç”·äººï¼Œåªæœ‰æŠŠæ€§æ¬²ï¼Œæ„ŸåŠ¨ç­‰ç­‰ç­‰ç­‰å› ç´ å…¨æŠ›å¼€ï¼Œæ‰èƒ½çœŸæ­£è®¤è¯†è‡ªå·±å¯¹ä¸€ä¸ªå¥³äººçš„æ„Ÿæƒ…æ˜¯ä¸æ˜¯çˆ±ã€‚çˆ±ä¸èƒ½è§£å†³æ‰€æœ‰é—®é¢˜ï¼Œä½†æ˜¯èƒ½ç»™ç”·äººè§£å†³é—®é¢˜çš„åŠ¨åŠ›ã€‚æ²¡æœ‰åŠ¨åŠ›ç»è¥çš„å©šå§»ï¼Œéº»çƒ¦å¾ˆå¤šã€‚å› ä¸ºå©šå§»çš„é—®é¢˜å¾ˆå¤šã€‚</p>
<p>ç»“å©šå¯¹ç”·äººè€Œè¨€ï¼Œçº¯ç²¹æ˜¯è´£ä»»ã€‚æœ‰äº†æ‰¿æ‹…è´£ä»»çš„å†³å¿ƒï¼Œæ‰æ•¢è°ˆå©šå§»ï¼Œæ‰€ä»¥ï¼Œç»“å©šä¸€å®šè¦æ‰¾ä¸€ä¸ªè‡ªå·±çˆ±çš„å¥³äººã€‚è‡ªå·±ä½™ä¸‹çš„ç”Ÿå‘½å…¨éƒ¨ä¸ºä¹‹ä»˜å‡ºçš„å®¶åº­ï¼Œå¥³ä¸»äººä¸æ˜¯è‡ªå·±çœŸæ­£çˆ±çš„ï¼Œå¤ªæ‚²å‰§äº†ã€‚å› ä¸ºå©šå§»å”¯ä¸€èƒ½å›æŠ¥ç»™ç”·äººçš„ï¼Œä»…ä»…æ˜¯ä¸€åªèƒ½ç‰µç€è‡ªå·±èµ°å‘æ­»äº¡çš„æ‰‹ã€‚åƒä¸‡åˆ«å¥¢æœ›å©šå§»å›æŠ¥ç»™è‡ªå·±ä»€ä¹ˆï¼Œä»»ä½•å¥¢æœ›åªä¼šæ·»åŠ åŒæ–¹çš„å‹åŠ›ã€‚åšå¥½ä¸ˆå¤«è¯¥åšçš„ï¼Œè‡ªç„¶å¾—åˆ°åº”å¾—çš„ã€‚</p>
<p>å¾ˆé‡è¦çš„ä¸€ç‚¹ï¼Œä¸æ˜¯å¹³æ—¶æœ‰æ²¡æœ‰å…±åŒè¯­è¨€ï¼Œè€Œæ˜¯æœ‰åˆ†æ­§å’Œé—®é¢˜çš„æ²Ÿé€šã€‚è¯´ç™½äº†ï¼Œå¦‚æœç”·äººæ˜¯ä¸ªè®²é“ç†çš„äººï¼Œå¥³äººä¹Ÿå¾—æ˜¯ä¸ªæ‡‚é“ç†çš„äººï¼Œå¦‚æœç”·äººæ˜¯ä¸ªå–œæ¬¢ç”¨æ‹³å¤´è¯´è¯çš„äººï¼Œå¥³äººä¹Ÿå¾—æ˜¯ä¸ªè‚¯æŒ¨æ‹³å¤´çš„äººã€‚å¥³äººå¦‚æœå–œæ¬¢å” å¨ï¼Œç”·äººå°±å¾—å¬å¾—æƒ¯ã€‚æ€»ä¹‹ï¼Œä¸¤ä¸ªäººå¿…é¡»å¾—æœ‰ä¸ªæ‹¿å‡ºç»Ÿä¸€æ„è§çš„ç¨‹åºï¼Œä¸”åŒæ–¹éƒ½èƒ½æ¥å—ã€‚æœ€å¥½æ˜¯éƒ½ä¹æ„æ¥å—ã€‚å…¶å®è¿™ä¸€æ¡å¯¹äºçœŸæ­£ç›¸çˆ±çš„äººæ¥è®²ä¸æ˜¯é—®é¢˜ï¼ŒçœŸæ­£ç›¸çˆ±çš„ä¸¤ä¸ªäººæ°¸è¿œæ˜¯ç«™åœ¨å¯¹æ–¹ç«‹åœºæ€è€ƒé—®é¢˜çš„ã€‚</p>
<p>æœ‰æƒ…é¥®æ°´é¥±ï¼Œåªèƒ½é¥±ä¸€é¡¿ã€‚ç”·äººæ²¡ç»“å©šï¼Œæ˜¯æ½‡æ´’çš„ï¼Œä¸€ç»“å©šï¼Œè´Ÿæ‹…å°±æ¥äº†ã€‚ä¸¤ä¸ªäººçš„ç»“åˆæ‰€å¸¦çš„å‹åŠ›è‚¯å®šæ˜¯å·¨å¤§çš„ï¼Œå¿…é¡»è¦è€ƒè™‘åŒæ–¹çš„æ‰¿å—èƒ½åŠ›ï¼Œè‡ªå·±æ²¡æœ‰èƒ½åŠ›è´Ÿæ‹…ï¼Œå°±ä¸è¦å®³äººå®³å·±äº†ã€‚å¥³æœ‹å‹å¦‚æœå–œæ¬¢é’±ï¼Œæœ‰é’±å°±å¨¶ï¼Œæ²¡é’±å°±ä¸è¦ç ¸é”…å–é“å¨¶å›å®¶äº†ã€‚</p>
<p>æœ‰äº›è´Ÿæ‹…ï¼ŒèƒŒä¸Šå°±æ˜¯ä¸€è¾ˆå­çš„ã€‚å¯¹å©šå§»è€Œè¨€ï¼Œè‚¯é™ªè‡ªå·±ä¸€èµ·å¥‹æ–—çš„å¥³äººï¼Œæ‰çœŸæ­£åº”è¯¥çæƒœã€‚å•å•æ˜¯ä¸¤ä¸ªäººä¸€èµ·æ”¹å–„ç”Ÿæ´»çš„è¿‡ç¨‹ï¼Œå°±å·²ç»æ˜¯å©šå§»å®è´µçš„è´¢å¯Œäº†ã€‚åˆ«è¯´ç°åœ¨è¿™æ ·çš„å¥³äººå°‘ï¼Œä¸å°‘ã€‚è€ç›¯ç€èŠ±ææ‹›å±•æƒ³é å«äººæ”¹å˜å‘½è¿çš„å¹´è½»å¥³äººï¼Œå°±åˆ«æ€ªå¥³äººç°å®ã€‚è‡ªå·±ä»æœªè§„åˆ’è¿‡æœªæ¥ï¼Œå°±åˆ«æ€ªå¥³äººä¸è‚¯é™ªè‡ªå·±ä¸€èµ·å¥‹æ–—ã€‚</p>
<p>æˆ‘ä¸€ç›´æå€¡å©šå‰æ€§è¡Œä¸ºï¼Œæ€§ç”Ÿæ´»å¾—åˆ°æ»¡è¶³çš„ç”·äººï¼Œæ‰æ›´å®¹æ˜“å‘ç°å¥³äººå…¶ä»–çš„é­…åŠ›ã€‚è€Œç°å®çš„æƒ…å†µæ˜¯ï¼Œä¸å°‘å¥½å¥³äººè¿˜å‰©ç€ï¼Œç”·äººå´åœ¨è¿½é€æ€§çš„è¿‡ç¨‹ä¸­è¿·å¤±äº†è‡ªå·±ã€‚å› è‰²è€Œç»“åˆï¼Œå¥³äººè‰²è¡°ä¹‹åï¼Œæ²¡æœ¬äº‹çš„ç”·äººç»§ç»­é¬¼æ··ï¼Œæœ‰æœ¬äº‹çš„æ¢ä¸ªå¥³äººå‡‘åˆã€‚è¿™æ ·çš„é£æ°”è¿˜æœ‰ä¸ªå¾ˆçƒ¦çš„å½±å“ï¼Œå¥³äººè¶Šæ¥è¶Šåœ¨æ„è‡ªå·±çš„å½¢è±¡ï¼ŒåŒ–å¦†æ—¶é—´è¶Šæ¥è¶Šé•¿ï¼Œè¡£é¢†è¶Šæ¥è¶Šä½ï¼Œè£™å­è¶Šæ¥è¶ŠçŸ­ã€‚è€Œå……ç”µçš„æ—¶é—´è¶Šæ¥è¶Šå°‘ï¼Œç‹¬ç«‹æ„è¯†è¶Šæ¥è¶Šæ·¡ã€‚</p>
<p>ç”·äººä¸€è¾¹è¿½é€å¥³è‰²ï¼Œä¸€è¾¹æŠ±æ€¨å¥³äººç´ è´¨è¶Šæ¥è¶Šä½ã€‚</p>
<p>å¥³äººå‘¢ï¼Ÿä¸€è¾¹æŠ±æ€¨ç”·äººè‚¤æµ…ï¼Œä¸€è¾¹ä¸æ–­è¿åˆè‚¤æµ…çš„å®¡ç¾ã€‚</p>
<p>å©šå§»ä¸æ˜¯äººç”Ÿçš„å…¨éƒ¨ï¼Œä¸¤ä¸ªäººæºæ‰‹ä¸€ç”Ÿï¼Œç›¸åŠ©åˆ™åˆ©ï¼Œç›¸é˜»åˆ™æŸã€‚æ€§æ ¼äº’è¡¥ä¹Ÿå¥½ï¼Œå¿—åŒé“åˆä¹Ÿå¥½ï¼Œå½¼æ­¤æˆä¸ºå¯¹æ–¹çš„åŠ©åŠ›ï¼ŒçœŸçš„å¾ˆé‡è¦ã€‚å¦‚æœå’Œä¸€ä¸ªå¥³äººå©šå‰å°±æ„Ÿè§‰ç–²æƒ«ã€‚ç›¸ä¿¡æˆ‘ï¼Œåˆ«ç»“å©šäº†ã€‚å®¶æ˜¯æ¸¯æ¹¾ï¼Œæ˜¯ä¸€ä¸ªè®©ç”·äººå¿«åˆ°å®¶é—¨å°±ä¼šä¸è‡ªè§‰åŠ å¿«è„šæ­¥çš„åœ°æ–¹ã€‚æ˜¯ä¸€ä¸ªä¸€å›å®¶å°±ä¼šå½»åº•æ”¾æ¾ï¼Œå¸ä¸‹æ‰€æœ‰ä¼ªè£…çš„åœ°æ–¹ã€‚æ˜¯ä¸€ä¸ªæ‰€æœ‰ç¬‘å®¹éƒ½å‘è‡ªçœŸå¿ƒçš„åœ°æ–¹ã€‚</p>
<p>æ€æ ·åŒºåˆ†æ¿€æƒ…å’Œçˆ±æƒ…ï¼Ÿå…¶å®å¾ˆå¥½åŒºåˆ†çš„ï¼Œå½“ä½ ä¸è§å¥¹æ—¶èŒ¶é¥­ä¸æ€ï¼Œæ˜¯æ¿€æƒ…ã€‚è€æƒ³è§åˆ°å¥¹ï¼Œæƒ³å’Œå¥¹ä¸€èµ·ç©ï¼Œä¸€èµ·ä¸ŠåºŠï¼Œä¸€èµ·åšç™½æ—¥æ¢¦ï¼Œæ˜¯æ¿€æƒ…ã€‚æ¯å¤©çŸ­ä¿¡ç”µè¯å¤šçš„æ²¡å®Œï¼Œæ˜¯æ¿€æƒ…ã€‚ä¸ºäº†ç”Ÿæ—¥èŠ‚æ—¥è´¹å°½å¿ƒæ€æƒ³æµªæ¼«çš„ç‚¹å­ï¼Œæ˜¯æ¿€æƒ…ã€‚</p>
<p>å½“ä½ å’Œå¥¹åœ¨ä¸€èµ·æ—¶è„‘å­é‡Œä¸è‡ªè§‰çš„è§„åˆ’å®å®åœ¨åœ¨çš„å°†æ¥ï¼Œæ˜¯çˆ±æƒ…ã€‚å½“ä½ ä»¬äº‰åµåˆ°å¾ˆå‡¶ï¼Œç«å¾ˆå¤§æ—¶ï¼Œä¹Ÿä¸å¿å¿ƒè¯´ä¸€å¥ä¼¤å®³å¥¹çš„è¯ï¼Œæ˜¯çˆ±æƒ…ã€‚å½“ä½ ä»¬æœ‰åˆ†æ­§æ—¶ï¼Œä½ æ€»æ˜¯èƒ½æ¸…æ¥šçš„çŸ¥é“å¥¹æ˜¯æ€ä¹ˆæƒ³çš„ï¼Œèƒ½ç†è§£å¥¹çš„åˆè¡·ï¼Œæ˜¯çˆ±æƒ…ã€‚</p>
<p>ç°åœ¨å¾ˆå¤šäººè°ˆæ‹çˆ±å¾ˆçŸ­æ—¶é—´å°±ç»“å©šäº†ï¼Œå½“ç„¶ï¼Œä¸æ˜¯è¯´æ—¶é—´çŸ­å°±ä¸å¥½ï¼Œè€Œæ˜¯è¦æ¸…æ¥šçš„çŸ¥é“ï¼Œå©šå‰çš„è€ƒå¯Ÿå¯¹è¿™ä¸€ç”Ÿçš„å½±å“ã€‚å¤±è´¥çš„å®¶åº­æ˜¯ä»»ä½•æˆåŠŸéƒ½å¼¥è¡¥ä¸äº†çš„ã€‚</p>
<p>äººï¼Œä¸€æ—¦ç¦»è¿‡ä¸€æ¬¡å©šï¼Œå†å¯»æ‰¾å¹¸ç¦çš„éš¾åº¦å°±æ›´å¤§äº†ã€‚å› ä¸ºï¼Œç¦»è¿‡å©šçš„äººæ›´éš¾ç›¸ä¿¡çˆ±æƒ…ã€‚æ›´ä½•å†µç¦»å©šå¯¹å­å¥³çš„å½±å“ï¼Œå¤ªå¤§å¤ªå¤§ã€‚äººï¼ŒçœŸæ­£èƒ½ç•™åœ¨è¿™ä¸ªä¸–ç•Œä¸Šçš„ï¼Œä¹Ÿå°±æ˜¯å­å¥³è¿™ç‚¹è¡€è„‰è€Œå·²ã€‚ä¸ºå­å¥³è¥é€ ä¸€ä¸ªå¥½çš„æˆé•¿ç¯å¢ƒï¼Œæ˜¯çˆ¶äº²çš„è´£ä»»ã€‚</p>
<p>å‰é¢è¯´è¿™ä¹ˆå¤šå…¶å®éƒ½æ˜¯è¯´é¢å¯¹å©šå§»çš„æ€åº¦è¦ç†æ€§ï¼Œè¦æ…é‡ã€‚</p>
<p>æ€åº¦ç«¯æ­£ä»¥åï¼ŒæŠ€å·§ä¹Ÿæœ‰å¾ˆå¤šéœ€è¦æ³¨æ„çš„åœ°æ–¹ã€‚æ˜æ˜ç›¸çˆ±çš„ä¸¤ä¸ªäººäº’ç›¸ä¼¤å®³çš„äº‹æƒ…å¤ªå¤šäº†ã€‚å¦‚æœçŠ¯é”™ï¼Œä¹Ÿè¦ç§¯ææƒ³åŠæ³•è¡¥æ•‘äº‰å–ã€‚ä¼¤å¯’å¿ƒæ•£ä¼™çš„ä¹Ÿå¤šï¼Œè€Œä¸”å©šå§»ç”Ÿæ´»ï¼Œç”·äººè¿˜æœ‰ä¸ªé‡è¦æŠ€æœ¯è¦æŒæ¡ï¼Œå°±æ˜¯è€å¦ˆä¸è€å©†çš„å…³ç³»ã€‚å©šåç”Ÿæ´»çç¢çš„äº‹æƒ…å¤ªå¤šï¼Œå…ˆè¯´è¯´å¤„ç†å©†åª³å…³ç³»ã€‚æ‰€æœ‰è¿˜æ²¡ç»“å©šçš„å…„å¼Ÿä¸€å®šä¸è¦æŠŠè¿™ä¸å½“ä¸€å›äº‹ã€‚ä¸€è¾¹æ˜¯ç”Ÿä½ å…»ä½ ä¸ºä½ ä»˜å‡ºæ‰€æœ‰çš„æ¯äº²ï¼Œä¸€è¾¹æ˜¯å°†è¦ç›¸ä¼´ä½ ä¸€ç”Ÿçš„è€å©†ã€‚åŒæ–¹éƒ½æœ‰è´£ä»»è¦ç…§é¡¾ã€‚è¿™ä¸ªå…³ç³»å¼„é¡ºäº†ï¼Œå°‘å¾ˆå¤šéº»çƒ¦ã€‚</p>
<p>æœ‰äººè¯´ç”·äººåœ¨å©†åª³ä¹‹é—´æ˜¯åŒé¢èƒ¶ï¼Œå¤¹åœ¨ä¸­é—´ä¸¤é¢è®¨å¥½ã€‚è¿™æ˜¯é”™çš„ã€‚ç”·äººå¿…é¡»æ˜¯ä¸€æ‰‹æ‹¿æ£’ä¸€æ‰‹æ‹¿æ¶¦æ»‘æ²¹ã€‚å°äº‹å±…ä¸­è°ƒèŠ‚ï¼ŒåŸåˆ™é—®é¢˜å¯¹äº‹ä¸å¯¹äººï¼Œé“ç†ç»ä¸èƒ½æ­ªï¼Œæ—¢ä¸èƒ½çºµå®¹åª³å¦‡ï¼Œä¹Ÿä¸èƒ½æƒ¯åäº†è€å¦ˆã€‚åšå†³ä¸è¦åœ¨è€å¦ˆé¢å‰è¯´åª³å¦‡ä¸å¯¹ï¼Œå¤šåŒ…æ¶µä¹‹ç±»ï¼Œä¹Ÿä¸èƒ½åœ¨åª³å¦‡é¢å‰è¯´ï¼Œè¿™éƒ½æ˜¯çºµå®¹ã€‚æŠŠæ¡ä¸€ä¸ªåŸåˆ™ï¼Œç»ä¸å…è®¸åª³å¦‡åœ¨è‡ªå·±é¢å‰è¯´è€å¦ˆçš„åè¯ï¼Œæœ‰äº‹è¯´äº‹ã€‚è¯¥æ€ä¹ˆè§£å†³æ€ä¹ˆè§£å†³ï¼Œæ˜¯è€å¦ˆä¸å¯¹ä¹Ÿè¦å’Œè€å¦ˆæŠŠäº‹æƒ…è®²æ¸…æ¥šï¼ŒåŒæ ·çš„ï¼Œè€å¦ˆè¯´è‡ªå·±åª³å¦‡çš„æ—¶å€™ä¹Ÿè¦åˆ†æ¸…æ˜¯éã€‚å±…ä¸­è®¨å¥½çš„åæœæ˜¯ä¸¤é¢ä¸æ˜¯äººï¼ŒçŸ›ç›¾è¿˜è¶Šæ¥è¶Šæ·±ã€‚</p>
<p>æ€»ä¹‹ï¼Œç»å¯¹çš„å…¬å¹³æ˜¯å¤„ç†å©†åª³å…³ç³»çš„å”¯ä¸€æ–¹å¼ï¼Œå§”å±ˆä»»ä½•ä¸€æ–¹ï¼Œéƒ½ä¼šä½¿çŸ›ç›¾æ¿€åŒ–ã€‚å¦ˆä¹Ÿå¥½ï¼Œè€å©†ä¹Ÿå¥½ï¼Œåº•çº¿éƒ½ç»™å¥¹ä»¬ç”»å¥½ã€‚äººéƒ½æ˜¯æœ‰é€‰æ‹©æ€§çš„ï¼Œæ—¢ç„¶è¦ä¸åˆ°ç‰¹æƒï¼Œè‡ªç„¶ä¼šæ³¨æ„å½¼æ­¤ç›¸å¤„ã€‚ä¸€å¼€å§‹å¯èƒ½ç”·äººæ—¥å­ä¸å¤ªå¥½è¿‡ï¼Œä¸¤è¾¹éƒ½è¦æ–—ä¸Šå‡ æ¬¡ã€‚ä½†æ˜¯æ…¢æ…¢çš„ï¼Œå®¶åº­ç§©åºå°±ä¼šèµ°ä¸Šæ­£è½¨ã€‚ å¦‚æœä¸€å¼€å§‹å›¾çœå¿ƒï¼Œå“„è¿‡å»ï¼Œä¸¤è¾¹è„¾æ°”éƒ½å…»å¤§äº†å°±å¤Ÿè‡ªå·±å—äº†ã€‚ï¼ˆå‰é¢å¿˜äº†è¯´äº†ï¼Œæ‰¾å¥³äººä¸€å®šè¦æ‰¾ä¸ªèªæ˜çš„ï¼Œç¬¨å¥³äººå¤šå¾ˆå¤šéº»çƒ¦ï¼Œèªæ˜çš„å¥³äººè‡ªå·±ä¼šå¤„ç†ï¼Œè‡ªå·±åªç”¨æ‰“æ‰“ä¸‹æ‰‹ï¼Œå…³ç³»å°±å¤„çš„å¾ˆå¥½äº†ã€‚ï¼‰</p>
<p>è¿˜æœ‰ä¸ªé—®é¢˜ï¼Œå°±æ˜¯å­å¥³ï¼Œç°åœ¨çš„å­©å­æ‰çœŸå«ä¸€ä¸ªå®è´ï¼Œä¸€å¤§å®¶äººå›´ç€è½¬ï¼Œå„æœ‰å„çš„ä¸»æ„ï¼Œå¾ˆå¤šçŸ›ç›¾éƒ½æ˜¯å› æ­¤è€Œèµ·ï¼Œåœ¨è¿™ä¸€ç‚¹ä¸Šï¼Œç”·äººä¸€å®šè¦å¼ºç¡¬ï¼Œä»ä¸€å¼€å§‹å°±ç»å¯¹ä¸èƒ½è®©æ­¥ï¼Œè¦ç»™å‡ºæ˜ç¡®çš„ä¿¡å·ï¼Œå­©å­æ˜¯è‡ªå·±çš„ã€‚åŒæ–¹çˆ¶æ¯è‚¯å¸®å¿™ï¼Œæ„Ÿè°¢ã€‚ä½†æ˜¯æ¶‰åŠå­©å­çš„ä¸€åˆ‡å†³å®šã€‚å¿…é¡»æ˜¯è‡ªå·±æ‹¿ä¸»æ„ã€‚ï¼ˆè¿™ä¸€ç‚¹èƒŒåœ°é‡Œå¯ä»¥å¤šå¬è€å©†çš„ï¼Œæ¯•ç«Ÿï¼Œå¦ˆå¦ˆæ˜¯æœ€çˆ±å­©å­çš„ã€‚ï¼‰è¿™ä¸€ç‚¹ç”³æ˜å°¤å…¶é‡è¦ï¼Œç›¸å½“äºè‡ªå·±ä¸€ä¸ªäººæŠŠæ‰€æœ‰ç‚®ç«æ½äº†ã€‚å¦åˆ™ï¼Œå­©å­ä¸€ç‚¹ç‚¹å°æ„Ÿå†’å®¶é‡Œå¯ä»¥é—¹ç¿»å¤©ã€‚ï¼ˆæˆ‘é‚£ä»Šå¤©ç¦»å©šçš„æœ‹å‹å°±æ˜¯å› ä¸ºè¿™ä¸ªï¼‰ã€‚</p>
<p>å©šå§»ç¡®å®æ˜¯ä¸ªå¤§è¯é¢˜ï¼Œä¸€æ—¶åè€Œä¸çŸ¥é“è¯´ä»€ä¹ˆå¥½äº†ï¼Œæˆ‘æ˜¯çœŸå¿ƒæƒ³å’Œå¤§å®¶äº¤æµä¸€ä¸‹ã€‚å› ä¸ºæˆ‘è‡ªè®¤ä¸ºè‡ªå·±çš„å©šå§»çœŸçš„æ˜¯ç§å¹¸ç¦ã€‚æˆ‘æ˜¯çœŸå¿ƒå¸Œæœ›æœ‰æ›´å¤šçš„äººèƒ½æ„‰å¿«çš„äº«å—å©šå§»ã€‚æœ‰äººè¯´ä¸åµæ¶ä¸ç®—å¤«å¦»ï¼Œè¯´çœŸçš„ï¼Œæˆ‘å’Œæˆ‘è€å©†çœŸè¿˜åµä¸èµ·æ¥æ¶ï¼Œå°±åƒæˆ‘å‰é¢è¯´çš„ï¼Œä¼¤å½¼æ­¤çš„è¯ç¡®å®ä¸å¿å¿ƒè®²å‡ºå£ã€‚ä½•å†µä¸€æ—¦æ¸…æ¥šå½¼æ­¤éƒ½æ˜¯å‡ºäºçˆ±ï¼Œåˆæœ‰ä»€ä¹ˆå¥½åµçš„ï¼Ÿæœ‰å‡ æ¬¡åˆšè¿›å…¥çŠ¶æ€ï¼Œçœ‹è§å½¼æ­¤è£…è…”ä½œåŠ¿ç”Ÿæ°”çš„æ ·å­å°±éƒ½ç¬‘äº†ã€‚</p>
<p>512åœ°éœ‡çš„æ—¶å€™ï¼Œæˆ‘åœ¨éœ‡åŒºï¼Œè¿™ä¹ˆå¤§çš„åŸå¸‚ï¼Œé€šè®¯ä¸­æ–­çš„æƒ…å†µä¸‹ï¼Œæˆ‘ç¬¬ä¸€æ—¶é—´è§åˆ°äº†æˆ‘çš„è€å©†ï¼Œä¸åœ¨æˆ‘ä»¬ä¸Šç­çš„é™„è¿‘ï¼Œä¹Ÿä¸åœ¨æˆ‘ä»¬å®¶é™„è¿‘ï¼Œè€Œæ˜¯åœ¨æˆ‘çˆ¶æ¯çš„å®¶é—¨å£ã€‚å¥¹çŸ¥é“ä½“è°…æˆ‘æ‹…å¿ƒçˆ¶æ¯çš„å¿ƒæƒ…ï¼Œæˆ‘çŸ¥é“å¥¹èƒ½ä½“è°…æˆ‘ã€‚è¿™å°±æ˜¯å©šå§»çš„é»˜å¥‘ã€‚ä¹Ÿæ˜¯å©šå§»å’Œæ‹äººçš„åŒºåˆ«ï¼Œå©šå§»æ‰¿è½½çš„æ›´å¤šã€‚</p>
<p>æ‹äººæ—¶åˆ»åªæœ‰ç”œèœœå’Œæµªæ¼«ï¼Œè€Œå©šå§»åˆ™æ›´å¤šæ˜¯è´£ä»»å’Œå¹³æ·¡ï¼Œè¿™ä¸ªè½¬åŒ–çš„è¿‡ç¨‹ï¼Œæ˜¯éœ€è¦åŒæ–¹æœ‰å……è¶³æ€æƒ³å‡†å¤‡çš„ã€‚å…¶å®åªè¦ä¸¤ä¸ªäººè‚¯ä¸€èµ·é¢å¯¹ï¼Œå©šå§»ç”Ÿæ´»å¹³æ·¡ä¸­çš„å¹¸ç¦å¹¶ä¸è¾“ç»™çƒ­æ‹æ—¶çš„æµªæ¼«ã€‚</p>
<blockquote>
<p>è½¬è½½åœ¨<a href="https://www.zhihu.com/question/19732277/answer/1056367198">çŸ¥ä¹</a></p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[nvidia-smiæŒ‡ä»¤æŠ¥é”™ï¼šFailed to initialize NVML: Driverè§£å†³]]></title>
        <id>https://sunyanhust.github.io/post/nvidia-smi-zhi-ling-bao-cuo-failed-to-initialize-nvml-driver-jie-jue/</id>
        <link href="https://sunyanhust.github.io/post/nvidia-smi-zhi-ling-bao-cuo-failed-to-initialize-nvml-driver-jie-jue/">
        </link>
        <updated>2020-04-05T15:18:44.000Z</updated>
        <content type="html"><![CDATA[<p>æœ€è¿‘è£…æ·±åº¦å­¦ä¹ ç¯å¢ƒçš„æ—¶å€™é‡è§çš„ï¼Œä¸»è¦åŸå› æ˜¯æ—§çš„æ˜¾å¡é©±åŠ¨æ²¡å¸è½½ã€‚</p>
<p>é¦–å…ˆéœ€è¦å¸è½½é©±åŠ¨</p>
<pre><code class="language-shell">sudo apt-get purge nvidia*
</code></pre>
<p>ç„¶åé‡æ–°å®‰è£…æ–°çš„é©±åŠ¨å³å¯ã€‚</p>
<p>å‚è€ƒæ–‡ç« ï¼šhttps://www.zhihu.com/people/sun-yan-90-29</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[æœ‰è¶£çš„ç½‘ç«™]]></title>
        <id>https://sunyanhust.github.io/post/you-qu-de-wang-zhan/</id>
        <link href="https://sunyanhust.github.io/post/you-qu-de-wang-zhan/">
        </link>
        <updated>2020-04-05T14:42:54.000Z</updated>
        <content type="html"><![CDATA[<h2 id="éŸ³ä¹">ğŸ“»éŸ³ä¹</h2>
<ul>
<li><a href="http://music.qkhhyiu.cn/">éŸ³ä¹æœç´¢å™¨</a>: å¤šç«™åˆä¸€éŸ³ä¹æœç´¢è§£å†³æ–¹æ¡ˆ</li>
<li><a href="http://guozhivip.com/yinyue/">æœæ±éŸ³ä¹</a></li>
</ul>
<h2 id="æœç´¢">ğŸ”®æœç´¢</h2>
<ul>
<li><a href="https://scholar.chongbuluo.com/">è™«éƒ¨è½</a></li>
<li><a href="http://guozhivip.com/so/">æœæ±æœç´¢</a></li>
<li><a href="https://jikipedia.com/">å°é¸¡è¯å…¸</a>ï¼šç½‘ç»œæµè¡Œè¯­</li>
<li><a href="https://zh.wikihow.com/%E9%A6%96%E9%A1%B5">wikihow</a>ï¼šç”Ÿæ´»ç»´åŸºç™¾ç§‘</li>
</ul>
<h2 id="æ’è¡Œæ¦œ">ğŸ“œæ’è¡Œæ¦œ</h2>
<ul>
<li><a href="http://guozhivip.com/rank/">æœæ±æ’è¡Œæ¦œ</a></li>
<li><a href="https://tophub.today/">ä»Šæ—¥çƒ­æ¦œ</a></li>
</ul>
<h2 id="å…¶ä»–">ğŸ“š å…¶ä»–</h2>
<ul>
<li>
<p><a href="http://guozhivip.com/eat/">ä»Šå¤©åƒå•¥å‘€</a></p>
</li>
<li>
<p><a href="http://www.underseacat.com/fan">äº‘é£æ‰‡</a>ï¼šå¿ƒé™è‡ªç„¶å‡‰</p>
</li>
<li>
<p><a href="https://fonts.safe.360.cn/">360æŸ¥å­—ä½“</a> ï¼šä½ çš„å­—ä½“èƒ½å•†ç”¨å—</p>
</li>
<li>
<p><a href="https://www.gaoding.com/koutu">æå®šæŠ å›¾</a></p>
</li>
<li>
<p><a href="http://www.nows.fun/">æ¯’é¸¡æ±¤</a></p>
</li>
<li></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[æ–‡ç« æ±‡æ€»ï¼šèåˆBNåŠ é€Ÿæ¨ç†ã€BERTæ¨ç†åŠ é€Ÿå®è·µã€pytorch C++å‰ç«¯æ¨ç†æ¨¡å‹ä»¥åŠReZero: ä½¿ç”¨åŠ æƒæ®‹å·®è¿æ¥åŠ é€Ÿæ·±åº¦æ¨¡å‹æ”¶æ•›]]></title>
        <id>https://sunyanhust.github.io/post/wen-zhang-hui-zong-rong-he-bn-jia-su-tui-li-bert-tui-li-jia-su-shi-jian-pytorch-cqian-duan-tui-li-mo-xing-yi-ji-rezero-shi-yong-jia-quan-can-chai-lian-jie-jia-su-shen-du-mo-xing-shou-lian/</id>
        <link href="https://sunyanhust.github.io/post/wen-zhang-hui-zong-rong-he-bn-jia-su-tui-li-bert-tui-li-jia-su-shi-jian-pytorch-cqian-duan-tui-li-mo-xing-yi-ji-rezero-shi-yong-jia-quan-can-chai-lian-jie-jia-su-shen-du-mo-xing-shou-lian/">
        </link>
        <updated>2020-04-04T14:48:05.000Z</updated>
        <content type="html"><![CDATA[<h2 id="èåˆbnåŠ é€Ÿæ¨ç†">ğŸ“šèåˆBNåŠ é€Ÿæ¨ç†</h2>
<p>æ‰¹å½’ä¸€åŒ–ï¼ˆBatch Normalizationï¼‰å› å…¶å¯ä»¥åŠ é€Ÿç¥ç»ç½‘ç»œè®­ç»ƒã€ä½¿ç½‘ç»œè®­ç»ƒæ›´ç¨³å®šï¼Œè€Œä¸”è¿˜æœ‰ä¸€å®šçš„æ­£åˆ™åŒ–æ•ˆæœï¼Œæ‰€ä»¥å¾—åˆ°äº†éå¸¸å¹¿æ³›çš„åº”ç”¨ã€‚ä½†æ˜¯ï¼Œåœ¨æ¨ç†é˜¶æ®µï¼ŒBNå±‚ä¸€èˆ¬æ˜¯å¯ä»¥å®Œå…¨èåˆåˆ°å‰é¢çš„å·ç§¯å±‚çš„ï¼Œè€Œä¸”ä¸æ¯«ä¸å½±å“æ€§èƒ½ã€‚<br>
<strong>å‚è€ƒæ–‡ç« </strong>ï¼š<a href="https://zhuanlan.zhihu.com/p/120265831">æ·±åº¦å­¦ä¹ æ¨ç†æ—¶èåˆBN,è½»æ¾è·å¾—çº¦5%çš„æé€Ÿ</a><br>
<strong>ä»£ç </strong>ï¼škerasçš„æš‚æ—¶æ²¡æœ‰æ‰¾åˆ°ï¼Œæœ‰ç©ºå¯ä»¥å†™å†™</p>
<h2 id="bertæ¨ç†åŠ é€Ÿå®è·µ">ğŸ“šBERTæ¨ç†åŠ é€Ÿå®è·µ</h2>
<p>ä¸»è¦åŸºäºFaster Transformerï¼Œ<strong>å‚è€ƒæ–‡ç« </strong>ï¼š</p>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/89694963">BERTæ¨¡å‹æ¨ç†åŠ é€Ÿæ€»ç»“</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/91024786">BERTæ¨ç†åŠ é€Ÿå®è·µ</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/73715272">NVIDIA BERTæ¨ç†è§£å†³æ–¹æ¡ˆFaster Transformerå¼€æºå•¦</a></li>
</ol>
<h2 id="pytorch-cå‰ç«¯æ¨ç†æ¨¡å‹">ğŸ“špytorch C++å‰ç«¯æ¨ç†æ¨¡å‹</h2>
<p>ä½¿ç”¨libtorch C++å‰ç«¯æ¥æ¨ç†å¤æ‚æ¨¡å‹ï¼Œå¯èƒ½ä¼šç”¨åˆ°ã€‚<strong>å‚è€ƒæ–‡ç« </strong>ï¼š<a href="https://zhuanlan.zhihu.com/p/69421019">å«Œpythonæ…¢ï¼Ÿæ¥è¿™é‡Œç”¨pytorch C++å‰ç«¯æ¨ç†æ¨¡å‹</a></p>
<h2 id="rezero-ä½¿ç”¨åŠ æƒæ®‹å·®è¿æ¥åŠ é€Ÿæ·±åº¦æ¨¡å‹æ”¶æ•›">ğŸ“šReZero: ä½¿ç”¨åŠ æƒæ®‹å·®è¿æ¥åŠ é€Ÿæ·±åº¦æ¨¡å‹æ”¶æ•›</h2>
<p><strong>è®ºæ–‡æ ‡é¢˜</strong>ï¼šReZero is All You Need: Fast Convergence at Large Depth</p>
<p><strong>è®ºæ–‡ä½œè€…</strong>ï¼šThomas Bachlechner, Bodhisattwa Prasad Majumder, Huanru Henry Mao, Garrison W. Cottrell, Julian McAuley</p>
<p><strong>è®ºæ–‡é“¾æ¥</strong>ï¼šhttps://arxiv.org/abs/2003.04887</p>
<p><strong>ä»£ç é“¾æ¥</strong>ï¼šhttps://github.com/majumderb/rezero</p>
<p>ç®€å•æ¥è¯´å¯¹æ®‹å·®è¿›è¡Œäº†åŠ æƒå¹¶åˆå§‹åŒ–æƒé‡ä¸º0æ¥åŠ å¿«ç½‘ç»œæ”¶æ•›é€Ÿåº¦ã€‚æ€è·¯æ¯”è¾ƒæ¸…æ™°ï¼Œå¯è¯æ˜ä¹Ÿworkï¼Œå…·ä½“å‚è€ƒæ–‡ç« <a href="https://zhuanlan.zhihu.com/p/113384612">ReZero: ä½¿ç”¨åŠ æƒæ®‹å·®è¿æ¥åŠ é€Ÿæ·±åº¦æ¨¡å‹æ”¶æ•›</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[æ–°å† ç—…æ¯’å…¨çƒå¤§æµè¡Œï¼šæˆ‘ä»¬ç¼ºä¹çš„åªæ˜¯ç–«è‹—ï¼Ÿ]]></title>
        <id>https://sunyanhust.github.io/post/xin-guan-bing-du-quan-qiu-da-liu-xing-wo-men-que-fa-de-zhi-shi-yi-miao/</id>
        <link href="https://sunyanhust.github.io/post/xin-guan-bing-du-quan-qiu-da-liu-xing-wo-men-que-fa-de-zhi-shi-yi-miao/">
        </link>
        <updated>2020-04-04T14:18:07.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>æœ¬æ–‡è½¬è‡ªå¾®ä¿¡å…¬ä¼—å·ï¼Œ<a href="https://mp.weixin.qq.com/s?__biz=MjM5MjYxOTQ2NA==&amp;mid=2650202369&amp;idx=1&amp;sn=738db7d0fc8c69f2dbe5b8ad64ae09e5&amp;chksm=bea1cfa689d646b0183608329abdbf11c53f64924ce476a219bc39cbb7373805c3dbaf36c936&amp;mpshare=1&amp;scene=23&amp;srcid=0404YwhJm01ENyZGtvQaeyr6&amp;sharer_sharetime=1586009335106&amp;sharer_shareid=47825813c3bfc95e426cc37b214c1ac0#rd">åŸæ–‡</a>ã€‚ä¸ªäººè§‰å¾—å†™å¾—éå¸¸å¥½ï¼Œä½œä¸ºæ­¤æ¬¡ç–«æƒ…çš„åæ€å’Œæ€»ç»“ã€‚</p>
</blockquote>
<p>åˆä¸€æ¬¡çš„å¼€å­¦å…¸ç¤¼ä»˜è¯¸ä¸œæµï¼Œè¿™ä¸€æ¬¡æ˜¥å¤©çš„å…¸ç¤¼æ˜¯å› ä¸ºæ–°å† è‚ºç‚ï¼Œä¸Šä¸€æ¬¡å†¬å¤©çš„å…¸ç¤¼æ˜¯å› ä¸ºé¦™æ¸¯åŠ¨è¡ã€‚ä¸å°‘æœ‹å‹é—®æˆ‘æ€ä¹ˆæ²¡æœ‰çœ‹åˆ°æˆ‘åœ¨æ–°å† è‚ºç‚ä¸‹çš„æ¼”è®²ã€è§‚ç‚¹å’Œæ–‡ç« ï¼Ÿè¿‘ä¸¤ä¸ªæœˆé‡Œï¼Œå¥½æ–‡ä½•æ­¢ä¸Šç™¾ä¸Šåƒï¼Ÿæœ‰å¤šå°‘ä»ç–«æƒ…ä¸­å¤®å‘å‡ºçš„ä»¤äººæ½¸ç„¶æ³ªä¸‹çš„äº²èº«ç»å†ï¼Ÿæœ‰å¤šå°‘å‘è‡ªå†…å¿ƒçš„è‡ªçœå’Œæ€è€ƒï¼Ÿæœ‰å¤šå°‘å¯¹å›½å®¶æœªæ¥çš„ç„¦è™‘å’ŒæœŸè®¸ï¼Ÿæˆ‘ä»¬å·²ç»å¥½ä¹…æ²¡æœ‰ç»å†è¿‡è¿™æ ·çš„åœºé¢ï¼Œåœ¨åŒä¸€ä¸ªæ—¶åˆ»ã€ä¸ºåŒä¸€ä¸ªäººã€ä¸ºåŒä¸€ä»¶äº‹å‘å‡ºæˆ‘ä»¬è°¦å‘çš„å£°éŸ³ï¼Œå¹èµ·æˆ‘ä»¬çš„å£å“¨å£°ï¼Ÿè€Œè¿™éƒ½æ˜¯ä¸ºäº†åŒä¸€ä¸ªç›®æ ‡ï¼Œå¸Œæœ›ç±»ä¼¼çš„æ‚²å‰§å¯ä»¥å†å°‘äº›ï¼›å¸Œæœ›æˆ‘ä»¬æ— éœ€ç”Ÿæ´»åœ¨ä¸å¿…è¦çš„ææƒ§ä¹‹ä¸­ï¼›å¸Œæœ›è¿™ä¸ªæ°‘æ—æ— è®ºä½•æ—¶éƒ½æ˜¯è¢«äººæ•¬é‡çš„ã€‚</p>
<p>è¿™å½“ç„¶æ˜¯ä¸€åœºç¾éš¾ã€‚åºšå­é¼ å¹´ä»¥è¶…å‡ºæ‰€æœ‰äººçš„æƒ³è±¡åŠ›ï¼Œå¼€å§‹äº†è¿™ä¸€åœºå¤©ç¾ï¼Œä½†è¿™ä¹Ÿæ˜¯ä¸€åœºäººç¥¸ã€‚æ ¹æ®è‹±å›½å—å®‰æ™®æ•¦å¤§å­¦çš„ç ”ç©¶ï¼Œå¦‚æœæ­¦æ±‰æå‰ä¸‰ä¸ªæ˜ŸæœŸå¼€å§‹ç‹™å‡»è¿™ä¸€ç—…æ¯’ï¼Œä»…ä¸­å›½å—æ„ŸæŸ“çš„æ•°ç›®å°±å¯ä»¥å‡å°‘95%ã€‚å½“ç„¶è¿™åªæ˜¯ä¸€é¡¹ç ”ç©¶ï¼Œè€Œç°å®ä¸æ•°å­—æ¨¡å‹ä¹‹é—´å­˜åœ¨çš„è·ç¦»æœ‰æ—¶å¯ä»¥æ˜¯å¦‚æ­¤ä¹‹å¤§ï¼å¦‚æœæ­¦æ±‰å°åŸä¹‹åæ¬§ç¾å„å›½ä¸ä¼šå¦‚æ­¤å‚²æ…¢ï¼Œè€Œæ˜¯ç§¯æåˆä½œåº”å¯¹ï¼Œä»Šå¤©çš„æ¬§æ´²å’Œç¾å›½æˆ–è®¸å°±ä¸ä¼šé¢å¯¹è¿™æ ·çš„äººé“å±æœºï¼åœ¨å…¨çƒé¢ä¸´è¿™æ ·çš„å¤§ç¾éš¾é¢å‰ï¼Œç›¸åï¼Œæˆ‘ä»¬çœ‹åˆ°çš„æ˜¯è‡ªç§ä¸è‡ªå¤§ã€å˜²è®½ä¸æŒ‡è´£ã€ææƒ§ä¸æ¨å¸ï¼Œç”šè‡³é˜´è°‹è®ºç”šåš£å°˜ä¸Šï¼Œä»£æ›¿äº†ç†æ€§çš„æ€è€ƒå’Œåº”æœ‰çš„åæ€ã€‚é¢å¯¹è¿™æ ·çš„ä¸–çºªç–«æƒ…å¤§æµè¡Œçš„ææƒ§ï¼Œæˆ‘ä»¬ç¼ºä¹çš„è¿œéæ§åˆ¶ç–«æƒ…çš„ç–«è‹—ï¼</p>
<p>æˆ‘ä»¬ç¼ºä¹å¸¸è¯†ï¼›æˆ‘ä»¬ç¼ºä¹è§è¯†ï¼›æˆ‘ä»¬ç¼ºä¹é€æ˜åº¦ï¼›æˆ‘ä»¬ç¼ºä¹åŒç†å¿ƒï¼›æˆ‘ä»¬ç¼ºä¹æ‹…å½“ï¼›æˆ‘ä»¬ç¼ºä¹åæ€â€¦â€¦</p>
<h2 id="æˆ‘ä»¬ç¼ºä¹å¸¸è¯†">æˆ‘ä»¬ç¼ºä¹å¸¸è¯†</h2>
<p>åœ¨è¿™åœºç–«æƒ…å¸­å·å…¨çƒæ—¶ï¼Œæ–°å† è‚ºç‚ä¹Ÿæˆäº†é˜´è°‹è®ºçš„æ¸©åºŠã€‚çŸ­çŸ­çš„ä¸€ä¸ªå¤šæœˆæ—¶é—´é‡Œï¼Œæœ‰æ­¦æ±‰ç—…æ¯’ç ”ç©¶æ‰€ç—…æ¯’å¤–æ¼çš„â€œæ³„æ¯’ä¹‹è¯´â€ï¼Œæœ‰ç¾å›½é©»æ­¦æ±‰é¢†äº‹é¦†ç•™ä¸‹å…«ä¸ªå¯ç–‘ç”ŸåŒ–æ¯’ç‰©ç®±çš„â€œç§æ¯’ä¹‹è¯´â€ï¼Œæœ‰ç¾å›½å‚è®®å‘˜æŸ¯é¡¿æŒ‡æ§æ¯’æºæ¥è‡ªå¤§é™†ç”ŸåŒ–å®éªŒå®¤çš„â€œæ”¾æ¯’ä¹‹è¯´â€ï¼Œæœ‰æ­¦æ±‰å†›è¿ä¼šæœŸé—´ç¾å›½å…µâ€œæ’­æ¯’ä¹‹è¯´â€ï¼Œè«è¡·ä¸€æ˜¯ã€‚æˆ‘ä»ä¸€å¼€å§‹å°±å¯¹é˜´è°‹è®ºå­˜ç–‘ï¼Œæˆ‘æ€»è§‰å¾—äººæ€§è™½æ¶ï¼Œä½†äººç±»çš„æ¶è¡Œè¿˜ä¸è‡³äºå¦‚æ­¤åŒªå¤·æ‰€æ€ã€‚æœ‰äº›æŒ‡æ§ï¼Œç¨å¾®æ±‚è¯ï¼Œå°±çŸ¥é“æ˜¯èƒ¡è¨€ä¹±è¯­ã€‚ç¾å›½é©»æ­¦æ±‰æ€»é¢†äº‹é¦†ä½äºæ­¦æ±‰æ–°ä¸–ç•Œå›½è´¸å¤§æ¥¼ç¬¬47æ¥¼ï¼Œåé™¢åœ¨å“ªé‡Œï¼Ÿç”ŸåŒ–æ¯’ç‰©ç®±åˆå¦‚ä½•åŸ‹åœ¨åœ°ä¸‹1.5å…¬å°ºå¤„ï¼Ÿè°è¨€å“—ä¼—å–å® ï¼Œä½†ä¿¡è€…ä¼—ï¼å¦‚æœç—…æ¯’æ¥è‡ªä¸­å›½çš„ç”Ÿç‰©åŸºå› ä½œæˆ˜å®éªŒå®¤ï¼Œå¯¹ç—…æ¯’çš„è®¤è¯†å’Œæ§åˆ¶è¿˜ä¼šé‚£ä¹ˆéš¾å—ï¼Ÿè¿™æ ·ä½æ°´å‡†çš„é˜´è°‹è®ºç«Ÿç„¶ç•…è¡Œå…¨çƒï¼å…¶å®åªè¦æœ‰åŸºæœ¬å¸¸è¯†ï¼Œåæ™ºçš„é˜´è°‹è®ºå°±ä¸å¯èƒ½å¤§è¡Œå…¶é“ã€‚</p>
<p>æˆ‘ä»¬ç¼ºä¹å¸¸è¯†ä¹Ÿå› ä¸ºæˆ‘ä»¬å¸¸å¸¸ä»¥åç›–å…¨ï¼Œä¿¡æ¯ä¸å¯¹ç§°ã€‚æ„å¤§åˆ©ä¸“å®¶é›·ç©†é½ï¼ˆGiuseppe Remuzziï¼‰è¡¨ç¤ºæ—©åœ¨å»å¹´11æœˆä»½ï¼Œæ„å¤§åˆ©åŒ—éƒ¨å°±æœ‰äººæŸ“ä¸Šé«˜åº¦ç–‘ä¼¼æ–°å† è‚ºç‚çš„ä¸æ˜è‚ºç‚ã€‚ä¸­å›½çš„ä¸€äº›åª’ä½“ç¬¬ä¸€æ—¶é—´å°±æŠ¥é“äº†æ„å¤§åˆ©æ˜¯æºå¤´çš„è¯´æ³•ï¼Œè®©ä¸å°‘ä¸­å›½äººä¿¡ä»¥ä¸ºçœŸã€‚ä¸­å›½çš„è®°è€…è¿˜çº·çº·æ‰“ç”µè¯å»é‡‡è®¿ï¼Œä»–å¯¹è‡ªå·±æ—©å…ˆçš„é‡‡è®¿è¢«æ–­ç« å–ä¹‰éå¸¸ä¸æ»¡ï¼Œå¹¶æŒ‡å‡ºè¿™æ˜¯æ•™ç§‘ä¹¦å¼çš„â€œå®£ä¼ æ‰‹æ®µâ€ã€‚ä½†ä¹‹åä»–çº æ­£ä¸­å›½åª’ä½“çš„è¯´æ³•ï¼Œå¹¶æ²¡æœ‰è¢«å¹¿æ³›æŠ¥é“ã€‚ä»–è¿˜åœ¨å¦ä¸€ä¸ªåœºåˆè¡¨ç¤ºï¼Œæ­¦æ±‰å¯èƒ½æ—©å·²å‡ºç°æ–°å† è‚ºç‚æ„ŸæŸ“ï¼ŒæœŸé—´æœ‰å¤§é‡ä¸­å›½äººä»æ­¦æ±‰æ¥åˆ°æ„å¤§åˆ©ï¼Œä»¤æ„å¤§åˆ©å‡ºç°äº†ç–‘ä¼¼æ¡ˆä¾‹ï¼Œç”±äºä¸€åˆ‡æ¥è‡ªä¸­å›½çš„ä¿¡æ¯éƒ½ä¸é€æ˜ï¼Œæ‰ä»¤ç–«æƒ…å¤±å»æ§åˆ¶çš„é»„é‡‘æ—¶æœºã€‚å…¶å®æ„å¤§åˆ©åŒ—éƒ¨æ¸©å·çš„äººå¾ˆå¤šï¼Œè€Œä¸€æœˆçš„æ—¶å€™ï¼Œé™¤äº†æ­¦æ±‰ï¼Œæ¸©å·ç–«æƒ…ä¹Ÿå¾ˆä¸¥é‡ã€‚åœ¨ä¸­å›½å°±æœ‰ä¸“å®¶å› çœ‹åˆ°æµ™æ±Ÿæœ‰äººæ„ŸæŸ“ä¹‹åï¼Œå¼ºçƒˆå»ºè®®æ­¦æ±‰å¿…é¡»å°åŸã€‚</p>
<p>ç–«æƒ…åˆšçˆ†å‘æ—¶ï¼Œæœ‰ä¸å°‘äººæ€»åœ¨é‚£é‡Œè´¨é—®ï¼Œç¾å›½æ¯å¹´å­£èŠ‚æ€§æµæ„Ÿæ­»äº†æˆåƒä¸Šä¸‡äººï¼Œæ— äººææ…Œï¼Œä¸–ç•Œå„å›½æ²¡æœ‰åˆ‡æ–­å’Œç¾å›½çš„è”ç³»ï¼Œä½†ç¾å›½ä¸ºä½•è¦åˆ‡æ‰å’Œä¸­å›½çš„è”ç³»ï¼Ÿè¿™æ˜¯å¦è¿‡åº¦ååº”ï¼Ÿæ˜¯å¦æ­§è§†ä¸­å›½ï¼Ÿæ˜¯å¦è¿åä¸–ç•Œå«ç”Ÿç»„ç»‡çš„æŒ‡å¼•ï¼Ÿä½†å­£èŠ‚æ€§æµæ„Ÿæœ‰ç–«è‹—ï¼Œæ­»äº¡ç‡åªæœ‰æ–°å† è‚ºç‚çš„ååˆ†ä¹‹ä¸€ï¼Œè¿™æ ·çš„äº‹å®å¾ˆå¤šäººå¹¶ä¸äº†è§£ã€‚å¦‚ä»Šçœ‹åˆ°ç–«æƒ…è”“å»¶å…¨çƒï¼Œçº½çº¦æˆä¸ºå¦ä¸€ä¸ªæ­¦æ±‰ï¼Œå¤§å®¶åº”è¯¥å¯ä»¥æ˜ç™½æ¯å¹´åœ¨ç¾å›½å‘ç”Ÿçš„å­£èŠ‚æ€§æµæ„Ÿå’Œæ–°å† è‚ºç‚ä¹‹é—´çš„æ ¹æœ¬ä¸åŒã€‚</p>
<p>æˆ‘ä»¬ç¼ºä¹å¸¸è¯†æ˜¯å› ä¸ºæˆ‘ä»¬å—åˆ¶äºæˆ‘ä»¬æœ‰é™çš„çŸ¥è¯†å’Œè§è¯†ï¼Œæ— æ³•è®¤è¯†äº‹ç‰©çš„çœŸç›¸ï¼›æˆ‘ä»¬ç¼ºä¹å¸¸è¯†ä¹Ÿæ˜¯å› ä¸ºæˆ‘ä»¬é¢å¯¹ææƒ§è€ŒæƒŠæ…Œå¤±æªï¼Œæ— æ³•ç†æ€§åœ°çœ‹å¾…è‡ªåª’ä½“æ—¶ä»£æ‰€è·å¾—çš„è™šå‡èµ„è®¯ï¼›æˆ‘ä»¬ç¼ºä¹å¸¸è¯†ä¹Ÿæ˜¯å› ä¸ºæˆ‘ä»¬çš„ç«‹åœºå’Œåè§æŒ¡ä½äº†è‡ªå·±çš„è§†çº¿ï¼Œæ— æ³•èµ°å‡ºåŸæœ‰çš„è®¤çŸ¥ã€‚</p>
<h2 id="æˆ‘ä»¬ç¼ºä¹è§è¯†">æˆ‘ä»¬ç¼ºä¹è§è¯†</h2>
<p>åŒæ ·åœ¨æ¬§ç¾å„å›½ï¼Œä¸å°‘äººè¿˜çœŸçš„å°†æ–°å† è‚ºç‚å’Œå­£èŠ‚æ€§æµæ„Ÿç­‰åŒèµ·æ¥ï¼Œæ ¹æœ¬ä¸æŠŠæ–°å† ç—…æ¯’å½“å›äº‹ï¼Œé…¿æˆä»Šæ—¥æ¬§ç¾å„å›½æ²¦é™·çš„æƒ¨ç—›æ•™è®­ã€‚åœ¨å‘ç”Ÿæ–°å† è‚ºç‚è¿™æ ·çš„å…¨çƒå…¬å…±åŒ»ç–—å±æœºæ—¶ï¼Œä¸è¦è¯´æ™®é€šäººï¼Œå³ä¾¿å…¨çƒæœ€é¡¶å°–çš„ä¼ æŸ“ç—…ä¸“å®¶å¯¹ç—…æ¯’éƒ½ç¼ºä¹è¶³å¤Ÿçš„è®¤è¯†ï¼ŒæŸæ‰‹æ— ç­–ï¼Œæ— æ³•é¢„è§å…¶å‘å±•æ–¹å‘ï¼Œè‡³å¤šåªèƒ½ä¾é æ¨¡å‹åšå‡ºæ¨ç®—ï¼Œä½†æœ€ç»ˆå’Œç°å®ä¹Ÿå¯èƒ½ç›¸è·ç”šè¿œã€‚åœ¨ç–«æƒ…åˆæœŸï¼Œä¸è¦è¯´è¥¿æ–¹çš„ä¸“å®¶ï¼Œå³ä¾¿å†…åœ°æœ€é¡¶å°–çš„ä¼ æŸ“ç—…ä¸“å®¶éƒ½ä¸è®¤ä¸ºè¿™æ¬¡ç–«æƒ…æ¯”â€œéå…¸â€ä¸¥é‡ã€‚å› é¦™æ¸¯çš„ç‰¹æ®Šåœ°ä½ï¼Œé¦™æ¸¯å¤§å­¦çš„ä¸“å®¶å­¦è€…æ•¢äºå‘å£°ï¼Œè¢å›½å‹‡æ•™æˆæ—©åœ¨1æœˆ3æ—¥å°±è­¦å‘Šé¦™æ¸¯æ”¿åºœï¼Œè¿™æ¬¡ç–«æƒ…æä¸ºä¸¥é‡ï¼Œé¦™æ¸¯ç‰¹åŒºæ”¿åºœæ—©åœ¨1æœˆ7æ—¥å°±å®£å¸ƒæŠŠâ€œä¸¥é‡æ–°å‹ä¼ æŸ“æ€§ç—…åŸä½“å‘¼å¸ç³»ç»Ÿç—…â€åˆ—ä¸ºé¡»å‘ˆæŠ¥çš„ç–¾ç—…ï¼Œå«ç”Ÿéƒ¨é—¨æœ‰æƒå¼ºåˆ¶éš”ç¦»æ€€ç–‘æ‚£è€…ã€‚ç®¡è½¶æ•™æˆæ˜¯é¦™æ¸¯å¤§å­¦æ–°å‘ä¼ æŸ“æ€§ç–¾ç—…å›½å®¶é‡ç‚¹å®éªŒå®¤ä¸»ä»»ï¼Œæœ€æ—©å‘å‡ºç–«æƒ…å°†å¤±æ§çš„è­¦å‘Šã€‚</p>
<p>é¦™æ¸¯å› 2003å¹´å—â€œéå…¸â€çš„æ²‰é‡æ‰“å‡»ï¼Œå¤§å®¶è®°å¿†çŠ¹æ–°ï¼Œä¸å°‘é¦™æ¸¯äººå¯¹æ–°å† è‚ºç‚éƒ½éå¸¸ææƒ§ï¼Œä¹Ÿå‡ºç°äº†æŠ¢è´­æ½®ã€‚ä½†åœ¨é¦™æ¸¯çš„è¥¿æ–¹äººå¯¹æ­¤çš„ååº”å°±å¤§ä¸ºä¸åŒï¼ŒåŒ…æ‹¬é¦™æ¸¯å¤§å­¦ä¸­çš„ç™½äººå­¦è€…ä¹Ÿè§‰å¾—è¿™æ˜¯ç±»ä¼¼æµæ„Ÿçš„ç—…æ¯’ï¼Œåªä¸è¿‡ä¼ æŸ“ç‡å’Œæ­»äº¡ç‡é«˜è€Œå·²ã€‚è¿™ç§åˆ¤æ–­ä¸€åº¦è®©æˆ‘è§‰å¾—é¦™æ¸¯æ˜¯å¦è¿‡åº¦ææ…Œäº†ï¼Œç‰¹åˆ«æ˜¯é¦™æ¸¯åŒ»åŠ¡äººå‘˜ä»¥ç½¢å·¥é€¼è¿«æ”¿åºœå°å…³çš„ä¸¾åŠ¨è¿‡æ¿€ï¼Œè¿èƒŒäº†åŒ»åŠ¡äººå‘˜æ•‘æ­»æ‰¶ä¼¤çš„ä¼¦ç†åº•çº¿ã€‚ç–«æƒ…åˆæœŸåœ¨é¦™æ¸¯è¡—ä¸Šä¹ŸåŸºæœ¬çœ‹ä¸åˆ°æœ‰å¤šå°‘è¥¿æ–¹äººæˆ´å£ç½©ï¼Œæ‰€ä»¥åœ¨è¥¿æ–¹çš„åäººå› ä¸ºæ‹…å¿ƒæ„ŸæŸ“ç—…æ¯’æˆ´å£ç½©ä¹Ÿè¢«è§†ä¸ºæ€ªç‰©ï¼Œä¸è¢«ç†è§£è¿˜ç®—æ¬¡è¦ï¼Œè¿˜å—åˆ°ç™½çœ¼å’Œæ­§è§†ï¼Œç”šè‡³é­äººæ¯’æ‰“ã€‚å› ä¸ºåœ¨è¥¿æ–¹çš„æ–‡åŒ–é‡Œï¼Œåªæœ‰å¾—ç—…çš„äººæ‰æˆ´å£ç½©ï¼Œè€Œä½ å¾—ç—…äº†å°±ä¸è¯¥å‡ºç°åœ¨å…¬ä¼—çš„åœ°æ–¹ã€‚å…¶å®è¥¿æ–¹äººè¿™æ ·çš„è¡Œä¸ºä¹Ÿæ˜¯å› è®¤çŸ¥å—é™ï¼Œè€Œè¯‰è¯¸æš´åŠ›çš„ä¸æ³•ä¹‹å¾’æ›´æ˜¯è”‘è§†äººæƒã€‚</p>
<p>è¿™æ¬¡ç–«æƒ…åœ¨æ¬§ç¾çš„è¿…é€Ÿè”“å»¶ç»ˆäºè®©è¥¿æ–¹æ„è¯†åˆ°æ–°å† ç—…æ¯’ä¸åªå±äºäºšæ´²äººï¼Œä»–ä»¬åŸå…ˆå†·çœ¼æ—è§‚ï¼Œä»¥ä¸ºç™½ç§äººå¯ä»¥åˆ€æªä¸å…¥ã€‚ç”šè‡³æ¬§ç¾çš„ä¸å°‘åŒ»å­¦ä¸“å®¶åˆæœŸéƒ½ä½ä¼°äº†è¿™ä¸ªç–«æƒ…çš„é£é™©ï¼Œä»æ„å¤§åˆ©å¤§æ„å¤±è†å·ï¼Œåˆ°è‹±å›½çš„â€œç¾¤ä½“å…ç–«â€ï¼Œå†åˆ°ç¾å›½çš„å…¨çº¿æ²¦é™·ï¼Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šéƒ½å’Œä»–ä»¬å¯¹è¿™ä¸ªç—…æ¯’çš„æœ‰é™è®¤çŸ¥æœ‰å…³ï¼Œè¯´éš¾å¬ç‚¹å°±æ˜¯æ— çŸ¥ã€‚å› æ­¤æ”¿åºœä¸æ•¢ä¸æ™®é€šæ°‘ä¼—çš„è®¤çŸ¥ç›¸å·¦ï¼Œè½»æ˜“åšå‡ºå°åŸçš„å†³å®šã€‚åŒ»å­¦ç•Œæœ¬èº«ä¹Ÿå­˜åœ¨å®Œå…¨å¯¹ç«‹çš„çœ‹æ³•ï¼Œç›´åˆ°ä¼¦æ•¦å¸å›½ç†å·¥å­¦é™¢æµè¡Œç—…ä¸“å®¶å°¼å°”Â·å¼—æ ¼æ£®å›¢é˜Ÿçš„ç ”ç©¶æŠ¥å‘Šåšå‡ºäº†ä»¤äººææƒ§çš„é¢„æµ‹ä¹‹åï¼Œè‹±ç¾ä¸¤å›½æ”¿åºœæ‰æ”¹å˜è¢«åŠ¨çš„åº”å¯¹ç­–ç•¥ã€‚è¿™ä»½ç ”ç©¶æŠ¥å‘Šè­¦å‘Šï¼Œå¦‚æœè‹±ç¾ä¸¤å›½ä¸ç§¯æåº”å¯¹ï¼Œè‹±å›½å°†ä¼šæœ‰è¶…è¿‡50ä¸‡çš„äººæ­»äº¡ï¼Œè€Œç¾å›½å°†æœ‰220ä¸‡äººæ­»äº¡ã€‚å³ä¾¿å¦‚æ­¤ï¼Œç‰›æ´¥å¤§å­¦çš„ç ”ç©¶å›¢é˜Ÿåœ¨æ­¤ä¹‹åè¿˜æ˜¯å¾—å‡ºæˆªç„¶ä¸åŒçš„ç»“è®ºï¼Œè®¤ä¸ºæ–°å† ç—…æ¯’åœ¨è‹±å›½å·²ç»ä¼ æ’­äº†ä¸€ä¸ªå¤šæœˆï¼Œå¤§çº¦ä¸€åŠäººå£å·²ç»è·å¾—äº†å®è´¨çš„ç¾¤ä½“å…ç–«èƒ½åŠ›ã€‚</p>
<p>å…¨çƒåœ¨åº”å¯¹è¿™ä¸ªæ–°å‹ç—…æ¯’çš„ä¾µè¢­æ—¶ï¼Œå› ä¸ºçŸ¥è¯†ä¸è¶³ï¼Œåšå‡ºäº†ä¸å°‘é”™è¯¯çš„åˆ¤æ–­ã€‚åœ¨ç–«æƒ…åˆæœŸï¼Œå¯¹ç—…æ¯’çš„ä¸¥é‡æ€§éš¾ä»¥åšå‡ºæ­£ç¡®çš„åˆ¤æ–­ï¼Œåœ¨è·å¾—äººä¼ äººçš„è¯æ®ä¹‹åæ‰è¢«è¿«åšå‡ºæ­¦æ±‰å°åŸçš„å†³å®šã€‚ä½†åŒæ—¶ä¹Ÿå› ä¸ºè®¤çŸ¥ä¸è¶³ï¼Œäººçš„è§è¯†æœ‰é™ï¼Œå½±å“äº†æˆ‘ä»¬åº”å¯¹ç—…æ¯’çš„ç­–ç•¥ã€‚ä¸œäºšåœ°åŒºæœ‰â€œéå…¸â€çš„æƒ¨é‡æ•™è®­å°±æä¸ºé‡è§†ï¼Œè¥¿æ–¹æ°‘ä¼—å¯¹æ–°å† ç—…æ¯’çš„è®¤çŸ¥åˆ™ä¸åŒï¼Œå®Œå…¨æ”¾ä»»ã€‚</p>
<p>æˆ‘ä»¬çš„è§è¯†å¸¸å¸¸å—é™äºæˆ‘ä»¬çš„ç”Ÿæ´»ç»å†å’Œç¯å¢ƒï¼Œä½†æˆ‘ä»¬ä¸å¯èƒ½äº²ä¸´å…¶å¢ƒå»è®¤çŸ¥æ¯ä¸€ä»¶äº‹ç‰©ï¼Œå› æ­¤è·å–å…¨é¢çš„ä¿¡æ¯å°±å˜å¾—è‡³å…³é‡è¦ã€‚ä¸å¹¸çš„æ˜¯æˆ‘ä»¬å› é˜²ç«å¢™æ— æ³•è·å¾—å®¢è§‚çš„ä¿¡æ¯ï¼Œå› å¤„åœ¨åŒæ¸©å±‚é‡Œæ‹’ç»ä¸åŒçš„ä¿¡æ¯ï¼Œæ›´ä¸è¦è¯´æˆ‘ä»¬å› ç¼ºä¹é€æ˜åº¦éš¾ä»¥æ¥æ”¶çœŸå®çš„ä¿¡æ¯ã€‚</p>
<h2 id="æˆ‘ä»¬ç¼ºä¹é€æ˜åº¦">æˆ‘ä»¬ç¼ºä¹é€æ˜åº¦</h2>
<p>å›é¦–å¾€äº‹ï¼Œä¸å°‘äººéƒ½ä½ä¼°äº†ç–«æƒ…çš„å±å®³ï¼ä½†æ˜¯ï¼Œåœ¨ç–«æƒ…è¿˜æ²¡æœ‰å¼€å§‹è”“å»¶æ—¶ï¼Œå¦‚æœåšåˆ°ä¿¡æ¯å…¬å¼€é€æ˜ï¼Œå¦‚æœå¹å“¨äººä¸è¢«åŠè¯«ã€è­¦å‘Šã€å’Œæƒ©ç½šï¼Œæˆ–è®¸æ–°å† è‚ºç‚å…¨çƒå¤§æµè¡Œçš„å†å²ä¼šæ”¹å†™ã€‚è®¸å¤šåœ¨æ­¦æ±‰ä¸è¯¥å‘ç”Ÿçš„äº‹ä¸€å®šä¸ä¼šå‘ç”Ÿï¼Œæ­¦æ±‰çš„ç‰ºç‰²å°±ä¸ä¼šè¿™ä¹ˆå¤§ï¼Œä¸­å›½ç™¾å§“çš„ç‰ºç‰²ä¹Ÿå°±ä¸ä¼šè¿™ä¹ˆå¤§ã€‚</p>
<p>ä»ä¸­å›½æœ€æ—©å¤„ç†æ–°å† è‚ºç‚çš„ä¸å½“åšæ³•ï¼Œåˆ°ä¸–ç•Œå«ç”Ÿç»„ç»‡è¿Ÿè¿Ÿæœªå¯¹å…¨çƒå‘å‡ºæœ€é«˜çº§åˆ«çš„è­¦å‘Šï¼Œåˆ°æ¬§ç¾å„å›½çš„è¿Ÿç¼“åº”å¯¹è¡ŒåŠ¨ï¼Œéƒ½å’Œç¼ºä¹é€æ˜åº¦æœ‰å…³è”ã€‚è¿™æ¬¡ç–«æƒ…å¦‚æ­¤è¿…çŒ›æ‰©æ•£çš„ç¬¬ä¸€è´£ä»»äººå½“ç„¶æ˜¯æ­¦æ±‰å½“å±€ã€æ¹–åŒ—å½“å±€ï¼Œä»–ä»¬å¯¹å…¬ä¼—éšç’ä¿¡æ¯ç”šè‡³æ©ç›–çœŸç›¸ï¼Œå¼•å‘äº†æ°‘ä¼—çš„ä¸ä¿¡ä»»ï¼Œå›½é™…ç¤¾ä¼šä¸å°‘äººç”šè‡³æ€€ç–‘ä¸­å›½çš„æ­»äº¡ç‡é€ å‡ã€‚ä¸­å›½æœ€ä¸ºå—ä¼¤çš„å°±æ˜¯å› å°é”å’Œéšç’ä¿¡æ¯ï¼Œå¯¼è‡´ç–«æƒ…çš„æ§åˆ¶å—åˆ°å»¶è¯¯ï¼Œé­åˆ°å›½é™…ç¤¾ä¼šè¯Ÿç—…ã€æ’æ–¥å’ŒæŒ‡è´£ã€‚æ­¦æ±‰å°åŸä¹‹åï¼Œä¸­å›½çš„ç»æµå’Œæ°‘ç”Ÿå—åˆ°é‡åˆ›çš„ä¸¾æªå’Œç‰ºç‰²ä¹Ÿå› æ­¤å¤§æ‰“æŠ˜æ‰£ï¼Œå¯¹ä¸­å›½çš„è´Ÿé¢å½±å“å…¶å®åˆšåˆšæµ®ç°ã€‚</p>
<p>ç¾å›½æ”¿å®¢åœ¨ä¸­å›½ç–«æƒ…æœ€ä¸¥é‡çš„æ—¶åˆ»ï¼Œé¢‡æœ‰éš”å²¸è§‚ç«çš„çœ‹å®¢å¿ƒæ€ã€‚ç‰¹æœ—æ™®ä¸ºäº†é€‰ä¸¾ï¼Œä¸ºäº†è‚¡å¸‚ä¸ä¸‹è·Œï¼Œä¸å½±å“ç»æµï¼Œå°±æ˜¯ä¸æ„¿æ‰¿è®¤ç–«æƒ…è¿Ÿæ—©ä¼šå†²å‡»ç¾å›½ã€‚ä»–æœ¬ä»¥ä¸ºå…³é—­äº†æ¥å¾€ä¸­å›½çš„èˆªçº¿ï¼Œåˆ‡æ–­äº†æ¥è‡ªä¸­å›½çš„äººæµå°±ä¸‡äº‹å¤§å‰äº†ã€‚ä»–è¿˜ä¸è®©é‚®è½®ä¸Šå—æ„ŸæŸ“çš„æ¸¸å®¢åœ¨ç¾å›½ä¸‹èˆ¹ï¼Œå°±æ˜¯è¦åˆ¶é€ ç¾å›½æœ¬åœŸç—…æ¯’æ„ŸæŸ“è€…å¾ˆä½çš„å‡è±¡ã€‚ä½†è¿™æ ·çš„åšæ³•å’Œä¸€åˆ‡ä»¥ç¨³å®šä¸ºé¦–è¦çš„è€ƒè™‘æœ‰ä½•åŒºåˆ«å‘¢ï¼Ÿåœ¨ç–«æƒ…ç»ˆäºå¸­å·ç¾å›½ä¹‹åï¼Œä»–ä¹Ÿæ˜¯ä¸æ–­å¤§äº‹åŒ–å°ï¼Œå°½é‡é™ä½ç–«æƒ…æ‰€å¸¦æ¥çš„å†²å‡»å’Œå½±å“ï¼Œç”šè‡³åœ¨æ„ŸæŸ“äººæ•°è¿˜åœ¨ä¸æ–­æ”€å‡æ—¶ç«Ÿç„¶è¡¨ç¤ºç¾å›½çš„ç»æµæ´»åŠ¨åœ¨å¤æ´»èŠ‚å°±å¯ä»¥æ¢å¤æ­£å¸¸ï¼æ‰€å¹¸ç¾å›½æœ‰ç‹¬ç«‹çš„åª’ä½“ï¼Œåœ¨ç™½å®«å¯ä»¥ç›´æ¥å’Œæ€»ç»Ÿå…¬å¼€å«æ¿ï¼Œä¸è®©æ”¿åºœä¼ æ’­çš„ä¸å®æ¶ˆæ¯å½“é“ã€‚åœ¨ç™½å®«è®°è€…ä¼šä¸Šï¼Œç¾å›½åª’ä½“å…¬å¼€è´¨ç–‘ç‰¹æœ—æ™®çš„æŠ—ç–«æ”¿ç­–ä¸å½“ï¼Œå½“åœºè´¨é—®æ€»ç»Ÿä¸ºä½•ä¸åœåœ°ä½¿ç”¨â€œä¸­å›½ç—…æ¯’â€è¿™æ ·çš„æ­§è§†æ€§å­—çœ¼ã€‚</p>
<p>æ—©åœ¨1æœˆ20æ—¥ï¼Œå½“æˆ‘ç¡®è®¤è¿™å°†æ˜¯ä¸€åœºå…¬å…±å«ç”Ÿç¾éš¾æ—¶ï¼Œæˆ‘å°±ç¬¬ä¸€æ—¶é—´åœ¨æˆ‘çš„æœ‹å‹åœˆé‡Œè½¬å‘äº†ç®¡è½¶æ•™æˆå¯¹ç–«æƒ…çš„â€œæ‚²è§‚â€çœ‹æ³•ã€‚ä½†ä»–çš„ç§‘å­¦åˆ†æåœ¨å†…åœ°è¢«è§†ä¸ºè€¸äººå¬é—»ï¼Œæœ‰äººç”šè‡³å€Ÿä»–çš„â€œé€ƒè·‘è¯´â€å¯¹ä»–è¿›è¡Œäººèº«æ”»å‡»ï¼Œä½†æ­£æ˜¯è¿™æ ·å®¢è§‚çš„ä¿¡æ¯æ‰æœ‰åŠ©äºæˆ‘ä»¬äº†è§£äº‹å®çœŸç›¸ï¼Œäº†è§£è¿™ä¸€å…¬å…±å«ç”Ÿå±æœºå·²ç»å»åˆ°äº†å¤šä¹ˆå±é™©çš„å¢ƒåœ°ï¼å…¶å®åœ¨å‘ç”Ÿç±»ä¼¼æ–°å† è‚ºç‚è¿™æ ·çš„å±æœºæ—¶ï¼Œé¢å¯¹å¤ªå¤šçš„ä¸ç¡®å®šæ€§ï¼Œè¦é˜»æ­¢è°£è¨€ï¼Œä¿¡æ¯çš„é€æ˜å°±æ˜¾å¾—å°¤ä¸ºé‡è¦ã€‚</p>
<p>é™¤äº†åˆ»æ„éšç’ä¿¡æ¯ï¼Œè¿˜æœ‰è™šå‡èµ„è®¯æ³›æ»¥ã€‚å…¨çƒæ•°ç™¾åç§‘å­¦å®¶2æœˆä¸Šæ—¬å‡ºå¸­æ—¥å†…ç“¦â€œä¸–å«è®ºå›â€ï¼Œè®¨è®ºæ–°å‹å† è‚ºç‚ç–«æƒ…ï¼Œå­¦è€…å°±æ„Ÿå¹ä»–ä»¬ä¸å¾—ä¸é¢å¯¹ä¸¤æ¡æˆ˜çº¿ä½œæˆ˜ï¼Œé™¤äº†åº”ä»˜ç—…æ¯’å¤§æµè¡Œï¼Œè¿˜è¦åº”ä»˜è™šå‡èµ„è®¯å¤§æ³›æ»¥ ï¼Œè€Œåº”å¯¹è™šå‡èµ„è®¯æ³›æ»¥æ¯”æŠ—ç–«æœ¬èº«è¿˜è‰°éš¾ã€‚ç½‘ä¸Šæµä¼ æœ€å¹¿æœ€å¿«çš„å¾€å¾€å°±æ˜¯è€¸äººå¬é—»çš„å‡æ¶ˆæ¯å’Œæ¸²æŸ“æˆè§çš„çœ‹æ³•ï¼Œè¿™äº›ä¸å®çš„ä¿¡æ¯ï¼Œæœ‰æ¶æ„é€ è°£ï¼Œæœ‰æ–­ç« å–ä¹‰ï¼Œå¯¼è‡´éç†æ€§çš„ååº”å’Œææ…Œï¼Œç”šè‡³åˆ¶é€ æ··ä¹±å’Œåˆ†åŒ–ã€‚ä¸–å«é¡¾é—®éš†åŸºå°¼ï¼ˆIra Longiniï¼‰å’Œé¦™æ¸¯å¤§å­¦åŒ»å­¦é™¢é™¢é•¿æ¢å“ä¼Ÿæ›¾æåŠå…¨çƒä¸‰åˆ†ä¹‹äºŒçš„äººå£æœ‰å¯èƒ½æ„ŸæŸ“æ–°å† ç—…æ¯’ï¼Œä½†ç½‘ä¸Šçš„ä¿¡æ¯éƒ½å¿½ç•¥äº†â€œå¦‚æœä¼ æ’­æœªåŠ æŠ‘åˆ¶â€çš„å‡è®¾ï¼Œç‰¹æ„å°†æœ€åçš„å¯èƒ½æ€§æ— é™æ”¾å¤§ï¼Œå¼•èµ·ä¸å¿…è¦çš„ææ…Œã€‚</p>
<p>åœ¨ä»»ä½•ä¸€åœºå…¬å…±å±æœºå‘ç”Ÿçš„æ—¶å€™ï¼Œæ”¿åºœæ˜¯ä¸å¯èƒ½é å±è”½ä¿¡æ¯æ¥é˜»æ­¢å±æœºçš„è”“å»¶ã€‚æ°æ°ç›¸åï¼Œè¿™åªä¼šé€ æˆå±æœºçš„è¿›ä¸€æ­¥æ¶åŒ–ã€‚å³ä¾¿åœ¨ä¸Šä¸ªä¸–çºªçš„è‹è”æ—¶ä»£ï¼Œå¯¹åˆ‡å°”è¯ºè´åˆ©æ ¸æ³„éœ²çš„éšç’æœ€ç»ˆç»™äººç±»å¸¦æ¥äº†ä¸€åœºä¸–çºªå¤§ç¾éš¾ï¼Œæ›´ä½•å†µæˆ‘ä»¬å·²ç»èº«å¤„ç¤¾äº¤åª’ä½“å¦‚æ­¤å‘è¾¾çš„æ—¶ä»£ï¼</p>
<p>é¢å¯¹å…¨çƒç–«æƒ…å¤§æµè¡Œï¼Œä¿¡æ¯æŠ«éœ²å’Œä¿¡æ¯å¯¹ç§°æœ‰åŠ©äºæˆ‘ä»¬äº†è§£ä¸åŒåœ°åŸŸï¼Œåœ¨ä¸åŒçš„æ–‡åŒ–å’ŒèƒŒæ™¯ä¸‹çš„ä¸åŒåº”å¯¹ç­–ç•¥å’Œæªæ–½ã€‚ä¸ç®¡æ˜¯å¯¹ç–«æƒ…çš„åˆ¤æ–­ï¼Œè¿˜æ˜¯åº”å¯¹ç–«æƒ…çš„æ–¹æ³•ï¼Œå„å›½éƒ½æœ‰ä¸åŒçš„ç†è§£å’Œåšæ³•ï¼Œç›¸äº’ä¹‹é—´ä¸ä»…ä¸è¯¥å˜²ç¬‘ï¼Œåè€Œåº”è¯¥å€Ÿé‰´ã€‚æˆ‘ä»¬å› æ¡ä»¶é™åˆ¶æ— æ³•è·å¾—å…¨é¢çš„ä¿¡æ¯ï¼Œä½†è‡³å°‘å¯ä»¥æ¢ä½æ€è€ƒï¼Œä»ä»–è€…çš„è§’åº¦çœ‹é—®é¢˜ï¼Œé¿å…å¹¸ç¾ä¹ç¥¸çš„çœ‹å®¢å¿ƒç†ã€‚</p>
<h2 id="æˆ‘ä»¬ç¼ºä¹åŒç†å¿ƒ">æˆ‘ä»¬ç¼ºä¹åŒç†å¿ƒ</h2>
<p>ç–«æƒ…çˆ†å‘ä¹‹åï¼Œå„å›½ä¸ä»…æœ‰ä¸åŒçš„è®¤çŸ¥è¿‡ç¨‹ï¼Œè€Œä¸”åœ¨è·å¾—ç›¸åŒçš„è®¤çŸ¥ä¹‹åæ‰€é‡‡å–çš„åº”å¯¹ä¹Ÿå¹¶ä¸ç›¸åŒã€‚æ­¦æ±‰å°åŸçš„æ¶ˆæ¯ä¼ å‡ºä¹‹åï¼Œè¥¿æ–¹çš„ååº”ä¹Ÿæ˜¯ä¸¤æï¼Œæœ‰ç§°è¿™æ ·çš„ä¸¾æªæ˜¯æµè¡Œç—…ä¸“å®¶çš„å¤©å ‚ï¼Œè€Œè¿™åªæœ‰åœ¨å¨æƒå›½å®¶æ‰èƒ½å®ç°ï¼Œæ°‘ä¸»å›½å®¶åªèƒ½ç¾¡æ…•ã€‚ä½†ä¹Ÿæœ‰ä¸€äº›è¥¿æ–¹å›½å®¶çœ‹åˆ°ä¸­å›½é¢ä¸´çš„å›°å¢ƒï¼Œåœ¨ç–«æƒ…åˆšåˆšçˆ†å‘æ—¶ï¼Œä¹Ÿå¸¦æœ‰äº‹ä¸å…³å·±é«˜é«˜æŒ‚èµ·ã€ç”šè‡³å¹¸ç¾ä¹ç¥¸çœ‹ç¬‘è¯çš„å¿ƒæ€æ¥çœ‹å¾…ä¸­å›½çš„æŠ—ç–«ï¼Œè¿˜æŠŠç—…æ¯’ä¸ä¸­å›½çš„å›½æ°‘æ€§å’Œä½åŠ£æ–‡åŒ–ç›¸è”ç³»ã€‚</p>
<p>å„å›½æŠ—ç–«çš„åšæ³•ç¦»ä¸å¼€å…¶ä½“åˆ¶ã€æ–‡åŒ–ã€å†å²ç­‰å› ç´ ã€‚åœ¨ä¸­å›½ï¼Œä¸€å£°ä»¤ä¸‹ï¼Œä¸¾å›½ä½“åˆ¶ç«‹é©¬è§æ•ˆï¼Œæ•´ä¸ªå›½å®¶æœ‰å¦‚ä¸€éƒ¨æœºå™¨ï¼Œå…¨åŠ›æŠ—ç¾ï¼Œæ‰€æœ‰å…¶å®ƒäº‹æƒ…éƒ½è¦é è¾¹ç«™ï¼Œç”šè‡³åšå‡ºç‰ºç‰²ï¼ŒåŒ…æ‹¬åœ¨â€œå‡†æˆ˜äº‰â€çŠ¶æ€ä¸‹ä¸ªä½“çš„æƒåˆ©å’Œè‡ªç”±ï¼Œå…¶å®ƒç—…äººå¯å¦å—åˆ°æ­£å¸¸çš„åŒ»ç–—æ•‘åŠ©ï¼Œéƒ½ä¸æ˜¯æœ€é‡è¦çš„è€ƒè™‘ã€‚äº‹å®è¯æ˜ï¼Œè¿™æ ·çš„ç‰ºç‰²ç¡®å®å·¨å¤§ï¼Œä½†è¿™ä¸€æŠ—ç–«å†å²ä¸Šæœªæ›¾ç»å†è¿‡çš„ä¸¾æªï¼Œä¸€åº§ä¸Šåƒä¸‡äººå£çš„å¤§åŸå¸‚è¢«å°åŸä¸¤ä¸ªæœˆçš„æˆ˜ç•¥æœ€ç»ˆæ˜¯å¥æ•ˆçš„ã€‚</p>
<p>ä¸­å›½çš„ç‰ºç‰²é˜»æ­¢äº†ç–«æƒ…è”“å»¶ï¼Œå¯æ­Œå¯æ³£ã€‚å³ä¾¿å¦‚æ­¤ï¼Œå¯åœˆå¯ç‚¹ä¹‹å¤„ä¹Ÿå¤šå¦‚ç‰›æ¯›ï¼Œé‡è›®ä½œä¸šçš„ç°è±¡ä¹Ÿå¹¶éä¸ªåˆ«ã€‚ä¸­å›½äººä¸å–œæ¬¢ç¾å›½æŒ‡æ‰‹ç”»è„šï¼Œé‚£åˆ«çš„å›½å®¶éš¾é“å°±å–œæ¬¢ä¸­å›½è¿™ä¹ˆåšï¼Ÿä¸€äº›è‡ªåª’ä½“å¯¹åˆ«å›½çŠ¶å†µä¸€çŸ¥åŠè§£ï¼Œå……æ»¡æ— çŸ¥ã€åè§å’Œè½»è”‘ï¼Œéè¦è¯´äººå®¶ä¸ä¼šæŠ„ä½œä¸šã€‚çœ‹çœ‹ä¸œé‚»æ—¥æœ¬ï¼Œå’ŒéŸ©å›½çš„åšæ³•ä¹Ÿä¸åŒï¼Œè¿å¤§é¢ç§¯çš„æ£€æµ‹ä¹Ÿæ²¡åšï¼Œæƒ…å†µä¹Ÿä¸ç®—å¤ªåï¼æ—¥æœ¬çš„äººå£å¯†åº¦è¿˜è¶…è¿‡ä¸­å›½ï¼ä½†æ—¥æœ¬äººå¹³æ—¶çš„ç”Ÿæ´»å’Œå«ç”Ÿä¹ æƒ¯ï¼Œä½ åˆäº†è§£å¤šå°‘ï¼Ÿå…¶å®å°±æ˜¯åäººç¤¾ä¼šçš„é¦™æ¸¯ã€æ¾³é—¨ã€å°æ¹¾ã€æ–°åŠ å¡ç­‰åœ°çš„å¤„ç†æ–¹å¼éƒ½ä¸åŒï¼Œå½“ä¸­æ–°åŠ å¡çš„æ‰€è°“â€œä½›ç³»â€é˜²ç–«æªæ–½ç›¸å½“æˆåŠŸè®©ä¸å°‘äººå¤§è·Œçœ¼é•œã€‚</p>
<p>æ–°åŠ å¡ä»â€œé‡ç¾åŒºâ€åˆ°â€œæ¨¡èŒƒç”Ÿâ€ï¼Œè¡¨é¢ä¸Šçœ‹å»ä¼¼ä¹é€‰æ‹©äº†â€œä½›ç³»â€çš„æŠ—ç–«ç­–ç•¥ï¼Œæ›¾å¼•æ¥ä¸å°‘æ€€ç–‘ã€ç”šè‡³å˜²ç¬‘ã€‚æ–°åŠ å¡é˜²ç–«æˆåŠŸæ˜¯æœ‰åŸå› çš„ï¼Œå…¶ç­–ç•¥å¯ä»¥æ¦‚æ‹¬ä¸ºï¼šæœ€å¿«ååº”ã€æœ€æ—©é˜²èŒƒã€æœ€æœ‰ç³»ç»Ÿã€æœ€ä¸¥æƒ©ç½šã€æœ€å°‘æŠ˜è…¾ã€æœ€ç¼ºææ…Œã€‚æ–°åŠ å¡ä¸€åº¦æ˜¯ä»…æ¬¡äºä¸­å›½ç—…ä¾‹ç¬¬äºŒé«˜çš„å›½å®¶ï¼ŒåŒæ—¶äººå£ç¨ å¯†ï¼Œè¿˜æ˜¯å›½é™…äº¤é€šæ¢çº½ã€‚ä½†æ–°åŠ å¡æ”¿åºœååº”è¿…é€Ÿä¸”æ•ˆç‡é«˜ï¼Œæœ€æ—©é™åˆ¶æ¥è‡ªä¸­å›½çš„äººæµï¼Œå¹¶å®æ–½äº†å¯¹ä¸åŒäººç¾¤çš„ä¼‘å‡ä»¤å’Œå±…å®¶éš”ç¦»ä»¤ã€‚â€œéå…¸â€ä¹‹åå»ºç«‹èµ·æ¥çš„ç–«æƒ…è­¦æŠ¥ç³»ç»Ÿç«‹å³æ´¾ä¸Šç”¨åœºã€‚æ–°åŠ å¡å›½å®¶ä¼ æŸ“ç—…ä¸­å¿ƒé›†å…ˆè¿›çš„æ£€æµ‹ã€æ²»ç–—ä¸å®éªŒç ”ç©¶ä¸ºä¸€ä½“ï¼Œé©¬ä¸Šç ”å‘å¹¶åˆä½œç”Ÿäº§äº†å¿«é€Ÿç—…æ¯’æ£€è¯•å‰‚ï¼Œæœ‰å¥å…¨çš„æ£€æµ‹ä½“ç³»ï¼Œä¿è¯äº†ç–‘ä¼¼æ‚£è€…å°½å¿«å¾—åˆ°æ²»ç–—ï¼Œé¿å…äº†ç–«æƒ…çš„ä¼ æ’­ï¼ŒåŠ å¼ºäº†æ°‘ä¼—çš„ä¿¡å¿ƒã€‚æ–°åŠ å¡ç¼ºä¹å£ç½©ç”Ÿäº§èƒ½åŠ›ï¼Œä¸é¼“åŠ±å¤§å®¶æˆ´å£ç½©ï¼Œä½†æ”¿åºœè¿˜æ˜¯å¿«é€Ÿè´­ä¹°äº†äº”ç™¾ä¸‡ä¸ªå£ç½©æ´¾å‘åˆ°æ¯å®¶æ¯æˆ·ï¼Œå®‰æŠšæ°‘ä¼—ã€‚æ–°åŠ å¡æœ‰å……è¶³çš„åŒ»ç–—èµ„æºï¼Œç±»ä¼¼äºä¸­å›½çš„å‘çƒ­é—¨è¯Šå°±æœ‰873ä¸ªï¼Œç›¸å½“äºåŒ—äº¬å‘çƒ­é—¨è¯Šçš„11å€ã€‚æˆ‘å¾ˆæ—©åœ¨æœ‹å‹åœˆé‡Œå°±è½¬å‘ç›¸å…³çš„ä¿¡æ¯çœ‹å¥½æ–°åŠ å¡çš„åšæ³•ï¼Œç”šè‡³æ¯”é¦™æ¸¯è¿˜æˆåŠŸï¼Œæ²¡æœ‰å‘ç”Ÿé¦™æ¸¯æ’é•¿é˜Ÿäº‰å£ç½©ã€æŠ¢å•çº¸çš„â€œå¥‡è§‚â€ã€‚ä½†è¯è¯´å›æ¥ï¼Œé¦™æ¸¯çš„ææ…Œæ˜¯åŸºäºé¦™æ¸¯æ›¾åœ¨2003å¹´â€œéå…¸â€æ—¶æ›¾é­é‡åˆ›çš„æƒ¨ç—›å†å²ï¼Œä»¥åŠé¦™æ¸¯å’Œå†…åœ°æ¯å¤©æœ‰å¤§é‡çš„äººå‘˜æ¥å¾€è¿™ä¸€äº‹å®ã€‚</p>
<p>éŸ©å›½è¿™æ¬¡çš„æŠ—ç–«æ¨¡å¼åœ¨è¥¿æ–¹æ›´æ˜¯å—åˆ°è‚¯å®šï¼Œæ³•å›½æ€»ç»Ÿå’Œç‘å…¸é¦–ç›¸ç­‰å¤šå›½æ”¿è¦ç”šè‡³è‡´ç”µéŸ©å›½è®¨æ•™ã€‚ä½†éŸ©å›½å¯¹ç–«æƒ…çš„æ§åˆ¶åˆ°åº•æœ‰ä½•é­…åŠ›ï¼Ÿä¸ºä½•è¥¿æ–¹æ„¿æ„åˆ°éŸ©å›½å–ç»å’Œå¤åˆ¶éŸ©å›½æ¨¡å¼å‘¢ï¼ŸéŸ©å›½ä¹Ÿæ›¾é¢å¯¹ä¸ä¸­å›½ç›¸åŒçš„å›°å¢ƒï¼Œä½†ä¸¤å›½åœ¨å¤§èŒƒå›´å‘ç”Ÿç–«æƒ…ä¹‹åï¼Œé‡‡å–äº†ç±»ä¼¼çš„æŠ—ç–«æˆ˜ç•¥ï¼Œæ–°å¢ç—…ä¾‹æ›²çº¿è¿…é€Ÿè¢«å‹å¹³ã€‚ä½†è¥¿æ–¹åœ¨çœ‹éŸ©å›½çš„ç»éªŒæ—¶ï¼Œç‰¹åˆ«çœ‹é‡éŸ©å›½æ²¡æœ‰å› ç–«æƒ…å‡ºç°å‹åˆ¶è¨€è®ºå’Œä¿¡æ¯å—é˜»çš„ç°è±¡ï¼Œæ²¡æœ‰å› ç¦ä»¤å½±å“æ°‘ä¼—çš„è¡ŒåŠ¨å’Œè‡ªç”±ï¼Œå›½å®¶çš„ç»æµæ›´æ²¡æœ‰å—åˆ°å¤ªå¤§çš„å†²å‡»ã€‚éŸ©å›½çš„ç»éªŒå¯ä»¥å½’ç»“ä¸ºï¼šæ—©å¹²é¢„ã€æ—©å‡†å¤‡ã€æ—©æ£€æµ‹ã€æ—©è·Ÿè¸ªã€æ—©éš”ç¦»ã€æ—©è§‚å¯Ÿã€‚éŸ©å›½çš„ä¼ä¸šæ—©å°±åˆ¤æ–­ç—…æ¯’è¿Ÿæ—©ä¼šæ‰©æ•£åˆ°éŸ©å›½ï¼Œç¬¬ä¸€æ—¶é—´å°±ç ”å‘å‡ºæ£€æµ‹è¯•å‰‚ç›’ï¼Œè·å¾—æ”¿åºœçš„ç´§æ€¥å®¡æ‰¹æŠ•æ”¾å¸‚åœºï¼Œæ£€æµ‹è¿‡ç¨‹åªéœ€ååˆ†é’Ÿï¼Œå‡ å°æ—¶å†…å¯ä»¥å‡ºç»“æœï¼Œå‡†ç¡®ç‡è¶…è¿‡98%ã€‚éŸ©å›½å•æ—¥å¯æ£€æµ‹è¿‘ä¸¤ä¸‡äººï¼Œæ£€æµ‹ç‡å…¨çƒä¹‹å† ï¼Œå·²æœ‰120å¤šä¸ªå›½å®¶äº‰ç›¸ä»éŸ©å›½è¿›å£æµ‹è¯•ç›’ã€‚éŸ©å›½æ”¿åºœè¿˜è¿…é€Ÿä¿®è®¢æ³•å¾‹ï¼Œç½‘ç«™å’Œæ‰‹æœºéƒ½å¯ä»¥è¿½è¸ªç—…å‘è€…ï¼Œä¸€æ—¦æœ‰æ–°ç—…ä¾‹ï¼Œå°±å¯ä»¥è·å¾—ä¿¡æ¯å’Œè­¦æŠ¥ã€‚</p>
<p>å¥½çš„ç»éªŒå½“ç„¶å¯ä»¥æŠ„ï¼Œå¯ä»¥å€Ÿé‰´ï¼Œä½†ä¸å¿…è¿‡åˆ†åœ°æ˜¾è€€è‡ªå·±çš„æˆåŠŸï¼Œè¿™åªä¼šè®©äººåæ„Ÿã€‚å·±æ‰€ä¸æ¬²ï¼Œå‹¿æ–½äºäººã€‚ç°åœ¨ä¸­å›½ä¸å‡†å¤–å›½äººå…¥å¢ƒï¼Œè¿™æ˜¯å› ä¸ºä¸­å›½ä¸èƒ½å†å†’ç¬¬äºŒæ¬¡ç–«æƒ…å¤±æ§çš„é£é™©ï¼Œäºæƒ…äºç†éƒ½ä¸æ˜¯è‡ªç§è‡ªåˆ©ã€‚åŒæ ·ï¼Œç–«æƒ…çˆ†å‘åˆæœŸï¼Œé¦™æ¸¯ã€æ–°åŠ å¡ã€æ„å¤§åˆ©ã€ç¾å›½ç­‰åœ°å¯¹ä¸­å›½äººå°å…³ã€æ’¤ä¾¨ä¹Ÿæ˜¯åŒç†ï¼Œäººå®¶ä¹ŸåŒæ ·ä¸æ„¿æ„çœ‹åˆ°ç–«æƒ…è”“å»¶ï¼Œä¸ºä½•é‚£æ—¶å°±å¯ä»¥æ”»å‡»åˆ«äººæ˜¯æ¶æ„åˆ¶é€ ææ…Œï¼Œæ˜¯å¯¹ä¸­å›½èƒŒåæ’ä¸Šä¸€åˆ€å‘¢ï¼Ÿç¾å›½åœ¨æ¬§æ´²ç–«æƒ…ä¸¥é‡ä¹‹åä¹Ÿç¦æ­¢æ¬§æ´²äººå‰å¾€ç¾å›½ï¼Œæœ€åè¿è‹±å›½è¿™ä¸ªå°å…„å¼Ÿä¹Ÿè¿›äº†å…¥å¢ƒé™åˆ¶åå•ã€‚æ—¥æœ¬ç°åœ¨å¯¹åŒ…æ‹¬ä¸­å›½ã€éŸ©å›½ã€ç¾å›½ã€æ¬§æ´²åœ¨å†…çš„å›½æ°‘å…¥å¢ƒéƒ½é‡‡å–åå››æ—¥éš”ç¦»çš„æ”¿ç­–ã€‚ç–«æƒ…åˆæœŸï¼Œä¸­å›½æ°‘ä¼—å¯¹æ—¥æœ¬çš„æ€åº¦å‘ç”Ÿäº†180åº¦çš„å¤§è½¬å¼¯ï¼Œæ›¾ç»è¢«æˆ‘ä»¬éª‚å¾—ä¸€æ— æ˜¯å¤„çš„å¤§å’Œæ°‘æ—ä¼¼ä¹å¯¹ä¸­å›½å¾ˆå‹å¥½ã€å¾ˆå–„è‰¯ï¼Œå‘ä¸­å›½æèµ å„ç±»ç‰©èµ„ï¼Œè€Œå¯¹ç¾å›½æ”¿åºœçš„è¡¨ç°æä¸ºä¸æ»¡ã€‚å…¶å®æŠ›å¼€ç¾å›½æ°‘é—´å’Œä¼ä¸šçš„èµ„åŠ©ä¸æï¼Œä¸ºä½•ä¸€å®šå°±è¦æœŸå¾…å’Œä¸­å›½æ­£åœ¨æ‰“è´¸æ˜“æˆ˜çš„ç‰¹æœ—æ™®æ”¿åºœå¯¹ä½ å‹å¥½å‘¢ï¼Ÿè€Œå¯¹ä¸­å›½æœ€æ—©é”å›½çš„æ˜¯æœé²œã€ä¿„ç½—æ–¯ã€è¶Šå—ç­‰å›½ï¼</p>
<p>åœ¨ç–«æƒ…è¢­å‡»çš„ææƒ§ä¸­ï¼Œæˆ‘ä»¬æ›´ä¸å¯ä»¥å¹¸ç¾ä¹ç¥¸åœ°å˜²ç¬‘åˆ«äººçš„è¡Œä¸ºï¼Œé€è¿‡æ¸²æŸ“åˆ«å›½çš„ç–«æƒ…å¤±æ§æ¥å±•ç°è‡ªå·±çš„è‹±æ˜å’Œä¼Ÿå¤§ï¼Œè€Œå¿˜è®°äº†è‡ªå·±å¹¶æ²¡æœ‰èµ°å‡ºé™©å¢ƒã€‚ç¾å›½å’Œæ„å¤§åˆ©çš„æŠ¥çº¸ä¸Šå¯†å¯†éº»éº»çš„è®£å‘Šï¼Œçœ‹å»ä»¤äººæ‚²ä¼¤å’Œæ²‰é‡ï¼Œæ°æ°å½°æ˜¾äº†äººæ€§çš„ä¸€é¢ã€‚ä¸­å›½ä¸å°‘åª’ä½“å°†æ„å¤§åˆ©å’Œç¾å›½åŒ»é™¢ä¸­çš„å°¸ä½“çš„ç…§ç‰‡æ— é™æ¸²æŸ“ï¼Œè€Œå¤±å»äº²äººçš„æ­¦æ±‰äººå‰å»é¢†å–éª¨ç°ç›’ï¼Œä¸ºäº†æ­£å¸¸çš„æ‚¼å¿µå‘å‡ºçš„å“€æ€å’Œç…§ç‰‡å´æ¶ˆå¤±äº†ã€‚æˆ‘ä»¬å½“ä¸­æ€»æœ‰äººä¸æ„¿æ­£è§†è‡ªå·±çš„åˆ›ä¼¤ï¼Œä¸å¯å¿å—å°†è‹¦éš¾ã€æ‚²å‰§å’Œä¸‘æ¶å‘ˆç°åœ¨ä»–ä»¬é¢å‰çš„äººï¼Œå°†è¯»è€…é«˜è¾¾äº”åƒä¸‡çš„â€œæ—¥è®°â€è§†ä¸ºæ¶æ¯’ã€æ— è€»ï¼Œå´åˆå¦‚æ­¤é’Ÿæƒ…åœ°å±•ç¤ºâ€œçº½çº¦åŒ»é™¢å°¸æ»¡ä¸ºæ‚£â€ã€â€œçº½çº¦ç©·äººç–«æƒ…ä¹‹ä¸‹è¢«è¿«ä¹˜ååœ°é“ä¸Šç­â€ã€â€œè‹±å›½æ”¿åºœå‹’ä»¤åŒ»ç”Ÿå°å£â€è¿™æ ·çš„æ–‡å­—å’Œç…§ç‰‡ã€‚å¹¿ä¸œä¸€ä¸ªä¼ä¸šè€æ¿ç«Ÿç„¶å»ºè®®å‚å®¶åšå‡æµ‹æ¸©æªå–ç»™ç¾å›½ï¼Œè®©æ„ŸæŸ“è€…è¶Šæ¥è¶Šå¤šï¼Œè¾½å®æœ‰é¤å…é—¨å¤–è´´å‡ºæ¨ªå¹…ç¥è´ºç¾æ—¥ç–«æƒ…æ‰©æ•£ï¼Œå°±ä¸å•å•æ˜¯æ²¡æœ‰åŒç†å¿ƒäº†ï¼Œè€Œæ˜¯æ— çŸ¥çš„åäººç±»è¨€è®ºã€‚</p>
<p>å¦‚æœæˆ‘ä»¬å¯ä»¥åŒæ ·æ¯«æ— é¡¾è™‘åœ°æ‹·é—®è‡ªå·±ï¼ŒçŠ¹å¦‚å¦‚æ­¤å¿ƒå®‰ç†å¾—åœ°å¯¹ä»–äººæå‡ºè´¨ç–‘ï¼Œæˆ‘ä»¬çš„å¿ƒæ™ºå°±ä¸€å®šä¸ä¼šèç¼©ï¼Œæˆ‘ä»¬å…´è®¸ä¹Ÿå°±æœ‰äº†å¸Œæœ›ã€‚å¦‚ä»Šï¼Œæˆ‘ä»¬ç”šè‡³æ— æ³•æ­£å¸¸åœ°ä¼¸å‡ºèˆŒå¤´ï¼Œé“å‡ºè‡ªå·±çš„ç”œé…¸è‹¦è¾£ï¼Œåˆä½•å¿…å¦‚æ­¤å±…é«˜ä¸´ä¸‹ï¼Œå¸¦ç€å¹¸ç¾ä¹ç¥¸çš„ç—…æ€ï¼Œåˆ»æ„è¥é€ ä¼¼æ˜¯è€Œéçš„åœºæ™¯ï¼Œæ¥å½°æ˜¾é‚£è™šå¹»çš„ä¼˜è¶Šæ„Ÿï¼Ÿï¼ä½†æˆ‘æ€»æ˜¯å›ºæ‰§åœ°åšä¿¡ï¼Œä¸€ä¸ªäººã€ä¸€ä¸ªå›½å®¶ã€ä¸€ä¸ªæ°‘æ—åªè¦å‹‡äºæ‰¿æ‹…èµ·è‹¦éš¾ä¸­çš„è´£ä»»ï¼Œæœ€ç»ˆä¸€å®šæ˜¯ä¼šå¾—åˆ°åˆ«äººçš„ç†è§£å’Œèµè®¸çš„ã€‚</p>
<h2 id="æˆ‘ä»¬ç¼ºä¹æ‹…å½“">æˆ‘ä»¬ç¼ºä¹æ‹…å½“</h2>
<p>åœ¨è¿™æ¬¡ç–«æƒ…ä¸­æœ€å¸¸å¬åˆ°çš„ä¸€ä¸ªå­—å°±æ˜¯ç”©é”…ï¼Œè¿™åœºâ€œç”©é”…å¤§æˆ˜â€ä»æ­¦æ±‰å°åŸçš„é‚£ä¸€åˆ»å¼€å§‹å°±ä¸æ–­ä¸Šæ¼”ï¼Œä»å½“åœ°çš„åŒ»ç–—æœºæ„ï¼Œåˆ°å„çº§æ”¿åºœå®˜å‘˜ï¼Œåˆ°ä¸­å›½ç–¾ç—…æ§åˆ¶ä¸­å¿ƒï¼Œå¤§å®¶éƒ½åœ¨é—®ï¼Œç–«æƒ…å¤±æ§å’Œè”“å»¶çš„è´£ä»»åœ¨è°ï¼Ÿ</p>
<p>ä¸­å›½åœ¨â€œéå…¸â€ä¹‹åè€—èµ„11äº¿ï¼Œæ­å»ºäº†å…¨çƒæœ€å¤§çš„ä¼ æŸ“ç—…ç–«æƒ…å’Œçªå‘å…¬å…±å«ç”Ÿäº‹ä»¶ç½‘ç»œç›´æŠ¥ç³»ç»Ÿï¼Œè¿‡å»15å¹´é—´æŒç»­ç›‘æµ‹39ç§æ³•å®šä¼ æŸ“ç—…ã€‚è¿™ä¸ªå…¨çƒæœ€å¿«é€Ÿçš„ç–«æƒ…ä¸ŠæŠ¥ç³»ç»Ÿï¼Œå¯ä»¥åœ¨çŸ­çŸ­ä¸¤å°æ—¶å†…å°†ç–«æƒ…ä¸Šè¾¾åŒ—äº¬ï¼Œä¸­å›½æœ€é«˜çš„ç–¾ç—…é˜²ç–«ä¸“å®¶åœ¨2019å¹´æ›¾ç»è¡¨ç¤ºä¸­å›½ç»ä¸ä¼šé‡æ¼”â€œéå…¸â€æ‚²å‰§ã€‚ä½†è¯éŸ³åˆšè½ï¼Œè¿™ä¸ªè€—è´¹å·¨èµ„çš„ç³»ç»Ÿå¹¶æ²¡æœ‰åœ¨è¿™æ¬¡ç—…æ¯’è”“å»¶ä¸­å‘æŒ¥åŠŸæ•ˆã€‚æˆ–è®¸æˆ‘ä»¬æ°¸è¿œéƒ½æ— æ³•çŸ¥é“çœŸç›¸ï¼Œä½†æœ‰ä¸€ç‚¹å¾ˆæ¸…æ¥šï¼Œä¸“ä¸šåˆ¤æ–­åœ¨æ˜å“²ä¿èº«ã€æ²¡æœ‰æ‰¿æ‹…çš„å®˜åƒšç³»ç»Ÿä¸­è¢«å†·å†»äº†ï¼Œç”Ÿå‘½çš„ä»·å€¼ä¹ŸåŒæ ·åœ¨ä¸ªäººæƒåŠ›çš„æ£‹ç›˜ä¸Šè¢«æŠ›ä¹‹è„‘åã€‚</p>
<p>è¿™åœºç–«æƒ…æœ€å¤§çš„è®½åˆºæ˜¯ï¼Œå…¨çƒæœ€å¤§çš„ä¸¤ä¸ªç»æµä½“åœ¨é¢å¯¹è¿™åœºä¸–ç•Œå…¬å…±å«ç”Ÿå¤§å±æœºæ—¶ï¼Œç«Ÿç„¶ä¸Šæ¼”äº†ä¸€å‡ºæä¸ºç›¸ä¼¼çš„é—¹å‰§ã€‚å‡ ä¹æ¯å¤©é™ªåŒç‰¹æœ—æ™®åœ¨ç™½å®«è§è®°è€…çš„ç¾å›½ä¼ æŸ“ç—…é¦–å¸­ä¸“å®¶ç¦è¥¿ä¸è°„åªšæƒè´µï¼Œä¸ä»‹æ„é“å‡ºä¸ä»–æ—è¾¹çš„æ€»ç»Ÿç«‹åœºä¸åŒçš„çœ‹æ³•ï¼Œå…¶ç‹¬ç«‹çš„ä¸“ä¸šç²¾ç¥ä¸å—æ”¿æ²»çš„å·¦å³ï¼Œä½†ä»–çš„ä¸“ä¸šåˆ¤æ–­ä¹ŸåŒæ ·è¢«ç¾å›½æ€»ç»ŸæŸä¹‹é«˜é˜ã€‚ç–«æƒ…åœ¨ä¸­å›½è”“å»¶æ¶åŒ–ä¹‹æ—¶ï¼Œç¾å›½çš„ç§‘å­¦å®¶å°±å‘å‡ºè­¦å‘Šï¼Œä½†ç¾å›½ç–¾ç—…é˜²ç–«ä¸­å¿ƒã€ç¾å›½é£Ÿå“å’Œè¯ç‰©ç®¡ç†å±€ã€ç¾å›½å«ç”Ÿå’Œå…¬å…±æœåŠ¡éƒ¨ä¼¼ä¹éƒ½æ²¡æœ‰çœ‹åˆ°é‡‡å–è¡ŒåŠ¨çš„ç´§è¿«æ€§ï¼Œæ›´ä½•å†µç¾å›½æ€»ç»Ÿç‰¹æœ—æ™®æœ¬äººäº†ã€‚ç‰¹æœ—æ™®å‘æ¥è”‘è§†ç§‘å­¦å’Œä¸“ä¸šçš„æ„è§ï¼Œè”é‚¦æ”¿åºœè¢«ä¸€ç¾¤ç§‘å­¦æ€€ç–‘è®ºè€…æŠŠæŒã€‚è€Œç‰¹æœ—æ™®å°±å–œæ¬¢çœ‹æå³çš„ç¦å…‹æ–¯ç”µè§†å°ï¼Œæ›¾ä¸ä¸­å›½åŒè¡ŒèˆŒæˆ˜çš„å¥³ä¸»æ’­Trish Reganå°±é¼“å¹ç–«æƒ…æ˜¯æ°‘ä¸»å…šçš„é˜´è°‹ï¼Œè€Œç‰¹æœ—æ™®æœ¬äººå°±æ˜¯ä¸€ä¸ªé˜´è°‹è®ºè€…ã€‚ä»–åŒæ ·ä¸ä¿¡ä»»ä¸»æµåª’ä½“ï¼Œä¸åœåœ°å’Œä¸»æµåª’ä½“åœ¨ç™½å®«è®°è€…ä¼šä¸Šå”‡æªèˆŒå‰‘ï¼Œç”šè‡³å½“ä¼—ä¾®è¾±è®°è€…ã€‚ç‰¹æœ—æ™®ä¹Ÿä¸é‡è§†æ¥è‡ªæƒ…æŠ¥æœºå…³çš„æŠ¥å‘Šï¼Œè­¦å‘Šç–«æƒ…çš„ä¸¥é‡æ€§è¢«ä¸­å›½ä½ä¼°å’Œéšç’ï¼Œä»¥åŠç–«æƒ…å°†ä¼šè”“å»¶å…¨çƒã€‚æ­¤å¤–ï¼Œç‰¹æœ—æ™®å¯¹ç©æ”¿æ²»çš„å…´è¶£å¤šè¿‡æŠ—ç–«ï¼Œä¸ºäº†ç«é€‰å°±æ˜¯ä¸æ„¿æ‰¿è®¤ç–«æƒ…è¿Ÿæ—©ä¼šå†²å‡»ç¾å›½ï¼Œä»–å¯¹ç–«æƒ…è½»ææ·¡å†™çš„åŸå› ä¹Ÿæ˜¯å› ä¸ºæ°‘ä¸»å…šä¸»æ”¿çš„çº½çº¦å·ã€åŠ å·ã€åç››é¡¿å·å—åˆ°é‡åˆ›ï¼Œä½†å…±å’Œå…šçš„çº¢å·å¹¶æœªå—åˆ°å¤ªå¤§çš„å½±å“ã€‚çº½çº¦æ—¶æŠ¥åœ¨3æœˆ28æ—¥åˆŠç™»ä¸‡å­—æ–‡ï¼Œä»¥â€œç¾å›½é”™å¤±çš„ä¸€ä¸ªæœˆâ€ä¸ºé¢˜ï¼Œåˆ†æäº†ç¾å›½å› æ£€æµ‹æŠ€æœ¯è½åï¼Œæ³•è§„ä¸é…å¥—ï¼Œç™½å®«é¢†å¯¼æ— æ–¹ï¼Œæ”¿åºœå®˜åƒšä½œé£ï¼Œå¯¼è‡´ç¾å›½å¤±å»äº†ç–«æƒ…é˜²æ§çš„é»„é‡‘30å¤©ã€‚</p>
<p>ç¾å›½çš„ç§‘æŠ€å’ŒåŒ»ç–—å‘è¾¾ï¼Œç¾å›½çš„åŒ»ç–—å¼€æ”¯å GDPçš„æ¯”ä¾‹æœ€é«˜ï¼Œè¾¾åˆ°äº†è¿‘18%ï¼Œä½†ç¾å›½è‡³ä»Šçš„è¡¨ç°ä¸ºä½•ä»¤äººå¤§è·Œçœ¼é•œï¼Ÿæ— æ³•æ—©æœŸè¿›è¡Œæ£€æµ‹æ˜¯ç–«æƒ…è”“å»¶çš„å…ƒå‡¶ï¼Œç¾å›½ç–¾ç—…é˜²æ§ä¸­å¿ƒä¹Ÿä¸æ˜¯ä¸ä½œä¸ºï¼Œä½†ä¸ºä½•ä¼šå‘ç”Ÿè¿™æ ·ç¾éš¾æ€§çš„å¤±è¯¯å‘¢ï¼Ÿè¿™å’Œæ¬§ç¾ç¤¾ä¼šå¯¹æ–°å† è‚ºç‚çš„è½»è§†æœ‰ç›¸å½“å¤§çš„å…³è”ã€‚ä¸­å›½åœ¨ä¿®æ­£äº†å‰æœŸéšç’ç–«æƒ…çš„é”™è¯¯ä¹‹åï¼Œæ­¦æ±‰å°åŸçš„å¿«é€Ÿè¡ŒåŠ¨ï¼Œä¸ºæ•´ä¸ªå›½é™…ç¤¾ä¼šæ§åˆ¶ç–«æƒ…äº‰å–äº†éš¾å¾—çš„å®è´µæ—¶é—´ã€‚éšåä¸œäºšå„å›½å’Œåœ°åŒºä¹Ÿçº·çº·é‡‡å–è¡ŒåŠ¨ï¼Œå¤§ä½“ä¸Šéƒ½å–å¾—ä¸€å®šçš„æˆæ•ˆï¼Œåˆ¶æ­¢äº†æ–°å† ç—…æ¯’çš„è”“å»¶ã€‚é—æ†¾çš„æ˜¯ï¼Œç”±äºå¯¹ç–«æƒ…çš„è®¤çŸ¥å­˜åœ¨æå¤§çš„åå·®ï¼Œæ¬§ç¾å›½å®¶éƒ½æ²¡æœ‰åŠæ—¶é‡‡å–é€‚å½“çš„åº”å¯¹æªæ–½ï¼Œæ¬§æ´²å’Œç¾å›½å…ˆåæ¼”å˜æˆç–«æƒ…çš„é‡ç¾åŒºã€‚æ­¤æ¬¡ç–«æƒ…çš„å¦ä¸€ä¸ªä¸­å¿ƒæ„å¤§åˆ©ï¼Œä¹Ÿåªä¸è¿‡åœé£äº†å‰å¾€ä¸­å›½çš„èˆªç­ã€‚è€Œç¾å›½æ—©åœ¨1æœˆ3æ—¥å°±è·å¾—äº†ä¸­å›½çš„é€šæŠ¥ï¼Œ ä½†ç¾å›½å’Œå…¶å®ƒæ¬§æ´²å›½å®¶ä¸€æ ·ä¸€ç›´å¿ƒæ€è¶…ç„¶ï¼Œè§‰å¾—è‡ªå·±è¿œéš”é‡æ´‹ï¼Œâ€œéå…¸â€åªåœ¨ä¸œäºšæµè¡Œï¼Œä¾¿ä»¥ä¸ºæ­¤æ¬¡æ–°å† è‚ºç‚ä¹ŸåŒæ ·ä¼šå±€é™åœ¨ä¸œäºšåœ°åŒºã€‚</p>
<p>è€Œç–«æƒ…åœ¨ç¾å›½å¼€å§‹è”“å»¶åï¼Œè¿™åœºâ€œç”©é”…â€å¤§æˆ˜ç«Ÿç„¶ä¹Ÿè”“å»¶åˆ°å›½é™…ç¤¾ä¼šï¼Œä¸­ç¾ä¸¤å›½çˆ†å‘äº†ä»¤äººæ§è…¹çš„å”‡æªèˆŒæˆ˜ã€‚ä¸­å›½å¤–äº¤éƒ¨çš„æ–°ä»»å‘è¨€äººåœ¨æ¨ç‰¹ä¸Šæ€€ç–‘ç¾å†›åœ¨æ­¦æ±‰æ’­æ¯’ï¼Œç‰¹æœ—æ™®äº²è‡ªä¸Šé˜µï¼Œæ¶æ„åœ°ç§°æ–°å† è‚ºç‚ä¸ºâ€œä¸­å›½ç—…æ¯’â€ã€‚ç—…æ¯’èµ·æºåœ°çš„äº‰è®ºå‡¸æ˜¾äº†å„æ–¹æ„å›¾é€è¿‡â€œç”©é”…â€æ¥æ¨å¸åº”æœ‰çš„è´£ä»»ï¼Œå…¶å®èµ·æºåœ°ä½•ç½ªä¹‹æœ‰ï¼Ÿè€Œç¾å›½å›½åŠ¡å¿è“¬ä½©å¥¥åœ¨ç‰¹æœ—æ™®æ”¹å£ä¹‹åï¼Œè¿˜åšæŒè¦å°†æ­¦æ±‰ç—…æ¯’å†™è¿›ä¸ƒå¤§å·¥ä¸šå›½å¤–é•¿çš„å…¬æŠ¥é‡Œï¼Œè€Œè¢«å…¶å®ƒå›½å®¶æ‹’ç»ã€‚ç¾å›½è‡ªå·±æµªè´¹äº†ä¸€ä¸ªå¤šæœˆçš„æ—¶é—´ï¼Œç–«æƒ…å¤±æ§ï¼Œç‰¹æœ—æ™®å´åªä¼šå°†çŸ›å¤´è½¬ç§»ï¼Œæ©ç›–è‡ªå·±æŠ—ç–«èƒ½åŠ›çš„å¤±è¯¯ï¼æ›´ä¸ºä¸¥é‡çš„æ˜¯ï¼Œâ€œä¸­å›½ç—…æ¯’â€ç»è¿‡ä»–çš„å¤§å˜´å·´ï¼Œåœ¨æ¨ç‰¹é‡Œä¸€å¤©åˆä¸€å¤©åœ°åœ¨è¯´ï¼Œä¼ éå…¨çƒï¼Œé€ æˆäº†ç¾å›½ç­‰åœ°æ­§è§†äºšè£”äººçš„çŠ¯ç½ªä¸Šå‡ã€‚ç¾å›½è”é‚¦è°ƒæŸ¥å±€çš„ä¸€é¡¹å…¨æ–°ç ”ç©¶ï¼Œè­¦å‘Šå…¨ç¾é’ˆå¯¹äºšè£”äººçš„ä»‡æ¨çŠ¯ç½ªæ¡ˆä»¶æ•°ç›®ï¼Œå› æ–°å‹å† çŠ¶ç—…æ¯’ç–«æƒ…çš„æ‰©æ•£è€Œé£™å‡ï¼Œå±åŠç¾å›½çš„äºšè£”ç¤¾ç¾¤ã€‚è¿æ–°åŠ å¡æ€»ç†ææ˜¾é¾™åœ¨æ¥å—ç¾å›½æœ‰çº¿ç”µè§†æ–°é—»ç½‘CNNé‡‡è®¿çš„æ—¶å€™ï¼Œä¸ä»…æ„Ÿæ…¨ç¾å›½å¤±å»äº†é¢†å¯¼ä¸–ç•Œæˆ˜ç–«çš„èƒ½åŠ›ï¼Œè€Œä¸”æƒŠå¹è¿™ä¸¤ä¸ªä¸–ç•Œå¤§å›½ç«Ÿç„¶å¯ä»¥å¦‚æ­¤ä½æ°´å¹³åœ°è¿›è¡Œâ€œå£æ°´æˆ˜â€ã€‚</p>
<p>ä»äºšæ´²åˆ°æ¬§æ´²åˆ°ç¾æ´²ï¼Œæ˜”æ—¥ç¹å¿™çš„å¤§éƒ½ä¼šå› è¿™åœºç–«æƒ…ï¼Œç”Ÿæ´»å·²ç»åœé¡¿ã€‚è¿™åœºç–«æƒ…ä¸ä»…æš´éœ²äº†æˆ‘ä»¬åˆ¶åº¦çš„ç¼ºé™·ã€ç³»ç»Ÿçš„è„†å¼±ã€å’Œäººæ€§çš„ç½ªæ¶ï¼Œå…¨çƒå·²ç»è·Œå…¥æ–°ä¸€è½®çš„é‡‘èå¸‚åœºå¤§åŠ¨è¡å’Œå…¨çƒç»æµå¤§è¡°é€€ï¼Œä½†ä¸å¹¸çš„æ˜¯ï¼Œæˆ‘ä»¬ä¸ä»…æ²¡æœ‰è¿›è¡Œåæ€ï¼Œå´ä¾æ—§åœ¨é‚£é‡Œè‡ªæˆ‘é™¶é†‰å’Œè‡ªæˆ‘æ’•è£‚ï¼</p>
<h2 id="æˆ‘ä»¬ç¼ºä¹åæ€">æˆ‘ä»¬ç¼ºä¹åæ€</h2>
<p>ä¸€åœºå²æ— å‰ä¾‹çš„ç—…æ¯’å¤§æµè¡Œæ­£å‘å…¨çƒå„ä¸ªè§’è½å†²æ’ï¼Œæ­»äº¡ç¬¼ç½©ç€è¿™ä¸ªæ˜Ÿçƒã€‚ä½†é¢å¯¹è¿™åœºçªå¦‚å…¶æ¥çš„å¤©ç¾ï¼Œå…¶ä¸­å¤šå°‘äººç¥¸æ˜¯å¯ä»¥é¿å…çš„å‘¢ï¼Ÿ</p>
<p>å°å£vså°åŸï¼šå›´ç»•ç€è¿™åœºäººé“å±æœºçš„äº‰è®ºç„¦ç‚¹ä»ä¸€å¼€å§‹å°±ä»è¿™é‡Œå±•å¼€ã€‚å¦‚æœæ²¡æœ‰å‘ç”Ÿâ€œå°å£â€äº‹ä»¶ï¼Œæ–°å† è‚ºç‚çš„è”“å»¶æ˜¯å¦ä¼šæœ‰å¦ä¸€ä¸ªç»“å±€ï¼Ÿæˆ‘ä»¬æ— æ³•çŸ¥é“ç­”æ¡ˆï¼Œä½†æˆ‘ä»¬çŸ¥é“è‡³å°‘ä¸ä¼šå¦‚æ­¤æƒ¨çƒˆã€‚é—®é¢˜åœ¨äºä¸€ä¸ªç»æµå¦‚æ­¤å‘è¾¾çš„å›½åº¦ï¼Œä¸ºä½•ä¾æ—§æ— æ³•å®ç°ä¸€ä¸ªå¼€æ”¾ç¤¾ä¼šæ‰€éœ€è¦çš„åŸºæœ¬æ¡ä»¶ï¼›ä¸€ä¸ªè‡ªä¿¡çš„ç¤¾ä¼šä¸ºä½•éš¾ä»¥æ‹‰å“å±æœºæ¥ä¸´çš„è­¦æŠ¥å£°ã€‚è€Œè¿™å¹¶éä¸ªåˆ«å’Œå•ä¸€ç°è±¡ï¼Œè¿™æœ‰å¦‚éšè—åœ¨æˆ‘ä»¬ç¤¾ä¼šä¸­çš„æ¯’ç˜¤å’Œé¡½ç–¾ï¼Œæ€»æ˜¯å¦‚æ­¤ç²—æš´åœ°å‹åˆ¶å–„æ„çš„æé†’å’Œæ‰¹è¯„ã€‚</p>
<p>åœ¨å±æœºæŠµè¾¾ä¸´ç•Œç‚¹ä¹‹åä¹‰æ— åé¡¾çš„â€œå°åŸâ€è¡ŒåŠ¨ï¼Œå°½ç®¡æƒ¨çƒˆï¼Œå´ä¹Ÿæ˜¯è¿«ä¸å¾—å·²çš„å­¤æ³¨ä¸€æ·ï¼Œä½†æˆ‘ä»¬å¹¶éäº‹äº‹éƒ½ä¸€å®šè¦ä»¥ç‰ºç‰²ä¸ªä½“çš„ä»£ä»·æ¥å®ç°å®å¤§çš„ç›®æ ‡ï¼Œæ–‡æ˜æ˜¯ä½“ç°åœ¨å¯¹æ¯ä¸€ä¸ªç”Ÿå‘½çš„å…³æ€€ä¸Šçš„ã€‚â€œå°å£â€å¯ä»¥ä»¤ä¸€ä¸ªæ°‘æ—ã€ä¸€ä¸ªå›½å®¶åœ¨å…¨çƒå¤±å»ä¿¡ç”¨å’Œä¿¡ä»»ï¼Œå³ä¾¿åœ¨â€œå°åŸâ€çš„å·¨å¤§ç‰ºç‰²ä¹‹åï¼Œå—æ„ŸæŸ“å’Œæ­»äº¡çš„å®˜æ–¹çš„æ•°æ®è¿˜æ˜¯è¢«è´¨ç–‘ã€‚æ‰ªå¿ƒè‡ªé—®ï¼Œä¸ºä½•ä¸­å›½å¸¸å¸¸æˆä¸ºè¿™ç±»è¢«æ€€ç–‘çš„ç›®æ ‡ä¸å¯¹è±¡ï¼Ÿä¸€ä¸ªçœŸæ­£å¼€æ”¾çš„ç¤¾ä¼šï¼Œå’Œä¸€ä¸ªé€æ˜åº¦é«˜çš„ç¤¾ä¼šï¼Œä¸€å®šå¯ä»¥å‹‡æ•¢åœ°é¢å¯¹çœŸç›¸å¹¶å‘å¤§ä¼—æä¾›çœŸç›¸ã€‚æ‰€å¹¸ï¼Œåœ¨ç–«æƒ…é‡å‡»ä¸‹ï¼Œä¸­å›½ä¹Ÿå‡ºç°äº†éš¾å¾—ä¸€è§çš„åª’ä½“æ¾ç»‘ç°è±¡ã€‚</p>
<p>å¦ä¸€æ–¹é¢ï¼Œè¥¿æ–¹ä¹Ÿå¸¸å¸¸ä»å›ºæœ‰çš„è®¤çŸ¥å‡ºå‘ï¼Œç”¨æœ‰è‰²çœ¼é•œçœ‹å¾…ä¸­å›½çš„â€œå°åŸâ€è¡ŒåŠ¨ã€‚åœ¨è¿™åœºæŠ—ç–«ä¸­ï¼Œä¸ä¸œäºšå„åœ°åœ¨æ­¦æ±‰â€œå°åŸâ€ä¹‹åè¿…é€Ÿè¿›å…¥ä½œæˆ˜çŠ¶æ€å®Œå…¨ä¸åŒï¼Œæ¬§ç¾å„å›½ä¸ä»…è´Ÿé¢çœ‹å¾…ä¸­å›½çš„â€œå°åŸâ€è¡ŒåŠ¨ï¼Œè€Œä¸”æ²¡æœ‰ä»ä¸­å›½çš„â€œå°åŸâ€è¡ŒåŠ¨ä¸­å—…å‡ºå±æœºçš„ä¸¥é‡ç¨‹åº¦ã€‚</p>
<p>å‚²æ…¢vsè‡ªå¤§ï¼šè¿™è®©æˆ‘ä»¬å†æ¬¡æ´»ç”Ÿç”Ÿåœ°çœ‹åˆ°äº†å‚²æ…¢ä¸æ— çŸ¥ï¼Œæ¬§ç¾å„å›½æ™®éå°†æœ€åˆåœ¨æ­¦æ±‰å‡ºç°çš„æ–°ç—…æ¯’å½’ç»“ä¸ºé»„ç§äººçš„ç—…ã€‚æ—¥æœ¬å‰¯é¦–ç›¸å…¼è´¢åŠ¡å¤§è‡£éº»ç”Ÿå¤ªéƒ2æœˆä»½æ›¾åœ¨G20è´¢é•¿çš„ä¸€æ¬¡ä¼šè®®ä¸Šä¸»åŠ¨è¡¨ç¤ºæ´åŠ©æ„å¤§åˆ©å’Œè¥¿ç­ç‰™ï¼Œå´è‡ªè®¨æ²¡è¶£ï¼Œæ¬§æ´²å›½å®¶éå¸¸ä¸å±‘ã€‚æ„å¤§åˆ©å‰¯æ€»ç†åæ¥åœ¨G7è´¢æ”¿ä¼šè®®ä¸Šæ›´ç›´æˆªäº†å½“åœ°è¡¨ç¤ºï¼Œè¿™æ˜¯é»„ç§äººæ‰ä¼šå¾—çš„ç—…ï¼Œå’Œä»–ä»¬è¥¿æ–¹äººæ²¡æœ‰å…³ç³»ã€‚æ— æ€ªä¹ï¼Œæ„å¤§åˆ©ä¸€åº¦æˆä¸ºä¸­å›½ä¹‹å¤–æ„ŸæŸ“è€…æœ€å¤šçš„å›½å®¶ã€‚ç‰¹æœ—æ™®çš„å‚²æ…¢ä¸è‡ªå¤§ç»ˆäºåœ¨ç–«æƒ…æ¨ªæ‰«ç¾å›½ä¹‹åï¼Œè¢«è¿«æ‰¿è®¤ç¾å›½å°†é¢å¯¹æ¯”ç¬¬äºŒæ¬¡ä¸–ç•Œå¤§æˆ˜è¿˜è¦æƒ¨é‡çš„æ­»äº¡ã€‚</p>
<p>ç„¶è€Œä¸è¥¿æ–¹çš„å‚²æ…¢ç›¸å¯¹åº”çš„åˆ™æ˜¯åœ¨ä¸­å›½è‡ªåª’ä½“çš„ä¸–ç•Œé‡Œæ— æ—¶ä¸åœ¨çš„è‡ªå¤§ï¼Œåœ¨é‚£é‡Œä½ åªæœ‰çœ‹åˆ°ä¸­å›½æˆäº†å…¨çƒæŠ—ç–«çš„è‹±é›„å’Œæ•‘ä¸–ä¸»ï¼Œæ‰€æœ‰çš„æ‚²å‰§éƒ½æ´»è„±è„±åœ°å˜æˆäº†èµæ­Œçš„ç´ æï¼Œè€Œå¿˜è®°äº†ç—…æ¯’æ˜¯ä»æ­¦æ±‰å¼€å§‹å‘å…¨å›½å’Œå…¨çƒè”“å»¶çš„ã€‚è¿™æ ·çš„è‡ªå¤§åœ¨ä¸­å›½æŠ—ç–«åˆç°æ›™å…‰ä¹‹åï¼Œæ›´æ˜¯å˜æˆäº†å¯¹ä»–å›½è‚†æ— å¿Œæƒ®çš„å˜²ç¬‘ã€‚è€Œæœ€æ–°çš„å¯¹è±¡å°±æ˜¯æ„ŸæŸ“æ–°å† è‚ºç‚äººæ•°æœ€å¤šçš„ç¾å›½ï¼Œå´å¿˜è®°äº†ç¾å›½æ‹¥æœ‰å¼ºå¤§çš„ç§‘æŠ€åŠ›é‡å’Œå‘è¾¾çš„åŒ»ç–—ä½“ç³»ï¼Œä»…ICUï¼ˆé‡ç—‡ç›‘æŠ¤å®¤ï¼‰çš„åºŠä½æ•°é‡å°±è¿œè¿œè¶…è¿‡ä¸­å›½ã€‚è€Œâ€œå‚²æ…¢â€ä¸â€œè‡ªå¤§â€è¿™å¯¹å­ªç”Ÿå…„å¼Ÿå´æ‹¥æœ‰ä¸€ä¸ªå…±åŒç‚¹ï¼šåè§ã€‚</p>
<p>åƒé‡å‘³vsæˆ´å£ç½©ï¼šåœ¨æœ‰å…³ç—…æ¯’æºå¤´çš„åƒé‡å‘³æ–‡åŒ–ï¼Œä»¥åŠé˜²æ­¢ç—…æ¯’æ‰©æ•£çš„æˆ´å£ç½©æ–‡åŒ–çš„è®¨è®ºä¸­ï¼Œæˆ‘ä»¬ä¹Ÿçœ‹åˆ°äº†ç±»ä¼¼çš„åè§ã€‚2003å¹´â€œéå…¸â€ä¹‹åä¸­å›½äººçš„ç¡®æ²¡æœ‰ä»ä¸­å¸å–æƒ¨ç—›çš„æ•™è®­ï¼ŒåŠæ—¶å…³é—­é‡å‘³å¸‚åœºï¼Œä¸å°‘äººå› è€Œå°†æ­¤æ¬¡ç—…æ¯’çš„çˆ†å‘ä¸ä¸­å›½äººå–œçˆ±åƒé‡å‘³çš„æ–‡åŒ–è”ç³»åœ¨ä¸€èµ·ã€‚è¿™æ ·çš„çœ‹æ³•æœ‰å…¶é“ç†ï¼Œä¸­å›½äººæ˜¯æ—¶å€™æ”¹å˜åƒé‡å‘³çš„ç”Ÿæ´»ä¹ ä¿—ã€‚æœ‰è¶£çš„æ˜¯ï¼Œä¸­å›½ç½‘æ°‘åè€Œæ‰¾å‡ºäº†çº½çº¦ä¸Šæµç¤¾ä¼šåƒé‡å‘³çš„è§†é¢‘ï¼Œä¸€æ—¶ä¹‹é—´åœ¨æœ‹å‹åœˆä¸­ç–¯ä¼ ï¼Œè¯æ˜ç¾å›½äººä¸è¿‡æ˜¯äº”åæ­¥ç¬‘ç™¾æ­¥ã€‚ä¸è¿‡è¿™å‡ å¹´æ¯”è¾ƒä¸¥é‡çš„ä¼ æŸ“ç—…ï¼ŒåŒ…æ‹¬ä¸­ä¸œå‘¼å¸ç»¼åˆç—‡å’Œç”²å‹H1N1æµæ„Ÿç—…æ¯’å¹¶éæºè‡ªä¸­å›½ã€‚</p>
<p>å¦ä¸€æ–¹é¢ï¼Œäºšæ´²äººæˆ´å£ç½©ä»¥é˜²æ­¢ç—…æ¯’æ‰©æ•£åŸºæœ¬æ˜¯å…±è¯†ã€‚ä½†è¥¿æ–¹äººï¼Œå³ä¾¿æ˜¯ç”Ÿæ´»åœ¨äºšæ´²çš„è¥¿æ–¹äººä¹Ÿä¸å–œæ¬¢æˆ´å£ç½©ã€‚åœ¨è¥¿æ–¹ï¼Œè§†å£ç½©ä¸ºç—…äººæ ‡å¿—çš„è§‚å¿µè¿˜å¸¦æ¥äº†å¯¹äºšè£”äººçš„æ­§è§†ã€‚åœ¨æ¬§ç¾å„å›½ç”Ÿæ´»çš„äºšè£”äººå¤„åœ¨æˆ´å£ç½©è¢«æ­§è§†ï¼Œä¸å¸¦å£ç½©æ€•æŸ“ä¸Šç—…æ¯’çš„å¤©äººäº¤æˆ˜ä¸­ã€‚ä½†åœ¨è¿™æ¬¡ç–«æƒ…é‡å‡»æ¬§ç¾ä¹‹åï¼Œæˆ´å£ç½©æŠµæŠ—ç—…æ¯’çš„è®¤çŸ¥ç»ˆäºæ…¢æ…¢å¼€å§‹åœ¨æ¬§ç¾è¢«æ¥å—äº†ã€‚</p>
<p>è‡ªåª’ä½“vsä¸»æµåª’ä½“ï¼ˆèµç¾vsæ‰¹è¯„ï¼‰ï¼šåœ¨ç–«æƒ…çš„æŠ¥é“ä¸Šï¼Œä¸­å›½çš„ä¸»åŠ›å†›æ˜¯è‡ªåª’ä½“ï¼Œä¸ç®¡æ˜¯èµæ­Œï¼Œè¿˜æ˜¯æ‰¹è¯„ï¼Œè‡ªåª’ä½“å¸¦æœ‰æ›´å¤šçš„ä¸»è§‚æ€§å’Œæƒ…ç»ªæ€§ã€‚è€Œåœ¨è®¸å¤šå…¶å®ƒåœ°æ–¹ï¼ŒæŠ¥é“ç–«æƒ…çš„ä¸»åŠ›æ˜¯ä¸»æµåª’ä½“ï¼ŒåŠ›æ±‚å®¢è§‚ã€‚ç‰¹åˆ«æ˜¯ç¾å›½åª’ä½“ï¼Œå…¶è§’è‰²æ˜¯ç›‘ç£æ”¿åºœï¼Œä¸”å–œæ¬¢ç›‘ç£å…¨ä¸–ç•Œçš„æ”¿åºœï¼Œå¤šæ•°åˆæ˜¯è‡ªç”±ä¸»ä¹‰å€¾å‘ï¼Œæ‰€ä»¥ç‰¹æœ—æ™®ä¹Ÿåæ„Ÿç¾å›½ä¸»æµåª’ä½“ã€‚ä½†åªæœ‰åœ¨ç¾å›½è¿™ä¸ªå›½å®¶ï¼ŒCBSè®°è€…èƒ†æ•¢åœ¨ç™½å®«æ€’æ€¼æ€»ç»Ÿä¸ºä½•è¦ä½¿ç”¨æ­§è§†æ€§çš„â€œä¸­å›½ç—…æ¯’â€ï¼›NBCçš„è®°è€…è´¨é—®ç‰¹æœ—æ™®å¹æ§æ•ˆæœæœªç»è¯å®çš„æŠ—ç–«è¯ç‰©æ˜¯å¦ç»™ç¾å›½äººè™šå‡çš„å¸Œæœ›ï¼Œå¹¶æŒ‡ç¾å›½æ•°ç™¾ä¸‡äººæ´»äºææƒ§ä¸­ï¼›çº½çº¦æ—¶æŠ¥é©»äº¬è®°è€…å¼ å½¦ï¼ˆIan Johnson ï¼‰çš„â€œè§‚ç‚¹â€æ–‡ç« ï¼ŒæŒ‡å‡ºä¸­å›½ä¸ºç¾å›½èµ¢å¾—äº†æ—¶é—´å´è¢«ç¾å›½ç™½ç™½æµªè´¹äº†ï¼›çº½çº¦æ—¶æŠ¥çš„ç¤¾è®ºå…¬å¼€è°´è´£ç‰¹æœ—æ™®æ”¿åºœå®˜å‘˜çš„è¨€è¯åŠ å‰§äº†å¯¹äºšè£”çš„ç§æ—ä»‡æ¨ã€‚</p>
<p>ä¸­å›½è‡ªåª’ä½“é‡Œé‚£ä¸ªå‘è‡ªçº½çº¦çš„æŠ—ç–«æ—¥è®°ï¼Œä½œè€…å£°ç§°å…¶ç´ æå…¨éƒ¨å–è‡ªç¾å›½åª’ä½“çš„å…¬å¼€æŠ¥é“ï¼Œè€Œéé“å¬é€”è¯´ï¼Œè¯­å¸¦åŒå…³ã€‚çš„ç¡®ï¼Œå½“çº½çº¦æˆä¸ºç¾å›½çš„æ­¦æ±‰æ—¶ï¼Œæˆ‘æ¯å¤©åœ¨ç¾å›½ç”µè§†æ–°é—»ä¸Šçœ‹åˆ°çš„å‡ ä¹å…¨æ˜¯â€œè´Ÿé¢â€æ¶ˆæ¯ã€‚æ¯ä¸€ä¸ªæ´»ç”Ÿç”Ÿçš„äººç¦»å¼€äººä¸–æ—¶çš„å‡„æƒ¨æ•…äº‹ï¼›ç—…äººå› ç¼ºä¹åŒ»ç–—è®¾å¤‡æ— æ³•è·å¾—åŠæ—¶åŒ»æ²»çš„æ‚²å‰§ï¼›åŒ»åŠ¡äººå‘˜é¢å¯¹æ­»äº¡å¨èƒæˆ˜æ–—åœ¨ç¬¬ä¸€çº¿å‡ ä¹å´©æºƒçš„åœºé¢ï¼›åœç•™åœ¨è¡—è¾¹è£…æ»¡å°¸ä½“çš„å†°å†»è½¦å’ŒåŒ»é™¢èµ°å»Šé‡Œè¿å°¸è¢‹çš„åœºæ™¯ï¼›è´¨é—®ç™½å®«ä½•æ—¶å¯ä»¥ç¡®ä¿åŒ»ç–—è®¾å¤‡è¿æŠµç°åœºçš„æ„¤æ€’ï¼›å—åˆ°ç—…æ¯’æ„ŸæŸ“å¨èƒä¸‹ç¾å›½æµ·å†›å®˜å…µçš„å‘¼åï¼›å¤±å»å·¥ä½œçš„æ™®é€šäººæ— æ³•äº¤ä»˜æˆ¿è´·çš„å¿§è™‘ã€‚åœ¨è¿™é‡Œä½ çœ‹åˆ°çš„æ˜¯ææƒ§ï¼Œæ˜¯æ‹…å¿§ï¼Œæ˜¯æ‚²ä¼¤ï¼Œåœ¨è¿™é‡Œä½ å¬ä¸åˆ°ä»»ä½•èµæ­Œã€‚</p>
<p>å¨æƒvsæ°‘ä¸»ï¼šè¿™æ¬¡å…¨çƒæŠ—ç–«çš„å™äº‹å·²ç»æˆä¸ºä¸­å›½æ¨¡å¼å’Œè¥¿æ–¹æ¨¡å¼ä¹‹äº‰ï¼Œç”šè‡³ä¸Šå‡åˆ°å¨æƒè¿˜æ˜¯æ°‘ä¸»ä½“åˆ¶åœ¨æŠ—ç–«ä¸­å“ªä¸ªæ›´æœ‰æˆæ•ˆçš„äº‰è®ºï¼Œä½†ä¸å°‘äººå´å¿˜è®°äº†æ— è®ºä½•ç§ä½“åˆ¶éƒ½æœ‰å…¶æˆåŠŸä¸å¤±è´¥çš„ç»éªŒä¸æ•™è®­ã€‚åœ¨æ¬§æ´²æˆä¸ºé‡ç¾åŒºä¹‹åï¼Œå¾·å›½çš„æ­»äº¡ç‡å´ä¸€ç›´å¾ˆä½ï¼Œè¿™æˆ–è®¸ä¸æ—¥è€³æ›¼æ°‘æ—çš„è‡ªå¾‹æœ‰å…³ã€‚åœ¨äºšæ´²å¤„äºææ…Œçš„æ—¶å€™ï¼Œæ—¥æœ¬å¹¶æ²¡æœ‰è·Ÿéšä¸­å›½å°åŸã€æ²¡æœ‰è·ŸéšéŸ©å›½å¤§é¢ç§¯æ£€æµ‹ï¼Œä½†ä¹Ÿæ²¡æœ‰åƒæ¬§ç¾å‘è¾¾å›½å®¶é‚£æ ·å¤±æ§ï¼Œè¿™æˆ–è®¸ä¸å¤§å’Œæ°‘æ—çš„è‡ªå¾‹å’Œç”Ÿæ´»ä¹ æƒ¯æœ‰å…³ã€‚å¦‚æœå°†æŠ—ç–«ç®€å•åœ°çœ‹æˆæ˜¯ä¸­å›½ä½“åˆ¶çš„èƒœåˆ©ï¼Œé‚£ä¹ˆéŸ©å›½ã€æ—¥æœ¬ã€æ–°åŠ å¡ã€é¦™æ¸¯ã€å°æ¹¾ç­‰åœ°åˆæ˜¯ä½•ç§ä½“åˆ¶ï¼Ÿæ— ç–‘ï¼Œä¸­å›½è‡ªä¸Šè€Œä¸‹çš„åŠ¨å‘˜åŠ›é‡ï¼Œè®©å…¨çƒçœ‹åˆ°äº†ä¸­å›½ä½“åˆ¶æˆ˜èƒœç–«æƒ…çš„è¶…å¼ºèƒ½åŠ›ï¼Œä½†è‡ªä¸‹è€Œä¸Šçš„å…¬æ°‘ç¤¾ä¼šçš„åº”å˜å’Œè°ƒæ•´èƒ½åŠ›åœ¨çº½çº¦æˆä¸ºç–«æƒ…é‡ç¾åŒºä¹‹åï¼ŒåŒæ ·ä»¤äººåˆ®ç›®ç›¸çœ‹ã€‚</p>
<p>çº½çº¦åœ¨ä¸­å¤®å…¬å›­ã€ä½“è‚²åœºè¿…é€Ÿå»ºèµ·æ–¹èˆŸåŒ»é™¢ï¼Œå¹¶åŠ å¿«å¯¹å—æ„ŸæŸ“ç–‘ä¼¼äººå‘˜çš„æ£€æµ‹ã€‚æ¥è‡ªå…¨ç¾çš„å…­ä¸‡å¤šååŒ»åŠ¡äººå‘˜ä¸»åŠ¨æŠ¥åæˆä¸ºè‡ªæ„¿è€…ï¼Œè‡ªå‘å‰å¾€çº½çº¦æ”¯æ´äººæ‰‹ä¸è¶³çš„åŒ»é™¢ï¼Œâ€œæ·è“â€èˆªç©ºå…è´¹è½½é€è¿™äº›åŒ»æŠ¤äººå‘˜â€œä¸Šæˆ˜åœºâ€ï¼Œé…’åº—å…è´¹æä¾›ä½å®¿ï¼Œä¼ä¸šæ…·æ…¨æèµ æ€¥éœ€çš„é˜²æŠ¤ç”¨å“å’ŒåŒ»ç–—è®¾å¤‡ï¼Œä½†æ²¡æœ‰ä¼ä¸šå¯¹è¿™äº›è¡ŒåŠ¨å‘ç¨¿ã€åšå…¬å…³ã€é«˜è°ƒå®£ä¼ ã€‚å³ä¾¿ç¾å›½æ€»ç»Ÿé¢å¯¹æ–°å† è‚ºç‚çš„ååº”ä¸‘æ€ç™¾å‡ºï¼Œä½†è¿™ä¸ªå›½å®¶æ‰€å¹¸ä¸æ˜¯ä¸€ä¸ªäººè¯´çš„ç®—ï¼Œå—ç–«æƒ…å½±å“æœ€å¤§çš„çº½çº¦å·ã€åŠ å·ã€åç››é¡¿å·éƒ½ä¸ç†ç¬ä»–çš„ç‹‚è¨€å¦„è¯­ã€‚è€Œç¾å›½çš„ä½“åˆ¶ä¹Ÿå†³å®šäº†è”é‚¦æ”¿åºœå¯¹å·ä¸€çº§æ”¿åºœçš„äº‹åŠ¡ä¸å¯å¹²æ¶‰ï¼Œå³ä¾¿ç‰¹æœ—æ™®æƒ³å¯¹çº½çº¦å’Œä¸´è¿‘çš„ä¸¤ä¸ªå·â€œå°åŸâ€ï¼Œä½†çº½çº¦å·å·é•¿å…¬å¼€åå¯¹ï¼Œä½¿å¾—ç‰¹æœ—æ™®ä¸å¾—ä¸æ”¾å¼ƒè¿™ä¸€æƒ³æ³•ã€‚ç‰¹æœ—æ™®éšå¿ƒæ‰€æ¬²ï¼Œç–«æƒ…è¿˜æœªæ§åˆ¶ï¼Œå°±è¦æ±‚å¤æ´»èŠ‚æ¢å¤ç»æµè¿ä½œï¼Œä½†ç–¾ç—…ä¸“å®¶å’Œåª’ä½“åˆ™å…¬å¼€å’Œä»–å”±å¯¹å°æˆã€‚å› æ­¤ï¼Œåº”å¯¹ç—…æ¯’éœ€è¦åœ¨ä¸€ä¸ªè‡ªä¸‹è€Œä¸Šçš„å…¬æ°‘ç¤¾ä¼šé‡Œï¼Œæ°‘ä¼—æ•¢äºæ‰¿æ‹…å…¬æ°‘åº”æœ‰çš„è´£ä»»å’Œä¹‰åŠ¡ã€‚</p>
<p>åœ¨å…¨çƒé¢å¯¹è¿™åœºå‰æ‰€æœªæœ‰çš„å¤§ç¾éš¾æ—¶ï¼Œæˆ‘ä»¬éœ€è¦ç†æ€§åœ°æ€è€ƒäººç±»çš„å¤±è¯¯å’Œå¤±è´¥ï¼Œè€ŒéæŒ‡è´£å’Œæ¨å¸ã€‚è¿™åœºå¤§ç¾éš¾ç¦»è½å¹•ä¹‹æ—¥è¿˜æœ‰æ¼«æ¼«é•¿è·¯ï¼Œä½†è¿™åœºå¤©ç¾ä¸äººç¥¸ä¹Ÿç»™äººç±»æä¾›äº†ä¸€æ¬¡éš¾å¾—çš„åæ€æœºä¼šã€‚åœ¨è¿™åœºç–«æƒ…ç»“æŸä¹‹åï¼Œæˆ–è®¸å…¨çƒç»ˆå°†æ˜ç™½è¿™ä¸æ˜¯â€œä¸­å›½ç—…æ¯’â€ï¼Œæ˜¯å„å›½å¿…é¡»å…±åŒé¢å¯¹çš„â€œä¸–ç•Œç—…æ¯’â€ï¼Œç—…æ¯’æ°æ°å› æˆ‘ä»¬äººç±»çš„å‚²æ…¢ã€è‡ªå¤§ã€å’Œè‡ªç§è€Œå››å¤„è‚†è™ã€‚åœ¨è¿™ä¸ªå…¨çƒåŒ–è¢«æ±¡ååŒ–çš„æ—¶ä»£ï¼Œå°½ç®¡å›½ä¸å›½çš„ç•Œçº¿ä¾æ—§åˆ†æ˜ï¼Œä½†ç—…æ¯’ç»ä¸ä¼šåªåœ¨ä¸€å›½çš„è¾¹å¢ƒçº¿å†…åœç•™ã€‚æˆ‘ä»¬æ¯”ä»¥å¾€ä»»ä½•æ—¶å€™éƒ½æ›´éœ€è¦æœ‰å…¨çƒçš„è§†é‡å’Œå…¨çƒçš„èƒ¸æ€€ï¼Œæˆ‘ä»¬å¿…é¡»å­¦ä¼šå¦‚ä½•åˆä½œå»å…±åŒåº”å¯¹å‰æ‰€æœªæœ‰çš„æŒ‘æˆ˜ã€‚</p>
<p>åºšå­å¹´å¸¸å¸¸æ˜¯ç¾éš¾ä¹‹å¹´ï¼Œä½†æˆ–è®¸ä¹Ÿæ˜¯è½¬æŠ˜ä¹‹å¹´ã€‚åœ¨æ–°å† ç—…æ¯’æ¨ªæ‰«å…¨çƒä¹‹åï¼Œè¿™ä¸åº”è¯¥æ˜¯æˆ‘ä»¬é‡æ‹¾å­¤ç«‹çš„æ—¶åˆ»ï¼Œè€Œæ˜¯é€šå‘ä¸€ä¸ªä¸ä¸€æ ·çš„å…¨çƒåŒ–æ–°æ—¶ä»£çš„æ–°èµ·ç‚¹ã€‚</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CentosæœåŠ¡å™¨condaç¯å¢ƒé…ç½®è„šæœ¬]]></title>
        <id>https://sunyanhust.github.io/post/centos-fu-wu-qi-conda-huan-jing-pei-zhi-jiao-ben/</id>
        <link href="https://sunyanhust.github.io/post/centos-fu-wu-qi-conda-huan-jing-pei-zhi-jiao-ben/">
        </link>
        <updated>2020-04-04T14:11:21.000Z</updated>
        <content type="html"><![CDATA[<h2 id="è¯´æ˜">ğŸ“ƒè¯´æ˜</h2>
<p>æœ¬è„šæœ¬ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªåŠŸèƒ½ï¼š</p>
<ol>
<li>ä»æ¸…åæºè‡ªåŠ¨ä¸‹è½½anacondaå¹¶å®‰è£…</li>
<li>é…ç½®pipå›½å†…æºä¸ºé˜¿é‡Œæº</li>
<li>é…ç½®condaæºä¸ºustc(è¿™ä¸€æ­¥æœ‰ç–‘é—®ï¼Œå› ä¸ºcondaæºç»å¸¸ä¼šä¸å¯ç”¨ï¼Œéœ€è¦ç»å¸¸æ€§æµ‹è¯•)</li>
<li>è‡ªåŠ¨åˆ›å»ºtf14ç¯å¢ƒ å®‰è£…cudnnå’Œcudaä»¥åŠpytorch è‡ªåŠ¨æµ‹è¯•GPUç¯å¢ƒæ˜¯å¦å¯ç”¨</li>
<li>è‡ªåŠ¨åˆ›å»ºtf20ç¯å¢ƒ å®‰è£…cudnnå’Œcudaä»¥åŠpytorch è‡ªåŠ¨æµ‹è¯•GPUç¯å¢ƒæ˜¯å¦å¯ç”¨</li>
</ol>
<h2 id="code">ğŸ’¾Code</h2>
<pre><code class="language-shell">yum install -y bzip2

# download anaconda and install
echo &quot;download anaconda and install&quot;
wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.3.1-Linux-x86_64.sh
sh Anaconda3-5.3.1-Linux-x86_64.sh -u

source ~/.bashrc

# change pip source to aliyun
echo &quot;change pip source to aliyun&quot;

if [ ! -d &quot; ~/.pip/&quot; ];then
mkdir  ~/.pip
else
echo &quot;pip existed&quot;
fi

cat&gt;~/.pip/pip.conf&lt;&lt;EOF
[global]
index-url = http://mirrors.aliyun.com/pypi/simple/
[install]
trusted-host=mirrors.aliyun.com
EOF

# change anaconda source to ustc
echo &quot;change anaconda source to ustc&quot;
cat&gt;~/.condarc&lt;&lt;EOF 
channels:
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
  - https://mirrors.ustc.edu.cn/anaconda/cloud/menpo/
  - https://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/
  - https://mirrors.ustc.edu.cn/anaconda/cloud/msys2/
  - https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/
  - https://mirrors.ustc.edu.cn/anaconda/pkgs/free/
  - https://mirrors.ustc.edu.cn/anaconda/pkgs/main/
  - defaults
show_channel_urls: true
EOF

#gpu test file
cat&gt;gpu_test.py&lt;&lt;EOF
import os
import tensorflow as tf
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
if tf.test.gpu_device_name():
    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))
    print('Your tensorflow-gpu is available')
else:
    print('Your tensorflow-gpu is not available')
    print(&quot;Please install GPU version of TF&quot;)
import torch
if torch.cuda.is_available():
    print('Default GPU Device: {}'.format(torch.cuda.get_device_name()))
    print('Your pytorch-gpu is available')
else:
    print('Your pytorch-gpu is not available')
    print(&quot;Please install GPU version of Pytorch&quot;)
EOF

# creat tf14 env 
echo &quot;creating tf14 env&quot;
conda create -n tf14 python=3.7 -y
conda activate tf14

conda install tensorflow-gpu==1.14.0 -y
pip install torch torchvision -U
pip install numpy==1.15.4

python gpu_test.py

# creat tf20 env
echo &quot;creating tf20 env&quot;
conda create -n tf20 python=3.7 -y
conda activate tf20

conda install tensorflow-gpu==2.0.0 -y
pip install torch torchvision -U
pip install numpy==1.15.4

python gpu_test.py
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[KerasæŒ‡å®šæ˜¾å¡å¹¶é™åˆ¶æ˜¾å­˜ä½¿ç”¨ï¼ˆtensorflowåç«¯ï¼‰]]></title>
        <id>https://sunyanhust.github.io/post/keras-zhi-ding-xian-qia-bing-xian-zhi-xian-cun-shi-yong-tensorflow-hou-duan/</id>
        <link href="https://sunyanhust.github.io/post/keras-zhi-ding-xian-qia-bing-xian-zhi-xian-cun-shi-yong-tensorflow-hou-duan/">
        </link>
        <updated>2020-04-02T04:08:55.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>æœ¬æ–‡è½¬è½½è‡ª<a href="https://zhuanlan.zhihu.com/p/65218239">çŸ¥ä¹</a></p>
</blockquote>
<p>Kerasä½¿ç”¨æ˜¾å¡æ—¶æ˜¯é»˜è®¤è°ƒç”¨æ‰€æœ‰çš„GPUï¼Œå¹¶ä¸”å æ»¡æ‰€æœ‰æ˜¾å­˜çš„ï¼Œæ‰€ä»¥å°±å¾ˆæœ‰å¿…è¦ææ¸…æ¥šKeraså¦‚ä½•æŒ‡å®šGPUå’Œå¦‚ä½•é™åˆ¶æ˜¾å­˜çš„ä½¿ç”¨æ¯”ä¾‹äº†ã€‚</p>
<h2 id="æŒ‡å®šæŸå—gpu">ğŸ“’æŒ‡å®šæŸå—GPU</h2>
<p>æŒ‡å®šGPUå¾ˆç®€å•ï¼Œåœ¨è½½å…¥keraså’Œtensorflowä¹‹å‰ï¼Œè®¾ç½®CUDAè®¡ç®—ä½¿ç”¨çš„GPUåºå·å³å¯ã€‚è¿™å…¶å®æ˜¯CUDAæœ¬èº«çš„å‚æ•°ï¼Œå¯¹æ‰€æœ‰æ·±åº¦å­¦ä¹ æ¡†æ¶éƒ½æ˜¯é€‚ç”¨çš„ã€‚éœ€è¦æ³¨æ„çš„æ˜¯æœ€å¥½å†™åœ¨<code>improt keres</code> å’Œ <code>import tensorflow</code>ä¹‹å‰ï¼Œä¸ç„¶å¯èƒ½å‡ºé”™ã€‚</p>
<pre><code class="language-python">import os
os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;1&quot;
</code></pre>
<p>æ­¤ä»£ç é€‰æ‹©çš„æ˜¯ç¼–å·ä¸ºâ€œ1â€çš„æ˜¾å¡ã€‚æ˜¾å¡çš„ç¼–å·æ˜¯ä»â€œ0â€å¼€å§‹çš„ï¼Œè‹¥åªæœ‰ä¸€å—æ˜¾å¡åˆ™ç¼–å·ä¸ºâ€œ0â€ã€‚</p>
<h2 id="æŒ‡å®šå¤šå—gpu">ğŸ“’æŒ‡å®šå¤šå—GPU</h2>
<p>æŒ‡å®šå¤šå—GPUçš„æ–¹å¼å’Œå‰æ–‡å®Œå…¨ä¸€è‡´ï¼Œåªéœ€è¦å¤šå†™å‡ ä¸ªç¼–å·å³å¯ï¼š</p>
<pre><code class="language-python">import os
os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] =  &quot;0, 2&quot;
</code></pre>
<p>æ­¤æ—¶é€‰æ‹©çš„æ˜¯ç¼–å·ä¸ºâ€œ0â€å’Œç¼–å·ä¸ºâ€œ2â€çš„æ˜¾å¡</p>
<h2 id="æ§åˆ¶gpuæ˜¾å­˜ä½¿ç”¨æ¯”ä¾‹">ğŸ“’æ§åˆ¶GPUæ˜¾å­˜ä½¿ç”¨æ¯”ä¾‹</h2>
<p>Kerasæ˜¯é»˜è®¤å æ»¡GPUæ˜¾å­˜çš„ï¼Œæˆ‘ä»¬é€šè¿‡é‡è®¾backendçš„gpu_memory_fractionæ¥è¿›è¡Œè°ƒèŠ‚ï¼Œ0.3è¡¨ç¤ºå ç”¨30%çš„æ˜¾å­˜ï¼š</p>
<pre><code class="language-python">import tensorflow as tf
from keras.backend.tensorflow_backend import set_session
config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.3
set_session(tf.Session(config=config))
</code></pre>
<p>ä¸è¿‡è™½ç„¶é…ç½®äº†GPUæ˜¾å­˜çš„å ç”¨æ¯”ä¾‹ï¼Œå®é™…è¿è¡Œä¸­è‹¥ä¸å¤Ÿç”¨çš„è¯è¿˜æ˜¯è·å–æ›´å¤šçš„æ˜¾å­˜ã€‚æ¯”æ–¹è¯´å¦‚æœè¿è¡Œäº†3ä¸ªè®¾ç½®ä¸º30%æ˜¾å­˜çš„åº”ç”¨ï¼Œå®é™…ä¸Šæ˜¯å¯èƒ½è¶…è¿‡100%é€ æˆæ˜¾å­˜ä¸è¶³çš„ã€‚</p>
<h2 id="æŒ‡å®šgpuæ§åˆ¶æ˜¾å­˜ä½¿ç”¨">ğŸ“’æŒ‡å®šGPU+æ§åˆ¶æ˜¾å­˜ä½¿ç”¨</h2>
<p>å°†æŒ‡å®šGPUä¸æ§åˆ¶æ˜¾å­˜ä½¿ç”¨æ¯”ä¾‹åˆå¹¶æ“ä½œå³å¯ï¼š</p>
<pre><code class="language-python">import os
os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;1&quot;
import tensorflow as tf
from keras.backend.tensorflow_backend import set_session
config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.3
set_session(tf.Session(config=config))
</code></pre>
<p>è¯¥ä»£ç å®ç°çš„æ˜¯æŒ‡å®šç¼–å·ä¸ºâ€œ1â€çš„GPUï¼Œå¹¶è®¾ç½®å ç”¨æ˜¾å­˜çš„æ¯”ä¾‹ä¸º30%ã€‚</p>
<h2 id="æ˜¾å­˜çš„æŒ‰éœ€åˆ†é…åŠ¨æ€å¢é•¿">ğŸ“’æ˜¾å­˜çš„æŒ‰éœ€åˆ†é…ï¼ˆåŠ¨æ€å¢é•¿ï¼‰</h2>
<p>å¦‚æœå¹¶ä¸æ¸…æ¥šè‡ªå·±çš„åº”ç”¨åˆ†é…å¤šå°‘çš„æ˜¾å­˜æ¯”ä¾‹åˆé€‚ï¼Œå¯ä»¥ä½¿ç”¨æŒ‰éœ€åˆ†é…çš„æ–¹å¼ï¼Œä¹Ÿå°±æ˜¯åŠ¨æ€å¢é•¿allow_growthï¼š</p>
<pre><code class="language-python">import os
os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;1&quot;
import tensorflow as tf
from keras.backend.tensorflow_backend import set_session
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
set_session(tf.Session(config=config))
</code></pre>
<p>è¯¥ä»£ç å®ç°çš„æ˜¯æŒ‡å®šç¼–å·ä¸ºâ€œ1â€çš„GPUï¼Œå¹¶è®¾ç½®å ç”¨æ˜¾å­˜çš„æ–¹å¼ä¸ºæŒ‰éœ€å¢é•¿ã€‚</p>
]]></content>
    </entry>
</feed>